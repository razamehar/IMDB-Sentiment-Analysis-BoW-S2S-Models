{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/razamehar/IMDB-Sentiment-Analysis-BoW-S2S-Models/blob/main/Sentiment_Analysis_V2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Download and Extraction\n",
        "\n",
        "---\n",
        "In this section, we focus on the steps required to download and extract the IMDB dataset. First, the dataset is retrieved from a specified URL, ensuring we have the necessary data for our analysis. After downloading, the contents of the dataset are extracted from the compressed tar.gz file. These steps are essential to prepare the data for subsequent processing and analysis, enabling us to work with the IMDB dataset effectively.\n"
      ],
      "metadata": {
        "id": "Ga3CyMBnw3or"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0VF02SS9X6b",
        "outputId": "99c156fa-e0c3-47c4-c0d7-8d3afa78dc7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  61.7M      0  0:00:01  0:00:01 --:--:-- 61.7M\n"
          ]
        }
      ],
      "source": [
        "# Download the IMDB dataset from the specified URL\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "\n",
        "# Extract the contents of the downloaded tar.gz file\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities\n",
        "\n",
        "---\n",
        "This section contains utility functions designed to assist with various tasks related to dataset management and analysis.\n",
        "\n",
        "First, the get_info function is defined to display the count of files, the name of the first file, and the content of a random file in a specified directory. It accepts a sub-directory (e.g., 'train' or 'test') and a category (e.g., 'neg' or 'pos') as arguments and returns a list of file names along with the number of files.\n",
        "\n",
        "Next, the move_files function is implemented to move a specified number of files from the training set to a validation set. It takes a list of file names, the number of validation samples, and the category as inputs, shuffling the file list and transferring the designated files.\n",
        "\n",
        "The get_info_from_ds function is then defined to provide information about a batched dataset created using Keras's text_dataset_from_directory function. It prints the shape and data type of the inputs and targets, as well as the first input and target sample.\n",
        "\n",
        "Lastly, the analyze_text_samples function calculates the ratio of the number of training samples to the mean number of words per sample and returns a list of all the words in the text samples. It iterates through the text files in a specified directory, counting the total words and computing the mean words per sample. This ratio helps determine whether a bag-of-words or sequence model might perform better on the data.\n",
        "\n",
        "These utility functions provide essential tools for managing and analyzing text datasets, aiding in the preparation and evaluation processes."
      ],
      "metadata": {
        "id": "EPND2Mncw-4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that displays the count of files, the name of the first file, and the content of a random file in the specified directory.\n",
        "\n",
        "import pathlib\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Set the path of the base directory.\n",
        "base_dir = pathlib.Path('/content/aclImdb')\n",
        "\n",
        "def get_info(sub_dir, category):\n",
        "  '''\n",
        "    Args:\n",
        "        sub_dir (str): A sub-directory within the base directory (e.g., 'train' or 'test').\n",
        "        category (str): A class sub-directory within the sub-directory that defines the class (e.g., 'neg' or 'pos').\n",
        "\n",
        "    Return:\n",
        "        file_names (list): List of names of all files and folders in the specified directory.\n",
        "        num_files (int): Count of samples in the specified directory.\n",
        "  '''\n",
        "\n",
        "  # Join the paths.\n",
        "  path = base_dir / sub_dir / category\n",
        "\n",
        "  # Retrieve the list of names of all files and folders, if any, in the specified path.\n",
        "  file_names = os.listdir(path)\n",
        "\n",
        "  # Count of files\n",
        "  num_files = len(file_names)\n",
        "\n",
        "  # Display the count of samples and the name of first file.\n",
        "  print(f'Directory: {sub_dir} - Class: {category}')\n",
        "  print(f'\\tNumber of samples: {num_files}')\n",
        "  print(f'\\tName of the first file: {file_names[0]}')\n",
        "\n",
        "  # Read a random sample and display its content.\n",
        "  idx = random.randint(0, num_files)\n",
        "\n",
        "  with open(path/file_names[idx], 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "  print(f'\\tContent of a random sample: {content}\\n')\n",
        "\n",
        "  return file_names, num_files"
      ],
      "metadata": {
        "id": "7ha98Q_7I2SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that moves files from training to val.\n",
        "\n",
        "import shutil\n",
        "\n",
        "def move_files(file_names, num_val_samples, category):\n",
        "  '''\n",
        "    Args:\n",
        "      file_names (list): List of names all files and folders in the specified directory.\n",
        "      num_files (int): Count of samples in the specified directory.\n",
        "      category (str): A class sub-directory within the sub-directory that defines the class (e.g., 'neg' or 'pos').\n",
        "  '''\n",
        "  # Shuffle the files using the seed.\n",
        "  random.Random(1000).shuffle(file_names)\n",
        "\n",
        "  val_files = file_names[-num_val_samples:]\n",
        "\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname,\n",
        "                val_dir / category / fname)"
      ],
      "metadata": {
        "id": "z3pGBtjZQP09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that inputs information about the batched dataset.\n",
        "\n",
        "def get_info_from_ds(ds, ds_type):\n",
        "  '''\n",
        "    Args:\n",
        "      ds (tf_BatchDataset): A batched dataset created using Keras's text_dataset_from_directory function.\n",
        "      df_type (str): Name of the batched dataset.\n",
        "  '''\n",
        "  print(ds_type)\n",
        "\n",
        "  for inputs, targets in ds:\n",
        "    print(\"\\tinputs.shape:\", inputs.shape)\n",
        "    print(\"\\tinputs.dtype:\", inputs.dtype)\n",
        "    print(\"\\ttargets.shape:\", targets.shape)\n",
        "    print(\"\\ttargets.dtype:\", targets.dtype)\n",
        "    print(\"\\tinputs[0]:\", inputs[0])\n",
        "    print(\"\\ttargets[0]:\", targets[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "5hVhOIsRWLbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that calculates the ratio of number per training samples / mean words per samples and also returns the list of all the words in the text samples.\n",
        "import glob\n",
        "\n",
        "def analyze_text_samples(path):\n",
        "  '''\n",
        "    Args:\n",
        "      path (str): path to a directory containing samples.\n",
        "\n",
        "    Returns:\n",
        "      words (list): List of all the words in the sample.\n",
        "  '''\n",
        "\n",
        "  words_in_samples = 0\n",
        "  words = []\n",
        "\n",
        "  # Define the path to the directory containing the text files\n",
        "  path = path\n",
        "\n",
        "  # Get a list of all text files in the directory\n",
        "  txt_files = glob.glob(os.path.join(path, '*.txt'))\n",
        "\n",
        "  # Iterate through the list of files and print the content of each file\n",
        "  for file in txt_files:\n",
        "      with open(file, 'r', encoding='utf-8') as f:\n",
        "          content = f.read()\n",
        "          words.append(content.split())\n",
        "          words_in_samples += len(content.split()) # .split() is used as we want the count of words and not characters.\n",
        "\n",
        "  print('Total words in all the sampples:', words_in_samples)\n",
        "\n",
        "  mean_words_per_sample = words_in_samples/num_train_samples\n",
        "  mean_words_per_sample\n",
        "\n",
        "  print('Mean words per sample:', mean_words_per_sample)\n",
        "\n",
        "  ratio = num_train_samples/mean_words_per_sample\n",
        "  print('Ratio of number per training samples / mean words per samples:', ratio)\n",
        "  print('\\n')\n",
        "\n",
        "  if ratio < 1500:\n",
        "    print('Bag-of-words model might perform better on this data.')\n",
        "  else:\n",
        "    print('Sequence model might perform better on this data')\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "DWJjuSXLiHZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Review\n",
        "\n",
        "---\n",
        "In this section, we utilize the get_info function to review the IMDB dataset. This function helps display the count of samples, the name of the first file, and the content of a random sample within specified directories. The results from this function provide a comprehensive overview of the dataset structure and contents, aiding in understanding the data distribution.\n",
        "\n",
        "We start by applying the get_info function to the training data for both positive and negative classes. The function returns a list of file names and the number of files in each category, which will be useful for further processing:\n",
        "\n",
        "For the 'train' sub-directory, we gather information on both 'pos' (positive) and 'neg' (negative) categories.\n",
        "Next, we apply the get_info function to the test data. Although the count of files in the 'test' sub-directory is not required for subsequent steps, invoking this function provides insight into the test data's structure:\n",
        "\n",
        "We examine the 'pos' (positive) and 'neg' (negative) categories within the 'test' sub-directory.\n",
        "This review step ensures that we have a clear understanding of the dataset's composition, which is crucial for any further analysis or model training."
      ],
      "metadata": {
        "id": "plEEXZlAxIte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use get_info() function to display the count of samples, the name of the first file, and the content of a random samples.\n",
        "# The function returns a list of file names as well as a count of files that will be utilized later.\n",
        "\n",
        "file_names_train_pos, num_files_train_pos = get_info('train', 'pos')\n",
        "file_names_train_neg, num_files_train_ne = get_info('train', 'neg')\n",
        "\n",
        "# Use _ as we will not require count of files in the class sub-directories of the test sub-directory.\n",
        "_, _ = get_info('test', 'pos')\n",
        "_, _ = get_info('test', 'neg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YTb0kP3-SvY",
        "outputId": "3edaf656-549b-4a2c-b2b6-72788bb24bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory: train - Class: pos\n",
            "\tNumber of samples: 12500\n",
            "\tName of the first file: 11657_9.txt\n",
            "\tContent of a random sample: It's really rare that you get an inside view at a media deception that has been so widely reported as official \"truth\" and caught so many \"news\" agencies with their pants down. This movie, in my view, deserves every price there is in journalism - it's objective (yes!), courageous and a real \"scoop\". It can do without comment, fake scenes or leading questions - everyone, including Chavez equally gets to make fools of themselves in their own words. The filmmakers \"only\" had to keep track of events and keep their cameras rolling.<br /><br />The Venezuelan elite teaches us \"How to depose of a President and sell it as a victory of democracy\". It's amazing that they lost in the end - so far. From what I know, the biggest TV station involved only got its terrestrial license revoked, they're still broadcasting via cable and satellite. I highly doubt whether George W. or Barack Obama would be that tolerant after an attempted coup. But then, they don't have to worry.<br /><br />The fact that the \"Chavez supporters shoot innocent civilians\" scam was so willingly repeated around the world reveals just how biased the so-called \"free\" (established) media really has become, or has always been, only more so. An important lesson to anyone interested in what \"really\" goes on in the world.<br /><br />The famous \"objectivity\" challenge always comes into play when journalists dare to oppose the mainstream view, or reveal unwelcome facts that accuse \"us\" - it has been true with the effects of the Atomic bomb, the US secret history of spreading \"democracy\" around the world or the Iraq war that, according to Johns Hopkins, has killed 1,3 million Iraquis by now, not to mention the 60,000 Afghans (in 2003) that are never mentioned. To be objective, Saddam Hussein was less damaging to his people than the US. And the US is ready & willing to be more damaging to the Iranians that he was.<br /><br />I'm quite curious about the upcoming trial of some Khmer Rouge leaders before the International Tribunal in The Hague, whether there will be any mention of \"our\" involvement in supporting and training Pol Pot's guerrillas in the 80's, when they had been largely defeated by the Vietnamese. Probably not.<br /><br />All the more reason to turn to the Independent media for balance, if not exposure of fraud.\n",
            "\n",
            "Directory: train - Class: neg\n",
            "\tNumber of samples: 12500\n",
            "\tName of the first file: 2266_1.txt\n",
            "\tContent of a random sample: My wife and I rented this movie because some people had drawn parallels between it and \"Office Space\". Blockbuster and IMDB even had it as an \"also recommended\" selection if you liked \"Office Space\".<br /><br />Now, I've seen Office Space probably 15 or 20 times. I love it. It's probably one of my 10 favorite movies. Witty, humorous, and featuring characters that remind me of people I've worked with over the years. \"Haiku Tunnel\" is similar to \"office Space\" in that they are both films. That's where the similarity ends. We sat through probably the first 50 minutes of HT, giving it the benefit of the doubt, hoping, nay, *praying* that it would get better. It didn't. We couldn't take it any more, and stopped the tape. Thank GOD it was a free rental. I'd have been p***ed if we'd actually paid for it. We should be reimbursed for having to sit through it. Now, since we didn't see the end, perhaps it miraculously comes together and redeems itself. I doubt it.<br /><br />Haiku Tunnel is so bad it's hard to believe it ever got produced. The movie is SO unfunny it's painful. Just mail the friggin letters already!!! The premise is asinine. The jokes are awful. We got as far as the \"printer doesn't work\" scene and had to stop. We couldn't take it anymore. This film is an EMBARRASMENT for Josh Kornbluth.<br /><br />If you are a fan of Office Space......don't waste your time with this turd. 0/10\n",
            "\n",
            "Directory: test - Class: pos\n",
            "\tNumber of samples: 12500\n",
            "\tName of the first file: 8145_9.txt\n",
            "\tContent of a random sample: If you're a fan of Turkish and Middle Eastern music, you're in great luck. This film is a documentary of current music in Istanbul, spanning the traditional to the modern. It's very good. You could not do better if you went to Istanbul yourself. We get interviews with Orhan Gencebay, concert clips of modern musical icons, a road show with a Romani (Gypsy) audience, Turkish Hip Hop (surprisingly very very good), and much much more. Some of the best female vocalists I've ever heard. A Kurdish woman singing in a hamam (steam bath) who will rip your heart out. Lots of social and political background. If this is your thing, you'll have a grand time. I could barely sit still in the theatre.<br /><br />CD soundtrack now available on amazon. Pricey.\n",
            "\n",
            "Directory: test - Class: neg\n",
            "\tNumber of samples: 12500\n",
            "\tName of the first file: 932_2.txt\n",
            "\tContent of a random sample: The most generic, surface-level biography you could hope for. Busey's impersonation of Holly is accurate -- but who wants to hear Gary Busey sing \"Maybe Baby\"? Typically, the members of the Hollies are used for comic relief and melodrama (Smith and Stroud, respectively) instead of as people or even characters. When Holly uses a string section, the old jewish-looking guys who come in tell him he's using the same techniques as Mozart. It's just this kind of cheeky statement that makes film biographies like this (and \"Amadeus\", about the aforementioned Mozart) so worthless. Some entertainment can be derived from Holly's excellent styles and songs done in a B-variation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** The training datasets have equal positive and negative samples, indicating class balance."
      ],
      "metadata": {
        "id": "tezg_Axw7mmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the unnecessary unsup directory and all of its contents (subdirectories and files) within the aclImdb/train directory.\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "bt3DlzlKIcZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we undertake the creation of a validation dataset, a crucial step for evaluating machine learning model performance on unseen data during training. We start by defining paths for the training and test directories within the base directory. Next, we establish the validation directory, complete with sub-directories for positive and negative classes, ensuring their presence even if already existing. We then determine the number of validation samples by aggregating the counts of positive and negative training samples and allocating ten percent of this total for validation. Using the move_files function, we transfer the calculated number of files from the training directory to the validation directory, organizing positive and negative samples accordingly. Finally, we employ the get_info function to display updated file counts, the name of the first file, and the content of a random file in both the training and validation directories post-transfer, ensuring the creation of a validation dataset essential for assessing model generalization."
      ],
      "metadata": {
        "id": "HeW9JT0kxNf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths of the train and test directories respectively.\n",
        "train_dir = base_dir / 'train'\n",
        "test_dir = base_dir / 'test'\n",
        "\n",
        "# Create the val directory.\n",
        "os.makedirs(base_dir / 'val' / 'pos', exist_ok=True)\n",
        "os.makedirs(base_dir / 'val' / 'neg', exist_ok=True)\n",
        "\n",
        "# Set the path of the val directory.\n",
        "val_dir = base_dir / 'val'"
      ],
      "metadata": {
        "id": "l3aIaNtPKDRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_files_train = num_files_train_pos + num_files_train_pos\n",
        "num_val_samples = int(num_files_train * 0.1)\n",
        "num_val_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkQKu-FGN7JB",
        "outputId": "7eb66db7-5872-43c7-a80c-50c2ba105ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "move_files(file_names_train_pos, num_val_samples, 'pos')\n",
        "move_files(file_names_train_neg, num_val_samples, 'neg')"
      ],
      "metadata": {
        "id": "dPLsJM61TBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use get_info() function to display the count of files, the name of the first file, and the content of a random file for train and val after moving the files.\n",
        "_, _ = get_info('train', 'pos')\n",
        "_, _ = get_info('train', 'neg')\n",
        "_, _ = get_info('val', 'pos')\n",
        "_, _ = get_info('val', 'neg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE3tiacFUypH",
        "outputId": "644d34e0-f363-4a10-8afe-76bcd0766fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory: train - Class: pos\n",
            "\tNumber of samples: 10000\n",
            "\tName of the first file: 11657_9.txt\n",
            "\tContent of a random sample: I am amazed that movies like this can still be made. I watch all kinds of movies all the time with my friends and i can say that this is one of the best i ever seen. Never thinked that a movie of 146 minutes can make me think about it on and on.<br /><br />Washington, charismatic and intense as ever, plays Creasy, a washed-up ex-counter-terrorist agent who's taken to the bottle. Once he's assigned to protect young Pita (Dakota Fanning) in Mexico City, his emotional and redemptive arc is jump-started in the way only an adorable little girl can provide. Inevitably, Pita is kidnapped by thugs, and Creasy decides that most of Mexico City must pay the price for daring to take away his character's teddy-bear-clutching catalyst. Yes, he has become...a Man on Fire. <br /><br />You must see this movie.\n",
            "\n",
            "Directory: train - Class: neg\n",
            "\tNumber of samples: 10000\n",
            "\tName of the first file: 2266_1.txt\n",
            "\tContent of a random sample: I love Westerns. I could watch them all day. \"The Good, the Bad, and the Ugly\" is my all time favorite. I watched \"Silverado\" for probably the 8th time just the other day because it was being featured on CMT. However, this movie, Shiloh Falls is without a doubt the worst Western I have ever watched. The acting was terrible all around. They explain nothing at the end of the mysterious compass looking thing. The only good part I can think of is the good-looking cantina girl. The very noticeable long pauses between the dialog seemed intentional just to make up time to make the movie of acceptable length. This movie wasn't even worth the new rental fee I paid at our local movie rental store. I felt like I was robbed and deserving of a rental refund if there was such a thing. Only reason I finished it was because I hate to not see a movie through to the end. I turned it off half way through because it was so bad. To the director, please do a better job if you decide to make another. This is the kind of movie that has the potential to turn people off to Westerns.\n",
            "\n",
            "Directory: val - Class: pos\n",
            "\tNumber of samples: 2500\n",
            "\tName of the first file: 4920_7.txt\n",
            "\tContent of a random sample: Just got through watching this version of \"Samhain\", and even though I still like it, it's nothing like the \"rough cut\" version I have. If you check the message board, you'll see an apology from the director for this cut down version, 79 minutes., and he says he had nothing to do with this R-rated trimmed down edit with a completely new screwed up ending. Christian really doesn't need to distant himself that much, because the basic gore elements still stand up, even though highly trimmed down. This is a damn shame, because this had the potential of being one of the goriest and best gore films in years. It still has the porn stars, and the inbreds, and some of the extreme gore can at least be partially seen. I'm just glad I have that \"rough cut\", because to me, it's a jewel for any gorehounds library. Christian Viel definitely has the skill and vision to deliver the goods, and hopefully his next project will be better produced. The idiots had a near classic in their hands, and screwed it up for everybody. \"Samhain\" may be one of the most controversial and mishandled horror movies ever, and too bad gorehounds didn't get to see what the director intended.<br /><br />********************************************* Just so you know what you missed, this is my review based upon the \"work print\" of SAMHAIN.<br /><br />The movie runs a little over 90 minutes and has no chapter stops. There is absolutely NO music soundtrack, and some of the scenes have no audio on the dialog, because I think they are meant to be looped in later. However, most of the movie does have audio with sound affects, and when an effect or scene is missing, a message appears as a cue for insertion when the movie is completed. It's exactly as it says, a \"Rough Cut\", BUT the only uncut version of \"Samhain\" you are ever likely to see. Reason, because the gore is extremely graphic, much more than even an NC-17 would allow. Yes there are a few porn stars, but they are just there for the killing, and to add a little sugar and spice. The story is pretty standard, American tourists on a vacation in Ireland and end up staying in a home in the middle of the woods. An area that is heavy on folklore, involving the ancient Druids and the celebration of Samhain, or as we call it Halloween. (spooky)<br /><br />The movie starts off with a HUGE dose of gore, as a camping couple is attacked by one of the local inbred mutants. This is a great gore scene, as the guy find his girl hanging from a cliff, with her crying for help. All he sees is her head, arms, and shoulders hanging in front of him and when he pulls her up, she has been completely sliced in two. This is what I would call EXTREME GORE, with entrails, blood, and severed limbs all over the place. We are in Herschell Gordon Lewis territory here folks, except the effects look much more realistic. I'm going to just skip the story, because it's your standard stalk and kill plot.<br /><br />The next gore scene is something to behold, as the boyfriend from the first killing is taken to a cave like location (TCM-2 stuff), and bound to a table. This geek then cuts all of his limbs off (off camera, with a cue to insert a scene), and then we see his torso on a barbecue pit, turning slowly over a fire, and the torso has a hard-on (if you can believe that). Yes, very bad taste, gross, gruesome, you find the right word, and it will probably fit too.<br /><br />Then later Jenna Jameson, her beautiful body and all, is cut from neck to crotch, and all her entrails are pulled out in graphic glee, and her blood drains into a pot. Yummy, a real turn on huh?<br /><br />But the best gore scene happens inside the house, and I have to admit, this is one of the best gore scenes I have seen. This guy (doesn't matter who) is caught from behind from a geek, and cut open at the ass hole. The geek then puts his hands in and rips out all the guys entrails, intestines, and what the hell ever else there is, right from his asshole. This goes on FOREVER, as the guy is screaming and more and more innards are pulled out laying all over the bathroom floor. This is so extreme, so over the top, that I found myself laughing all to hell. Obviously, you will NEVER EVER see this scene on a proper DVD, IMO, along with most of the other really extreme gore scenes.<br /><br />So, what to think of all of this. Well, first of all, even though I doubt this movie would ever be released in this totally uncut presentation, it makes this \"Rough Cut\" a rare jewel for gorehounds. Yes, it's a little difficult at first, with no soundtrack, a few scenes to still be inserted, and credits that have missing names all over the place. But that's what makes this so unique, and I wouldn't trade it for anything right now. Extreme gore, yes yes, extreme extreme gore. This makes \"Haute Tension\" look like a Disney movie.\n",
            "\n",
            "Directory: val - Class: neg\n",
            "\tNumber of samples: 2500\n",
            "\tName of the first file: 6857_4.txt\n",
            "\tContent of a random sample: I will admit that I did not give this movie much of a chance. I decided pretty early on that this just wasn't my kind of movie.<br /><br />For the most part, it has an excellent look in terms of its cinematography. The scenes of early 70's Manhattan look very good, as does the lead actress. It is a very crisp black and white, which could almost make the movie feel undated and fresh. However, some of the other techniques the filmmakers employ shoot that prospect all to hell. The disjointed editing is VERY late-60's, somewhere between surrealism and new wave. The story also feels like it came from a very specific time, somewhere between free love idealism and artsy experimentation.<br /><br />The film follows a young girl around the city as she looks for a man who she had anonymous phone sex with. As she meets other odd characters, she reveals her quirks and they reveal theirs. The movie seems to be meant as an off-the-wall, irreverent comedy, but adds an avant-garde feel. I would expect that if you like Andy Warhol movies, you would be very excited to discover The Telephone Book.<br /><br />Some problems I had: Near the end of the movie, one character tells a rambling anecdote that lasts over twelve minutesÂ—-brutal to sit through. Also, there is a very explicit animation sequence that I found gross and juvenile that serves as the film's climax. I did laugh out loud four or five times, and I liked the ending (minus the flat-out disgusting animation). And when the film switched to color for the final phone-booth-at-night sequence, I actually liked the way it looked even better. It ended up being one of those experiences where I felt like I could have really liked it if it been a little different. But this is what the filmmakers gave us. It is obscure, artsy, and way left of the dial, but none of those are reasons to recommend it on their own. I didn't find it to be unique or creative so much as forced and pretentious.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets Batch Creation\n",
        "\n",
        "---\n",
        "In this section, we create batched datasets for training, validation, and testing using TensorFlow's text_dataset_from_directory function. This process is essential for efficiently handling and feeding data into machine learning models.\n",
        "\n",
        "First, we define the batch size for the datasets, setting it to 32. This means that each batch will contain 32 samples. Next, we load the training dataset from the specified directory. The text_dataset_from_directory function is used to load the dataset from the 'train' directory, with the specified batch size.\n",
        "\n",
        "We then load the validation dataset. Similarly, the validation dataset is loaded from the 'val' directory, also using the specified batch size. Lastly, we load the test dataset. The test dataset is loaded from the 'test' directory, following the same procedure.\n",
        "\n",
        "To ensure the datasets are correctly loaded and structured, we use the get_info_from_ds function to display information about the training and validation datasets. This function prints the shape and data type of the inputs and targets, as well as the first input and target sample for both the training and validation datasets.\n",
        "\n",
        "By following these steps, we successfully create and batch the datasets, which are now ready for use in training, validating, and testing our machine learning models.\n"
      ],
      "metadata": {
        "id": "JgTKmjlYxUJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.utils import text_dataset_from_directory\n",
        "\n",
        "# Define the batch size for the dataset\n",
        "batch_size = 32\n",
        "\n",
        "# Load the training dataset from the specified directory\n",
        "train_ds = text_dataset_from_directory(\n",
        "    '/content/aclImdb/train',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load the validation dataset from the specified directory\n",
        "val_ds = text_dataset_from_directory(\n",
        "    '/content/aclImdb/val',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load the test dataset from the specified directory\n",
        "test_ds = text_dataset_from_directory(\n",
        "    '/content/aclImdb/test',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSrHGpW5VUs4",
        "outputId": "ffe483c6-2aed-447a-ca0a-619cfcae6212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_info_from_ds(train_ds, 'Train')\n",
        "get_info_from_ds(val_ds, 'Val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOdg78UMXsPy",
        "outputId": "4b22e70e-591c-4d01-d95a-0b45e28b784d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "\tinputs.shape: (32,)\n",
            "\tinputs.dtype: <dtype: 'string'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(b'I thought the original of this film was quaint and charming as well as having me sitting on the edge of my seat trying to figure it out.<br /><br />Since I had already seen the original, when I saw this on Sci Fi Channel- I don\\'t know if this remake was deliberately made for Sci Fi - I knew what it was within the first few minutes. Since I like Richard Burgi as a character actor, I wanted to see how he would pull it off.<br /><br />The writers/producers etc, modernized the film a bit by trying to explain the plight of the \"aliens\" (They could no longer reproduce their own kind and needed help) using the same pseudo science that has been crammed in our ears in the 90\\'s. Maybe it added a bit of polish to the film, or not.<br /><br />This film. Film? This production takes on a more sinister edge than the original did- The original ended with a confrontation between the young woman and the alien and an understanding of sorts took place, although no resolution of the Alien\\'s problem.<br /><br />I sort of remember that in this remake, the woman became rather hostile towards the Burgi/Alien- I think it could have ended better. But the ending is just the ending, and the yarn is a swell yarn, being of the basic 1958 Science Fiction Pulp Stock. Many great science fiction stories were written in the 50\\'s and some of them even made it to film.<br /><br />This is a swell thing to watch on like a rainy day or something. I rate it highly cos of all the remakes of old 50\\'s Sci Fi, this one came off well. I actually enjoyed this quite a bit.<br /><br />But if anyone really wants to see this story told WELL, I suggest the original 1958 version with Tom Tyron and Gloria Talbott, directed by Gene Fowler Jr.', shape=(), dtype=string)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n",
            "Val\n",
            "\tinputs.shape: (32,)\n",
            "\tinputs.dtype: <dtype: 'string'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(b'Jesse and Celine (Ethan Hawke and Julie Delpy) are two strangers on a European train. The two come from widely different backgrounds, he\\'s American and she\\'s French, after they talk a bit on the train Jesse manages to get Celine to get off the train and explore Vienna with him. During the next several hours the two wander Vienna taking in all that the city has to offer and become madly infatuated with each other. But will this newfound relationship last past sunrise.<br /><br />This wonderful romantic-comedy is a breath of fresh air to a genre that has been in decline. Written and directed by Richard (Dazed and Confused) Linklater, \"Before Sunrise\" never bores because of its\\' small cast. In fact it flourishes due to the leads that make you love their characters and have a wonderful charisma between the two. Smart dialogue makes this a must for romance fans.', shape=(), dtype=string)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consideration for Model Selection"
      ],
      "metadata": {
        "id": "Z3UpDgSRxc3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When to use a Sequence Model over Bag-of-Words Model**\n",
        "\n",
        "---\n",
        "Before proceeding with model selection, it's crucial to understand the characteristics of the dataset.\n",
        "\n",
        "First, we determine the total number of training samples by counting the files in both the 'positive' and 'negative' classes. Next, we calculate the total number of words across all samples and computing the mean number of words per sample.\n",
        "\n",
        "If the ratio between the number of samples in the training data and the average number of words per sample is less than 1500, then a bag-of-words model will perform better. Conversely, if the ratio is greater than 1500, a sequence model will perform better.\n",
        "\n",
        "In a bag-of-words model, word order is discarded, while order is considered in a sequence model. A third alternatie, the Transformer architecture presents a hybrid approach.\n",
        "\n",
        "*This heuristic rule is based on a systematic analysis of the performance of various text classification techniques across many different types of text datasets by Francois Chollet in 2017.*\n"
      ],
      "metadata": {
        "id": "5KnLjzZxcDly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname_pos = os.listdir('/content/aclImdb/train/pos')\n",
        "fname_neg = os.listdir('/content/aclImdb/train/neg')\n",
        "\n",
        "# Count of files\n",
        "num_train_samples = len(fname_pos + fname_neg)\n",
        "num_train_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TNO-Jt1a5us",
        "outputId": "d07fe0d1-5802-4d2a-c23e-c7e8d769bae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = analyze_text_samples('/content/aclImdb/train/pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhENpLiHhJ9w",
        "outputId": "a6c7a8e2-9169-40a4-dade-6ca73c80a41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in all the sampples: 2369499\n",
            "Mean words per sample: 118.47495\n",
            "Ratio of number per training samples / mean words per samples: 168.81205689472753\n",
            "\n",
            "\n",
            "Bag-of-words model might perform better on this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top 100 Words by Frequency\n",
        "\n",
        "---\n",
        "\n",
        "This section contains a visualization of the top 100 words by frequency. The words are categorized into four groups, each representing a range of word frequencies: the first group contains the top 30 words, the second group contains words ranked from 31 to 60, the third group contains words ranked from 61 to 90, and the fourth group consists of the remaining words, from 91 to 100. By examining these word frequencies, we gain insights into the distribution of language patterns within the dataset."
      ],
      "metadata": {
        "id": "QkkNmr95tOyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Create a translation table to remove punctuation\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "# Initialize an empty dictionary to store word frequencies\n",
        "words_dict = {}\n",
        "\n",
        "# Iterate over each list of words in the 'words' variable\n",
        "for list_words in words:\n",
        "    # Iterate over each word in the current list of words\n",
        "    for word in list_words:\n",
        "        # Strip leading and trailing whitespace, convert to lowercase\n",
        "        word = word.strip().lower()\n",
        "        # Remove punctuation from the word using the translation table\n",
        "        word = word.translate(translator)\n",
        "        # If the word is already in the dictionary, increment its count\n",
        "        if word in words_dict:\n",
        "            words_dict[word] += 1\n",
        "        # If the word is not in the dictionary, add it with a count of 1\n",
        "        else:\n",
        "            words_dict[word] = 1\n",
        "\n",
        "# Sort the dictionary by word frequency in descending order\n",
        "sorted_words_dict = dict(sorted(words_dict.items(), key=lambda x: x[1], reverse=True))"
      ],
      "metadata": {
        "id": "lJ5sxzLth20n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_30 = list(sorted_words_dict.keys())[:30]\n",
        "top_30_freq = list(sorted_words_dict.values())[:30]\n",
        "\n",
        "top_31_60 = list(sorted_words_dict.keys())[31:60]\n",
        "top_31_60_freq = list(sorted_words_dict.values())[31:60]\n",
        "\n",
        "top_61_90 = list(sorted_words_dict.keys())[61:90]\n",
        "top_61_90_freq = list(sorted_words_dict.values())[61:90]\n",
        "\n",
        "top_91_100 = list(sorted_words_dict.keys())[91:100]\n",
        "top_91_100_freq = list(sorted_words_dict.values())[91:100]\n",
        "\n",
        "fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(20, 18))\n",
        "\n",
        "ax[0].bar(top_30, top_30_freq)\n",
        "ax[0].set_title('Top 30 Words')\n",
        "\n",
        "ax[1].bar(top_31_60, top_31_60_freq)\n",
        "ax[1].set_title('Top 31-60 Words')\n",
        "\n",
        "ax[2].bar(top_61_90, top_61_90_freq)\n",
        "ax[2].set_title('Top 30 Words')\n",
        "\n",
        "ax[3].bar(top_91_100, top_91_100_freq)\n",
        "ax[3].set_title('Top 31-60 Words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sTQ16Fj6nj6H",
        "outputId": "dd6605df-947e-42b8-c35e-d1e025adbe93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Top 31-60 Words')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1800 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABmAAAAWsCAYAAAA+P0wTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVwW9f7//+eFyKYCogmSCmSKmqSpqaC5RaKSSWmpWVmRnEoycyk9mWnL0dyXXLI+aZ2j5bHcjhpKmrkRKmouuVWuKVgqELjD/P7ox3y9BBFs4AJ93G+363bzmnnNzOt9Odf6ZGZshmEYAgAAAAAAAAAAgGWcHN0AAAAAAAAAAADArYYABgAAAAAAAAAAwGIEMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAABuQc8++6wCAwMd3QYAAABw2yKAAQAAAGAZm81WoNvatWuLtI/z588rOjpa9evXl5eXl8qXL68GDRpo8uTJunz5cq761NRUxcTE6I477lC5cuXUtm1bbdu27Ybb6dSpkypWrCjDMOymb9++XTabTQEBAbmWWbNmjWw2m2bNmnXzAwQAAABQ4jk7ugEAAAAAt45///vfdvc///xzxcfH55pet27dIu3j/Pnz2rNnjzp16qTAwEA5OTlp06ZNeu2115SYmKh58+aZtdnZ2YqMjNSPP/6owYMHq3Llypo+fbratGmjpKQk1apV67rbadmypb755hvt3r1bISEh5vSNGzfK2dlZR48e1fHjx1WtWjW7eTnLAgAAALh1EcAAAAAAsMxTTz1ld/+HH35QfHx8rulFzcfHRz/88IPdtBdffFFeXl768MMPNWHCBPn5+UmSvvrqK23atEkLFixQt27dJElPPPGEateurbffftsurLlWToiyYcOGXAFMp06dtGbNGm3YsEE9evQw523YsEGVKlX62yHUhQsX5OLiIicnTmwAAAAAlER8UgcAAABQrDIzMzVw4EBVr15drq6uCg4O1rhx43Kdxstmsyk2NlZz585VcHCw3Nzc1LhxY61bt+6mt51zTZTU1FRz2ldffSVfX1899thj5rQ77rhDTzzxhJYsWaKLFy9ed31NmzaVi4uLeVRLjo0bN6pVq1Zq2rSp3bzs7Gz98MMPCgsLk81mkyT9+uuvevzxx+Xj4yMPDw81b95cy5cvt1vf2rVrZbPZ9OWXX2rYsGG688475eHhofT0dEnS4sWLVb9+fbm5ual+/fpatGhRnv1++eWXaty4sSpUqCBPT0+FhIRo8uTJN37gAAAAABQaR8AAAAAAKDaGYeiRRx7Rd999p+joaDVs2FArV67U4MGD9dtvv2nixIl29d9//73mz5+vfv36ydXVVdOnT1eHDh20efNm1a9f/4bbu3TpktLT03X+/Hlt3bpV48aNU0BAgO6++26zZvv27WrUqFGuI0maNm2qWbNm6cCBA3ZHt1wtJxTasGGDOe3YsWM6duyYwsLClJqaahem7Nq1S+np6eaRMykpKQoLC9O5c+fUr18/VapUSZ999pkeeeQRffXVV3r00Ufttvfuu+/KxcVFgwYN0sWLF+Xi4qJVq1apa9euqlevnkaNGqXTp0/rueeeszvtmSTFx8erZ8+eevDBB/XBBx9Ikvbu3auNGzfq1VdfveFjCQAAAKBwCGAAAAAAFJulS5dqzZo1eu+99/Tmm29Kkvr27avHH39ckydPVmxsrGrWrGnW7969W1u3blXjxo0lST169FBwcLCGDx+uhQsX3nB7CxcuVM+ePc37TZo00aeffipn5//3VejkyZNq1apVrmWrVq0qSTpx4sR1Axjpr9OQjR07Vr/99pvuvPNObdy40QxmUlNTNWrUKP3555+qUKGCGdTkBDCjR49WSkqK1q9fb07r06eP7r33Xg0YMEBdunSxC4YuXLigrVu3yt3d3Zz2xhtvyNfXVxs2bJCXl5ckqXXr1mrfvr0CAgLMuuXLl8vT01MrV65UmTJlbvjYAQAAAPh7OAUZAAAAgGKzYsUKlSlTRv369bObPnDgQBmGoW+++cZuemhoqBm+SFKNGjXUpUsXrVy5UllZWTfcXtu2bRUfH68FCxboxRdfVNmyZZWZmWlXc/78ebm6uuZa1s3NzZyfn5zgZP369ZL+Ov1Y48aN5eLiotDQUPO0Yznz3Nzc1KRJE/PxaNq0qbkOSSpfvrxiYmJ0+PBh/fTTT3bb6t27t134cvLkSe3YsUO9e/c2wxdJeuihh1SvXj27Zb29vZWZman4+Ph8xwMAAADAGgQwAAAAAIrNkSNH5O/vrwoVKthNz7kg/ZEjR+ym16pVK9c6ateurXPnzun333+/4fZ8fX0VHh6ubt26acaMGXr44Yf10EMPKTk52axxd3fP8zovFy5cMOfnp0WLFrLZbOa1XjZu3KgWLVpI+iv0qFevnt28+++/Xy4uLuZ4g4ODc63zeo9HUFCQ3f2c+Xk9Tteu9+WXX1bt2rXVsWNHVatWTc8//7zi4uLyHRsAAACAm0cAAwAAAOC20a1bN2VkZGjJkiXmtKpVq+rkyZO5anOm+fv757vOSpUqqU6dOtqwYYMyMjK0c+dOhYWFmfPDwsK0YcMGHT9+XEePHrU72qWwbhQG5adKlSrasWOHli5dal6Hp2PHjurdu/dNrxMAAADA9RHAAAAAACg2AQEBOnHihP7880+76fv27TPnX+3gwYO51nHgwAF5eHjojjvuKPT2c04nlpaWZk5r2LChtm3bpuzsbLvaxMREeXh4qHbt2jdcb8uWLbVr1y6tWrVKWVlZuQKYxMRErV271qzNERAQoP379+da3/Uej2vlzM/rccprvS4uLurcubOmT5+uX375Rf/4xz/0+eef6+eff77hGAEAAAAUDgEMAAAAgGLTqVMnZWVl6cMPP7SbPnHiRNlsNnXs2NFuekJCgrZt22beP3bsmJYsWaL27dvneyH5P/74Q4Zh5Jr+ySefSJJ5DRbpr6NiUlJStHDhQrvlFyxYoM6dO+d5fZhrtWzZUllZWRo3bpxq1aplFw6FhYUpIyND06dPl5OTk10406lTJ23evFkJCQnmtMzMTM2aNUuBgYG5ruNyrapVq6phw4b67LPP7EKl+Pj4XNePOX36tN19Jycn3XvvvZKU5ynYAAAAAPw9zo5uAAAAAMDto3Pnzmrbtq3efPNNHT58WA0aNNCqVau0ZMkS9e/fXzVr1rSrr1+/viIiItSvXz+5urpq+vTpkqSRI0fmu53//Oc/mjlzpqKionTXXXfpzz//1MqVKxUfH6/OnTurXbt2Zm23bt3UvHlzPffcc/rpp59UuXJlTZ8+XVlZWTfcTo6co1oSEhL07LPP2s2rXbu2KleurISEBIWEhMjb29ucN2TIEH3xxRfq2LGj+vXrJx8fH3322Wc6dOiQvv76azk53fhv5kaNGqXIyEi1bNlSzz//vM6cOaOpU6fqnnvuUUZGhln3wgsv6MyZM2rXrp2qVaumI0eOaOrUqWrYsKF5zRkAAAAA1iGAAQAAAFBsnJyctHTpUg0fPlzz58/X7NmzFRgYqLFjx2rgwIG56lu3bq3Q0FCNHDlSR48eVb169TRnzhzzyI3radmypTZt2qQvvvhCKSkpcnZ2VnBwsCZMmKBXXnnFrrZMmTJasWKFBg8erClTpuj8+fO6//77NWfOnFwXsr+eu+66S/7+/jpx4oTdES45wsLCtHTp0lzXf/H19dWmTZv0xhtvaOrUqbpw4YLuvfde/e9//1NkZGSBtt2hQwctWLBAw4YN09ChQ1WzZk3Nnj1bS5YsMU97JklPPfWUZs2apenTpys1NVV+fn7q3r27RowYUaCgBwAAAEDh2Iy8jssHAAAAAAez2Wzq27dvrtOVAQAAAEBpwJ85AQAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABZzdnQDAAAAAJAXLlcJAAAAoDTjCBgAAAAAAAAAAACLEcAAAAAAAAAAAABYjFOQ5SM7O1snTpxQhQoVZLPZHN0OAAAAAAAAAABwIMMw9Oeff8rf319OTvkf40IAk48TJ06oevXqjm4DAAAAAAAAAACUIMeOHVO1atXyrSGAyUeFChUk/fVAenp6OrgbAAAAAAAAAADgSOnp6apevbqZH+SHACYfOacd8/T0JIABAAAAAAAAAACSVKDLluR/gjIAAAAAAAAAAAAUGgEMAAAAAAAAAACAxQhgAAAAAAAAAAAALFboAGbdunXq3Lmz/P39ZbPZtHjx4uvWvvjii7LZbJo0aZLd9DNnzqhXr17y9PSUt7e3oqOjlZGRYVezc+dOPfDAA3Jzc1P16tU1ZsyYXOtfsGCB6tSpIzc3N4WEhGjFihV28w3D0PDhw1W1alW5u7srPDxcBw8eLOyQAQAAAAAAAAAACqXQAUxmZqYaNGigadOm5Vu3aNEi/fDDD/L39881r1evXtqzZ4/i4+O1bNkyrVu3TjExMeb89PR0tW/fXgEBAUpKStLYsWM1YsQIzZo1y6zZtGmTevbsqejoaG3fvl1RUVGKiorS7t27zZoxY8ZoypQpmjlzphITE1WuXDlFRETowoULhR02AAAAAAAAAABAgdkMwzBuemGbTYsWLVJUVJTd9N9++03NmjXTypUrFRkZqf79+6t///6SpL1796pevXrasmWLmjRpIkmKi4tTp06ddPz4cfn7+2vGjBl68803lZycLBcXF0nSkCFDtHjxYu3bt0+S1L17d2VmZmrZsmXmdps3b66GDRtq5syZMgxD/v7+GjhwoAYNGiRJSktLk6+vr+bMmaMePXrccHzp6eny8vJSWlqaPD09b/ZhAgAAAAAAAAAAt4DC5AaWXwMmOztbTz/9tAYPHqx77rkn1/yEhAR5e3ub4YskhYeHy8nJSYmJiWZNq1atzPBFkiIiIrR//36dPXvWrAkPD7dbd0REhBISEiRJhw4dUnJysl2Nl5eXmjVrZtZc6+LFi0pPT7e7AQAAAAAAAAAAFJblAcwHH3wgZ2dn9evXL8/5ycnJqlKlit00Z2dn+fj4KDk52azx9fW1q8m5f6Oaq+dfvVxeNdcaNWqUvLy8zFv16tVvOF4AAAAAAAAAAIBrWRrAJCUlafLkyZozZ45sNpuVqy4WQ4cOVVpamnk7duyYo1sCAAAAAAAAAAClkKUBzPr163Xq1CnVqFFDzs7OcnZ21pEjRzRw4EAFBgZKkvz8/HTq1Cm75a5cuaIzZ87Iz8/PrElJSbGrybl/o5qr51+9XF4113J1dZWnp6fdDQAAAAAAAAAAoLAsDWCefvpp7dy5Uzt27DBv/v7+Gjx4sFauXClJCg0NVWpqqpKSkszl1qxZo+zsbDVr1sysWbdunS5fvmzWxMfHKzg4WBUrVjRrVq9ebbf9+Ph4hYaGSpKCgoLk5+dnV5Oenq7ExESzBgAAAAAAAAAAoCg4F3aBjIwM/fzzz+b9Q4cOaceOHfLx8VGNGjVUqVIlu/qyZcvKz89PwcHBkqS6deuqQ4cO6tOnj2bOnKnLly8rNjZWPXr0kL+/vyTpySef1MiRIxUdHa033nhDu3fv1uTJkzVx4kRzva+++qpat26t8ePHKzIyUl9++aW2bt2qWbNmSZJsNpv69++v9957T7Vq1VJQUJDeeust+fv7KyoqqtAPFAAAAAAAAAAAQEEVOoDZunWr2rZta94fMGCAJKl3796aM2dOgdYxd+5cxcbG6sEHH5STk5O6du2qKVOmmPO9vLy0atUq9e3bV40bN1blypU1fPhwxcTEmDVhYWGaN2+ehg0bpn/+85+qVauWFi9erPr165s1r7/+ujIzMxUTE6PU1FS1bNlScXFxcnNzK+ywkYfAIcsd3UKeDo+OdHQLAAAAAAAAAIDbnM0wDMPRTZRU6enp8vLyUlpaGteDyQMBDAAAAAAAAADgdlKY3MDSa8AAAAAAAAAAAACAAAYAAAAAAAAAAMByBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALEYAAwAAAAAAAAAAYDECGAAAAAAAAAAAAIsRwAAAAAAAAAAAAFiMAAYAAAAAAAAAAMBiBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALEYAAwAAAAAAAAAAYDECGAAAAAAAAAAAAIsRwAAAAAAAAAAAAFiMAAYAAAAAAAAAAMBiBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALEYAAwAAAAAAAAAAYDECGAAAAAAAAAAAAIsRwAAAAAAAAAAAAFiMAAYAAAAAAAAAAMBiBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALFboAGbdunXq3Lmz/P39ZbPZtHjxYnPe5cuX9cYbbygkJETlypWTv7+/nnnmGZ04ccJuHWfOnFGvXr3k6ekpb29vRUdHKyMjw65m586deuCBB+Tm5qbq1atrzJgxuXpZsGCB6tSpIzc3N4WEhGjFihV28w3D0PDhw1W1alW5u7srPDxcBw8eLOyQAQAAAAAAAAAACqXQAUxmZqYaNGigadOm5Zp37tw5bdu2TW+99Za2bdumhQsXav/+/XrkkUfs6nr16qU9e/YoPj5ey5Yt07p16xQTE2POT09PV/v27RUQEKCkpCSNHTtWI0aM0KxZs8yaTZs2qWfPnoqOjtb27dsVFRWlqKgo7d6926wZM2aMpkyZopkzZyoxMVHlypVTRESELly4UNhhAwAAAAAAAAAAFJjNMAzjphe22bRo0SJFRUVdt2bLli1q2rSpjhw5oho1amjv3r2qV6+etmzZoiZNmkiS4uLi1KlTJx0/flz+/v6aMWOG3nzzTSUnJ8vFxUWSNGTIEC1evFj79u2TJHXv3l2ZmZlatmyZua3mzZurYcOGmjlzpgzDkL+/vwYOHKhBgwZJktLS0uTr66s5c+aoR48eNxxfenq6vLy8lJaWJk9Pz5t9mG5ZgUOWO7qFPB0eHenoFgAAAAAAAAAAt6DC5AZFfg2YtLQ02Ww2eXt7S5ISEhLk7e1thi+SFB4eLicnJyUmJpo1rVq1MsMXSYqIiND+/ft19uxZsyY8PNxuWxEREUpISJAkHTp0SMnJyXY1Xl5eatasmVkDAAAAAAAAAABQFJyLcuUXLlzQG2+8oZ49e5pJUHJysqpUqWLfhLOzfHx8lJycbNYEBQXZ1fj6+przKlasqOTkZHPa1TVXr+Pq5fKqudbFixd18eJF8356enqhxgsAAAAAAAAAACAV4REwly9f1hNPPCHDMDRjxoyi2oylRo0aJS8vL/NWvXp1R7cEAAAAAAAAAABKoSIJYHLClyNHjig+Pt7uPGh+fn46deqUXf2VK1d05swZ+fn5mTUpKSl2NTn3b1Rz9fyrl8ur5lpDhw5VWlqaeTt27Fihxg0AAAAAAAAAACAVQQCTE74cPHhQ3377rSpVqmQ3PzQ0VKmpqUpKSjKnrVmzRtnZ2WrWrJlZs27dOl2+fNmsiY+PV3BwsCpWrGjWrF692m7d8fHxCg0NlSQFBQXJz8/PriY9PV2JiYlmzbVcXV3l6elpdwMAAAAAAAAAACisQgcwGRkZ2rFjh3bs2CHpr4vd79ixQ0ePHtXly5fVrVs3bd26VXPnzlVWVpaSk5OVnJysS5cuSZLq1q2rDh06qE+fPtq8ebM2btyo2NhY9ejRQ/7+/pKkJ598Ui4uLoqOjtaePXs0f/58TZ48WQMGDDD7ePXVVxUXF6fx48dr3759GjFihLZu3arY2FhJks1mU//+/fXee+9p6dKl2rVrl5555hn5+/srKirqbz5sAAAAAAAAAAAA12czDMMozAJr165V27Ztc03v3bu3RowYoaCgoDyX++6779SmTRtJ0pkzZxQbG6v//e9/cnJyUteuXTVlyhSVL1/erN+5c6f69u2rLVu2qHLlynrllVf0xhtv2K1zwYIFGjZsmA4fPqxatWppzJgx6tSpkznfMAy9/fbbmjVrllJTU9WyZUtNnz5dtWvXLtBY09PT5eXlpbS0NI6GyUPgkOWObiFPh0dHOroFAAAAAAAAAMAtqDC5QaEDmNsJAUz+CGAAAAAAAAAAALeTwuQGll8DBgAAAAAAAAAA4HZHAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsFihA5h169apc+fO8vf3l81m0+LFi+3mG4ah4cOHq2rVqnJ3d1d4eLgOHjxoV3PmzBn16tVLnp6e8vb2VnR0tDIyMuxqdu7cqQceeEBubm6qXr26xowZk6uXBQsWqE6dOnJzc1NISIhWrFhR6F4AAAAAAAAAAACsVugAJjMzUw0aNNC0adPynD9mzBhNmTJFM2fOVGJiosqVK6eIiAhduHDBrOnVq5f27Nmj+Ph4LVu2TOvWrVNMTIw5Pz09Xe3bt1dAQICSkpI0duxYjRgxQrNmzTJrNm3apJ49eyo6Olrbt29XVFSUoqKitHv37kL1AgAAAAAAAAAAYDWbYRjGTS9ss2nRokWKioqS9NcRJ/7+/ho4cKAGDRokSUpLS5Ovr6/mzJmjHj16aO/evapXr562bNmiJk2aSJLi4uLUqVMnHT9+XP7+/poxY4befPNNJScny8XFRZI0ZMgQLV68WPv27ZMkde/eXZmZmVq2bJnZT/PmzdWwYUPNnDmzQL3cSHp6ury8vJSWliZPT8+bfZhuWYFDlju6hTwdHh3p6BYAAAAAAAAAALegwuQGll4D5tChQ0pOTlZ4eLg5zcvLS82aNVNCQoIkKSEhQd7e3mb4Iknh4eFycnJSYmKiWdOqVSszfJGkiIgI7d+/X2fPnjVrrt5OTk3OdgrSy7UuXryo9PR0uxsAAAAAAAAAAEBhWRrAJCcnS5J8fX3tpvv6+przkpOTVaVKFbv5zs7O8vHxsavJax1Xb+N6NVfPv1Ev1xo1apS8vLzMW/Xq1QswagAAAAAAAAAAAHuWBjCl3dChQ5WWlmbejh075uiWAAAAAAAAAABAKWRpAOPn5ydJSklJsZuekpJizvPz89OpU6fs5l+5ckVnzpyxq8lrHVdv43o1V8+/US/XcnV1laenp90NAAAAAAAAAACgsCwNYIKCguTn56fVq1eb09LT05WYmKjQ0FBJUmhoqFJTU5WUlGTWrFmzRtnZ2WrWrJlZs27dOl2+fNmsiY+PV3BwsCpWrGjWXL2dnJqc7RSkFwAAAAAAAAAAgKJQ6AAmIyNDO3bs0I4dOyT9dbH7HTt26OjRo7LZbOrfv7/ee+89LV26VLt27dIzzzwjf39/RUVFSZLq1q2rDh06qE+fPtq8ebM2btyo2NhY9ejRQ/7+/pKkJ598Ui4uLoqOjtaePXs0f/58TZ48WQMGDDD7ePXVVxUXF6fx48dr3759GjFihLZu3arY2FhJKlAvAAAAAAAAAAAARcG5sAts3bpVbdu2Ne/nhCK9e/fWnDlz9PrrryszM1MxMTFKTU1Vy5YtFRcXJzc3N3OZuXPnKjY2Vg8++KCcnJzUtWtXTZkyxZzv5eWlVatWqW/fvmrcuLEqV66s4cOHKyYmxqwJCwvTvHnzNGzYMP3zn/9UrVq1tHjxYtWvX9+sKUgvAAAAAAAAAAAAVrMZhmE4uomSKj09XV5eXkpLS+N6MHkIHLLc0S3k6fDoSEe3AAAAAAAAAAC4BRUmN7D0GjAAAAAAAAAAAAAggAEAAAAAAAAAALAcAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWMzyACYrK0tvvfWWgoKC5O7urpo1a+rdd9+VYRhmjWEYGj58uKpWrSp3d3eFh4fr4MGDdus5c+aMevXqJU9PT3l7eys6OloZGRl2NTt37tQDDzwgNzc3Va9eXWPGjMnVz4IFC1SnTh25ubkpJCREK1assHrIAAAAAAAAAAAAdiwPYD744APNmDFDH374ofbu3asPPvhAY8aM0dSpU82aMWPGaMqUKZo5c6YSExNVrlw5RURE6MKFC2ZNr169tGfPHsXHx2vZsmVat26dYmJizPnp6elq3769AgIClJSUpLFjx2rEiBGaNWuWWbNp0yb17NlT0dHR2r59u6KiohQVFaXdu3dbPWwAAAAAAAAAAACTzbj60BQLPPzww/L19dX//d//mdO6du0qd3d3/ec//5FhGPL399fAgQM1aNAgSVJaWpp8fX01Z84c9ejRQ3v37lW9evW0ZcsWNWnSRJIUFxenTp066fjx4/L399eMGTP05ptvKjk5WS4uLpKkIUOGaPHixdq3b58kqXv37srMzNSyZcvMXpo3b66GDRtq5syZNxxLenq6vLy8lJaWJk9PT8seo1tF4JDljm4hT4dHRzq6BQAAAAAAAADALagwuYHlR8CEhYVp9erVOnDggCTpxx9/1IYNG9SxY0dJ0qFDh5ScnKzw8HBzGS8vLzVr1kwJCQmSpISEBHl7e5vhiySFh4fLyclJiYmJZk2rVq3M8EWSIiIitH//fp09e9asuXo7OTU527nWxYsXlZ6ebncDAAAAAAAAAAAoLGerVzhkyBClp6erTp06KlOmjLKysvT++++rV69ekqTk5GRJkq+vr91yvr6+5rzk5GRVqVLFvlFnZ/n4+NjVBAUF5VpHzryKFSsqOTk53+1ca9SoURo5cuTNDBsAAAAAAAAAAMBk+REw//3vfzV37lzNmzdP27Zt02effaZx48bps88+s3pTlhs6dKjS0tLM27FjxxzdEgAAAAAAAAAAKIUsPwJm8ODBGjJkiHr06CFJCgkJ0ZEjRzRq1Cj17t1bfn5+kqSUlBRVrVrVXC4lJUUNGzaUJPn5+enUqVN2671y5YrOnDljLu/n56eUlBS7mpz7N6rJmX8tV1dXubq63sywAQAAAAAAAAAATJYfAXPu3Dk5OdmvtkyZMsrOzpYkBQUFyc/PT6tXrzbnp6enKzExUaGhoZKk0NBQpaamKikpyaxZs2aNsrOz1axZM7Nm3bp1unz5slkTHx+v4OBgVaxY0ay5ejs5NTnbAQAAAAAAAAAAKAqWBzCdO3fW+++/r+XLl+vw4cNatGiRJkyYoEcffVSSZLPZ1L9/f7333ntaunSpdu3apWeeeUb+/v6KioqSJNWtW1cdOnRQnz59tHnzZm3cuFGxsbHq0aOH/P39JUlPPvmkXFxcFB0drT179mj+/PmaPHmyBgwYYPby6quvKi4uTuPHj9e+ffs0YsQIbd26VbGxsVYPGwAAAAAAAAAAwGT5KcimTp2qt956Sy+//LJOnTolf39//eMf/9Dw4cPNmtdff12ZmZmKiYlRamqqWrZsqbi4OLm5uZk1c+fOVWxsrB588EE5OTmpa9eumjJlijnfy8tLq1atUt++fdW4cWNVrlxZw4cPV0xMjFkTFhamefPmadiwYfrnP/+pWrVqafHixapfv77VwwYAAAAAAAAAADDZDMMwHN1ESZWeni4vLy+lpaXJ09PT0e2UOIFDlju6hTwdHh3p6BYAAAAAAAAAALegwuQGlp+CDAAAAAAAAAAA4HZHAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLOTu6AcARAocsd3QLeTo8OtLRLQAAAAAAAAAALMARMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABZzdnQDAAoncMhyR7eQp8OjIx3dAgAAAAAAAACUGBwBAwAAAAAAAAAAYDECGAAAAAAAAAAAAIsRwAAAAAAAAAAAAFiMAAYAAAAAAAAAAMBiBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALFYkAcxvv/2mp556SpUqVZK7u7tCQkK0detWc75hGBo+fLiqVq0qd3d3hYeH6+DBg3brOHPmjHr16iVPT095e3srOjpaGRkZdjU7d+7UAw88IDc3N1WvXl1jxozJ1cuCBQtUp04dubm5KSQkRCtWrCiKIQMAAAAAAAAAAJgsD2DOnj2rFi1aqGzZsvrmm2/0008/afz48apYsaJZM2bMGE2ZMkUzZ85UYmKiypUrp4iICF24cMGs6dWrl/bs2aP4+HgtW7ZM69atU0xMjDk/PT1d7du3V0BAgJKSkjR27FiNGDFCs2bNMms2bdqknj17Kjo6Wtu3b1dUVJSioqK0e/duq4cNAAAAAAAAAABgshmGYVi5wiFDhmjjxo1av359nvMNw5C/v78GDhyoQYMGSZLS0tLk6+urOXPmqEePHtq7d6/q1aunLVu2qEmTJpKkuLg4derUScePH5e/v79mzJihN998U8nJyXJxcTG3vXjxYu3bt0+S1L17d2VmZmrZsmXm9ps3b66GDRtq5syZNxxLenq6vLy8lJaWJk9Pz7/1uNyKAocsd3QLeTo8OvKGNfRuvYL0LpXM/gvaOwAAAAAAAIDbW2FyA8uPgFm6dKmaNGmixx9/XFWqVNF9992njz/+2Jx/6NAhJScnKzw83Jzm5eWlZs2aKSEhQZKUkJAgb29vM3yRpPDwcDk5OSkxMdGsadWqlRm+SFJERIT279+vs2fPmjVXbyenJmc7AAAAAAAAAAAARcHyAObXX3/VjBkzVKtWLa1cuVIvvfSS+vXrp88++0ySlJycLEny9fW1W87X19ecl5ycrCpVqtjNd3Z2lo+Pj11NXuu4ehvXq8mZf62LFy8qPT3d7gYAAAAAAAAAAFBYzlavMDs7W02aNNG//vUvSdJ9992n3bt3a+bMmerdu7fVm7PUqFGjNHLkSEe3AQAAAAAAAAAASjnLj4CpWrWq6tWrZzetbt26Onr0qCTJz89PkpSSkmJXk5KSYs7z8/PTqVOn7OZfuXJFZ86csavJax1Xb+N6NTnzrzV06FClpaWZt2PHjhVs0AAAAAAAAAAAAFexPIBp0aKF9u/fbzftwIEDCggIkCQFBQXJz89Pq1evNuenp6crMTFRoaGhkqTQ0FClpqYqKSnJrFmzZo2ys7PVrFkzs2bdunW6fPmyWRMfH6/g4GBVrFjRrLl6Ozk1Odu5lqurqzw9Pe1uAAAAAAAAAAAAhWV5APPaa6/phx9+0L/+9S/9/PPPmjdvnmbNmqW+fftKkmw2m/r376/33ntPS5cu1a5du/TMM8/I399fUVFRkv46YqZDhw7q06ePNm/erI0bNyo2NlY9evSQv7+/JOnJJ5+Ui4uLoqOjtWfPHs2fP1+TJ0/WgAEDzF5effVVxcXFafz48dq3b59GjBihrVu3KjY21uphAwAAAAAAAAAAmCy/Bsz999+vRYsWaejQoXrnnXcUFBSkSZMmqVevXmbN66+/rszMTMXExCg1NVUtW7ZUXFyc3NzczJq5c+cqNjZWDz74oJycnNS1a1dNmTLFnO/l5aVVq1apb9++aty4sSpXrqzhw4crJibGrAkLC9O8efM0bNgw/fOf/1StWrW0ePFi1a9f3+phAwAAAAAAAAAAmGyGYRiObqKkSk9Pl5eXl9LS0jgdWR4Chyx3dAt5Ojw68oY19G69gvQulcz+C9o7AAAAAAAAgNtbYXIDy09BBgAAAAAAAAAAcLsjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGLOjm4AAEqLwCHLHd1Cng6PjnR0CwAAAAAAAACuwREwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYzNnRDQAAil7gkOWObiFPh0dHOroFAAAAAAAAoEhwBAwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGJFHsCMHj1aNptN/fv3N6dduHBBffv2VaVKlVS+fHl17dpVKSkpdssdPXpUkZGR8vDwUJUqVTR48GBduXLFrmbt2rVq1KiRXF1ddffdd2vOnDm5tj9t2jQFBgbKzc1NzZo10+bNm4timAAAAAAAAAAAAKYiDWC2bNmijz76SPfee6/d9Ndee03/+9//tGDBAn3//fc6ceKEHnvsMXN+VlaWIiMjdenSJW3atEmfffaZ5syZo+HDh5s1hw4dUmRkpNq2basdO3aof//+euGFF7Ry5UqzZv78+RowYIDefvttbdu2TQ0aNFBERIROnTpVlMMGAAAAAAAAAAC3uSILYDIyMtSrVy99/PHHqlixojk9LS1N//d//6cJEyaoXbt2aty4sWbPnq1Nmzbphx9+kCStWrVKP/30k/7zn/+oYcOG6tixo959911NmzZNly5dkiTNnDlTQUFBGj9+vOrWravY2Fh169ZNEydONLc1YcIE9enTR88995zq1aunmTNnysPDQ59++mlRDRsAAAAAAAAAAKDoApi+ffsqMjJS4eHhdtOTkpJ0+fJlu+l16tRRjRo1lJCQIElKSEhQSEiIfH19zZqIiAilp6drz549Zs21646IiDDXcenSJSUlJdnVODk5KTw83Ky51sWLF5Wenm53AwAAAAAAAAAAKCznoljpl19+qW3btmnLli255iUnJ8vFxUXe3t520319fZWcnGzWXB2+5MzPmZdfTXp6us6fP6+zZ88qKysrz5p9+/bl2feoUaM0cuTIgg8UAFAsAocsd3QLuRweHenoFgAAAAAAAFCCWX4EzLFjx/Tqq69q7ty5cnNzs3r1RWro0KFKS0szb8eOHXN0SwAAAAAAAAAAoBSyPIBJSkrSqVOn1KhRIzk7O8vZ2Vnff/+9pkyZImdnZ/n6+urSpUtKTU21Wy4lJUV+fn6SJD8/P6WkpOSanzMvvxpPT0+5u7urcuXKKlOmTJ41Oeu4lqurqzw9Pe1uAAAAAAAAAAAAhWV5APPggw9q165d2rFjh3lr0qSJevXqZf67bNmyWr16tbnM/v37dfToUYWGhkqSQkNDtWvXLp06dcqsiY+Pl6enp+rVq2fWXL2OnJqcdbi4uKhx48Z2NdnZ2Vq9erVZAwAAAAAAAAAAUBQsvwZMhQoVVL9+fbtp5cqVU6VKlczp0dHRGjBggHx8fOTp6alXXnlFoaGhat68uSSpffv2qlevnp5++mmNGTNGycnJGjZsmPr27StXV1dJ0osvvqgPP/xQr7/+up5//nmtWbNG//3vf7V8+f+7TsCAAQPUu3dvNWnSRE2bNtWkSZOUmZmp5557zuphAwAAAAAAAAAAmCwPYApi4sSJcnJyUteuXXXx4kVFRERo+vTp5vwyZcpo2bJleumllxQaGqpy5cqpd+/eeuedd8yaoKAgLV++XK+99pomT56satWq6ZNPPlFERIRZ0717d/3+++8aPny4kpOT1bBhQ8XFxcnX17dYxwsAAAAAAAAAAG4vxRLArF271u6+m5ubpk2bpmnTpl13mYCAAK1YsSLf9bZp00bbt2/PtyY2NlaxsbEF7hUAAAAAAAAAAODvsvwaMAAAAAAAAAAAALc7AhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFnN2dAMAANzKAocsd3QLeTo8OtLRLQAAAAAAANzSOAIGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBjXgAEAAHni+jUAAAAAAAA3jyNgAAAAAAAAAAAALMYRMAAA4JbD0TsAAAAAAMDRCGAAAABKmJIYIBEeAQAAAABQOJyCDAAAAAAAAAAAwGIEMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGKWBzCjRo3S/fffrwoVKqhKlSqKiorS/v377WouXLigvn37qlKlSipfvry6du2qlJQUu5qjR48qMjJSHh4eqlKligYPHqwrV67Y1axdu1aNGjWSq6ur7r77bs2ZMydXP9OmTVNgYKDc3NzUrFkzbd682eohAwAAAAAAAAAA2HG2eoXff/+9+vbtq/vvv19XrlzRP//5T7Vv314//fSTypUrJ0l67bXXtHz5ci1YsEBeXl6KjY3VY489po0bN0qSsrKyFBkZKT8/P23atEknT57UM888o7Jly+pf//qXJOnQoUOKjIzUiy++qLlz52r16tV64YUXVLVqVUVEREiS5s+frwEDBmjmzJlq1qyZJk2apIiICO3fv19VqlSxeugAAAC3vcAhyx3dQp4Oj450dAsAAAAAgNuM5QFMXFyc3f05c+aoSpUqSkpKUqtWrZSWlqb/+7//07x589SuXTtJ0uzZs1W3bl398MMPat68uVatWqWffvpJ3377rXx9fdWwYUO9++67euONNzRixAi5uLho5syZCgoK0vjx4yVJdevW1YYNGzRx4kQzgJkwYYL69Omj5557TpI0c+ZMLV++XJ9++qmGDBli9dABAAAAAAAAAAAkFUEAc620tDRJko+PjyQpKSlJly9fVnh4uFlTp04d1ahRQwkJCWrevLkSEhIUEhIiX19fsyYiIkIvvfSS9uzZo/vuu08JCQl268ip6d+/vyTp0qVLSkpK0tChQ835Tk5OCg8PV0JCQlENFwAAAKUUR+8AAAAAAKxUpAFMdna2+vfvrxYtWqh+/fqSpOTkZLm4uMjb29uu1tfXV8nJyWbN1eFLzvycefnVpKen6/z58zp79qyysrLyrNm3b1+e/V68eFEXL14076enpxdyxAAAAAAAAAAAAJJTUa68b9++2r17t7788sui3IxlRo0aJS8vL/NWvXp1R7cEAAAAAAAAAABKoSILYGJjY7Vs2TJ99913qlatmjndz89Ply5dUmpqql19SkqK/Pz8zJqUlJRc83Pm5Vfj6ekpd3d3Va5cWWXKlMmzJmcd1xo6dKjS0tLM27Fjxwo/cAAAAAAAAAAAcNuzPIAxDEOxsbFatGiR1qxZo6CgILv5jRs3VtmyZbV69Wpz2v79+3X06FGFhoZKkkJDQ7Vr1y6dOnXKrImPj5enp6fq1atn1ly9jpyanHW4uLiocePGdjXZ2dlavXq1WXMtV1dXeXp62t0AAAAAAAAAAAAKy/JrwPTt21fz5s3TkiVLVKFCBfOaLV5eXnJ3d5eXl5eio6M1YMAA+fj4yNPTU6+88opCQ0PVvHlzSVL79u1Vr149Pf300xozZoySk5M1bNgw9e3bV66urpKkF198UR9++KFef/11Pf/881qzZo3++9//avny/3fx1AEDBqh3795q0qSJmjZtqkmTJikzM1PPPfec1cMGAAAAHCpwyPIbFxWzw6MjHd0CAAAAADiM5QHMjBkzJElt2rSxmz579mw9++yzkqSJEyfKyclJXbt21cWLFxUREaHp06ebtWXKlNGyZcv00ksvKTQ0VOXKlVPv3r31zjvvmDVBQUFavny5XnvtNU2ePFnVqlXTJ598ooiICLOme/fu+v333zV8+HAlJyerYcOGiouLk6+vr9XDBgAAAAAAAAAAMFkewBiGccMaNzc3TZs2TdOmTbtuTUBAgFasWJHvetq0aaPt27fnWxMbG6vY2Ngb9gQAAADAMUri0TsSR/AAAAAA+HssD2AAAAAA4HZBeAQAAADgepwc3QAAAAAAAAAAAMCthiNgAAAAAOA2xNE7AAAAQNEigAEAAAAAlDolMUAiPAIAAMDVOAUZAAAAAAAAAACAxTgCBgAAAACAYlQSj96ROIIHAADAahwBAwAAAAAAAAAAYDGOgAEAAAAAAAXC0TsAAAAFRwADAAAAAABuCyUxQCI8AgDg1sUpyAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxTkEGAAAAAABQwpXE06dJBTuFGr1bj1PXAUDpQAADAAAAAAAA3IJKYoBEeATgdsIpyAAAAAAAAAAAACzGETAAAAAAAAAASpSSePSOxKnrABQOAQwAAAAAAAAAoNSHR6W9f9x6CGAAAAAAAAAAAHAgwqNbE9eAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABY7LYIYKZNm6bAwEC5ubmpWbNm2rx5s6NbAgAAAAAAAAAAt7BbPoCZP3++BgwYoLffflvbtm1TgwYNFBERoVOnTjm6NQAAAAAAAAAAcIu65QOYCRMmqE+fPnruuedUr149zZw5Ux4eHvr0008d3RoAAAAAAAAAALhF3dIBzKVLl5SUlKTw8HBzmpOTk8LDw5WQkODAzgAAAAAAAAAAwK3M2dENFKU//vhDWVlZ8vX1tZvu6+urffv25aq/ePGiLl68aN5PS0uTJKWnpxdto6VU9sVzjm4hTwX5/6J36xX0eVIS+y/NvUvsN45SmnuXbv39pjT3LpXM/ktz7xL7jaOU5t6lW3+/Kc29SyWz/9Lcu8R+4yiluXfp1t9vSnPvUsnsvzT3Lt36+01p7l0q3f2X5t5vNzmPiWEYN6y1GQWpKqVOnDihO++8U5s2bVJoaKg5/fXXX9f333+vxMREu/oRI0Zo5MiRxd0mAAAAAAAAAAAoRY4dO6Zq1arlW3NLHwFTuXJllSlTRikpKXbTU1JS5Ofnl6t+6NChGjBggHk/OztbZ86cUaVKlWSz2Yq839tVenq6qlevrmPHjsnT09PR7RQKvTtOae6f3h2jNPcule7+6d1xSnP/9O4Ypbl3qXT3T++OU5r7p3fHKM29S6W7f3p3nNLcP707RmnuXSrd/Zfm3ksLwzD0559/yt/f/4a1t3QA4+LiosaNG2v16tWKioqS9Feosnr1asXGxuaqd3V1laurq900b2/vYugUkuTp6VlqXxTo3XFKc//07hiluXepdPdP745Tmvund8cozb1Lpbt/enec0tw/vTtGae5dKt3907vjlOb+6d0xSnPvUunuvzT3Xhp4eXkVqO6WDmAkacCAAerdu7eaNGmipk2batKkScrMzNRzzz3n6NYAAAAAAAAAAMAt6pYPYLp3767ff/9dw4cPV3Jysho2bKi4uDj5+vo6ujUAAAAAAAAAAHCLuuUDGEmKjY3N85RjKBlcXV319ttv5zr9W2lA745Tmvund8cozb1Lpbt/enec0tw/vTtGae5dKt3907vjlOb+6d0xSnPvUunun94dpzT3T++OUZp7l0p3/6W591uRzTAMw9FNAAAAAAAAAAAA3EqcHN0AAAAAAAAAAADArYYABgAAAAAAAAAAwGIEMChWa9eulc1mU2pqqqNbKXZz5syRt7e3o9u4ZW3cuFEhISEqW7asoqKiHN3OLaVNmzbq37+/o9sotNLa99VuhTFIpWMcBXl/GjFihBo2bFhsPRXErfK+Whr2kVtdQT+n2Gw2LV68uMj7uR7DMBQTEyMfHx/ZbDbt2LHDYb3cLkrr8/PafcXb29tuHIGBgZo0aZLD+itujnoPu9H+4+jXFJRcpfW1B7hZJXmfL8m9/V2lfWylvf/bBQEMihQvBCguAwYMUMOGDXXo0CHNmTPH0e2YboXnwMKFC/Xuu+86uo1CK619X+3qMZTmH4pK4v/FzTw3Bw0apNWrVxdNQwVUVK8ppXn/gjW6d++uAwcOmPdLYuAoSXFxcZozZ46WLVumkydPqn79+o5uCTdw+PBhh4Rl1+4rBw4cKHHvRcWpJLyH5eXkyZPq2LGjo9sA8DeU1M8Mpc2t8t0PQG7Ojm4AAKzwyy+/6MUXX1S1atUc3cotx8fHx9Et3JTS2vfVboUxSLfOOMqXL6/y5cs7ug1IunTpklxcXBzdxi3F3d1d7u7ujm7jhn755RdVrVpVYWFhN7W8YRjKysqSszNfg251f3dfudWU1PcwPz8/R7dw27t8+bLKli3r6DaA296t8p0JQG4cAYMi8+yzz+r777/X5MmTZbPZZLPZdPjwYUlSUlKSmjRpIg8PD4WFhWn//v12yy5ZskSNGjWSm5ub7rrrLo0cOVJXrlwptt7j4uLUsmVLeXt7q1KlSnr44Yf1yy+/SPp/f8W3cOFCtW3bVh4eHmrQoIESEhLs1jFnzhzVqFFDHh4eevTRR3X69Oli6/9G8htfSXXx4kX169dPVapUkZubm1q2bKktW7aY/x+nT5/W888/L5vNVmKOgLnec+D7779X06ZN5erqqqpVq2rIkCHFun8X1tV/cT99+nTVqlVLbm5u8vX1Vbdu3RzbXD6u7jswMFD/+te/9Pzzz6tChQqqUaOGZs2a5dgGCyBnDG3atNGRI0f02muvmftSaVLSjgS72fena/+6b+3atWratKnKlSsnb29vtWjRQkeOHClxff/yyy/q0qWLfH19Vb58ed1///369ttvzfklZf+6cuWKYmNj5eXlpcqVK+utt96SYRiS/noOv/vuu3rmmWfk6empmJgYh/SYl/zeUy9duqTY2FhVrVpVbm5uCggI0KhRo4qtt2XLlsnb21tZWVmSpB07dshms2nIkCFmzQsvvKCnnnrK7hRkc+bM0ciRI/Xjjz+a+8TV761//PGHHn30UXl4eKhWrVpaunRpsYzn2Wef1SuvvKKjR4/KZrMpMDDwup8PcuScpu+bb75R48aN5erqqg0bNhRLv4V5/E+fPq2ePXvqzjvvlIeHh0JCQvTFF1/Yre+rr75SSEiI3N3dValSJYWHhyszM7NYxpLf8zOvU0h5e3ub+0xQUJAk6b777pPNZlObNm2KvN+89pWCnArro48+0sMPPywPDw/VrVtXCQkJ+vnnn9WmTRuVK1dOYWFhlnxmbtOmjV555RX1799fFStWlK+vrz7++GNlZmbqueeeU4UKFXT33Xfrm2++MZfJ7/PjrFmz5O/vr+zsbLvtdOnSRc8//7ykvP9C/ZNPPlHdunXl5uamOnXqaPr06X97bHnJzs7W66+/Lh8fH/n5+WnEiBHmvKv3H0e/Zl5Pfq8zOa8xq1evzvf7bXEqyHfZ+fPnq3Xr1nJzc9PcuXMlFd/+UBj57Tupqal64YUXdMcdd8jT01Pt2rXTjz/+WOw9fv7556pUqZIuXrxoNz0qKkpPP/20JGnGjBmqWbOmXFxcFBwcrH//+99mXV5HCaampspms2nt2rXFMQS1adNG/fr1u+5jffToUXXp0kXly5eXp6ennnjiCaWkpEi68WeGombF89PRvz/luNF3vyNHjqhz586qWLGiypUrp3vuuUcrVqwotv7yez5OmDBBISEhKleunKpXr66XX35ZGRkZkqT09HS5u7vbvadJ0qJFi1ShQgWdO3dOknTs2DE98cQT8vb2lo+Pj7p06WJ+1ylq+X3OuXjxogYNGqQ777xT5cqVU7NmzYrtuVlQ1+v/nXfeyfNo8YYNG+qtt95yQKe3MQMoIqmpqUZoaKjRp08f4+TJk8bJkyeNb7/91pBkNGvWzFi7dq2xZ88e44EHHjDCwsLM5datW2d4enoac+bMMX755Rdj1apVRmBgoDFixIhi6/2rr74yvv76a+PgwYPG9u3bjc6dOxshISFGVlaWcejQIUOSUadOHWPZsmXG/v37jW7duhkBAQHG5cuXDcMwjB9++MFwcnIyPvjgA2P//v3G5MmTDW9vb8PLy6vYxpCf/MZXUvXr18/w9/c3VqxYYezZs8fo3bu3UbFiReOPP/4wTp48aXh6ehqTJk0yTp48aZw7d87R7RqGkfdz4Pjx44aHh4fx8ssvG3v37jUWLVpkVK5c2Xj77bcd3e51tW7d2nj11VeNLVu2GGXKlDHmzZtnHD582Ni2bZsxefJkR7d3XTl9G4ZhBAQEGD4+Psa0adOMgwcPGqNGjTKcnJyMffv2ObbJG8gZw+nTp41q1aoZ77zzjrkvlSZX/1+UBDf7/vT2228bDRo0MAzDMC5fvmx4eXkZgwYNMn7++Wfjp59+MubMmWMcOXKkxPW9Y8cOY+bMmcauXbuMAwcOGMOGDTPc3NzMXkvC/tW6dWujfPnyxquvvmrs27fP+M9//mN4eHgYs2bNMgzjr+ewp6enMW7cOOPnn382fv7552Lv8Xrye08dO3asUb16dWPdunXG4cOHjfXr1xvz5s0rtt5SU1MNJycnY8uWLYZhGMakSZOMypUrG82aNTNr7r77buPjjz82Zs+ebX5OOXfunDFw4EDjnnvuMfeJnPdWSUa1atWMefPmGQcPHjT69etnlC9f3jh9+nSxjOedd94xqlWrZpw8edI4derUdT8f5PTz3XffGZKMe++911i1apXx888/F0uvOf0W9PE/fvy4MXbsWGP79u3GL7/8YkyZMsUoU6aMkZiYaBiGYZw4ccJwdnY2JkyYYBw6dMjYuXOnMW3aNOPPP/8s8nHc6PkpyVi0aJHdMl5eXsbs2bMNwzCMzZs3G5KMb7/91jh58qTD9pVr34sCAgKMiRMnmvclGXfeeacxf/58Y//+/UZUVJQRGBhotGvXzoiLizN++ukno3nz5kaHDh3+dn+tW7c2KlSoYLz77rvGgQMHjHfffdcoU6aM0bFjR2PWrFnGgQMHjJdeesmoVKmSkZmZecPPj2fOnDFcXFyMb7/91tzG6dOn7aZd/R5mGIbxn//8x6hatarx9ddfG7/++qvx9ddfGz4+PsacOXP+9viuHaunp6cxYsQI48CBA8Znn31m2Gw2Y9WqVYZh2O8/jn7NvJ78XmdyXmPyex8ubgX5LhsYGGj+3584caLY9ofCuNG+Ex4ebnTu3NnYsmWLceDAAWPgwIFGpUqViu01Pse5c+cMLy8v47///a85LSUlxXB2djbWrFljLFy40Chbtqwxbdo0Y//+/cb48eONMmXKGGvWrDEMwzD/T7Zv324uf/bsWUOS8d133xXLGPJ7rLOysoyGDRsaLVu2NLZu3Wr88MMPRuPGjY3WrVub47/eZ4bi8HefnyXh96ccN/ruFxkZaTz00EPGzp07jV9++cX43//+Z3z//ffF1lt+z8eJEycaa9asMQ4dOmSsXr3aCA4ONl566SVz+W7duhlPPfWU3Tq7du1qTrt06ZJRt25d4/nnnzd27txp/PTTT8aTTz5pBAcHGxcvXizyseX3OeeFF14wwsLCjHXr1hk///yzMXbsWMPV1dU4cOBAkfZVUPn1f+zYMcPJycnYvHmzWb9t2zbDZrMZv/zyiwO7vv0QwKBIXftFJ+cN8OovB8uXLzckGefPnzcMwzAefPBB41//+pfdev79738bVatWLZae8/L7778bkoxdu3aZH5A++eQTc/6ePXsMScbevXsNwzCMnj17Gp06dbJbR/fu3UtMAHOtq8dXEmVkZBhly5Y15s6da067dOmS4e/vb4wZM8YwDPsv+iXJtc+Bf/7zn0ZwcLCRnZ1tTps2bZpRvnz5EhuA5Yzh66+/Njw9PY309HRHt1Qg1wYwV3/gy87ONqpUqWLMmDHDQd0VzLVjuPqHotKkpAUwhnFz709X/3h1+vRpQ5Kxdu3a4mz7pvrOyz333GNMnTrVvO/o/at169ZG3bp17V4b33jjDaNu3bqGYfzVX1RUlKPaK5Sr31NfeeUVo127dnbjKm6NGjUyxo4daxiGYURFRRnvv/++4eLiYvz555/G8ePHDUnGgQMH7AIYw8j9Y20OScawYcPM+xkZGYYk45tvvinqoRiG8dcX/ICAAHPbN/p8kPMcWbx4cbH0d62CPv55iYyMNAYOHGgYhmEkJSUZkozDhw8XW+85bvT8vFEAk9ePi8Xh6n3FMHK/fuYVwFy9byckJBiSjP/7v/8zp33xxReGm5vb3+6tdevWRsuWLc37V65cMcqVK2c8/fTT5rSTJ08akoyEhIQCfX7s0qWL8fzzz5vzP/roI8Pf39+cf+1zumbNmrnCjXfffdcIDQ392+PLb6yGYRj333+/8cYbbxiGYb//lITXzGvd6HXmZt+Hi1Ne32UnTZpkV1Nc+0Nh5LfvrF+/3vD09DQuXLhgN79mzZrGRx99VJxtGoZhGC+99JLRsWNH8/748eONu+66y8jOzjbCwsKMPn362NU//vjj5u8FJSWAud5jvWrVKqNMmTLG0aNHzXk5v3/k/Kh7vc8MRc2K52dJ+v3pRt/9QkJCHBIMGcaNX8uvtWDBAqNSpUrm/UWLFhnly5c3MjMzDcMwjLS0NMPNzc38/Pjvf/871/vcxYsXDXd3d2PlypVWD8dOfp9zjhw5YpQpU8b47bff7JZ58MEHjaFDhxZpXwV1o89pHTt2tAvDXnnlFaNNmzbF3uftjlOQwSHuvfde899Vq1aVJJ06dUqS9OOPP+qdd94xz1Ncvnx59enTRydPnjQPTSxqBw8eVM+ePXXXXXfJ09NTgYGBkv469LYgY9i7d6+aNWtmt87Q0NAi7rrgCjK+kuSXX37R5cuX1aJFC3Na2bJl1bRpU+3du9eBnRXe3r17FRoaaneKnxYtWigjI0PHjx93YGc39tBDDykgIEB33XWXnn76ac2dO7fYnpNWuPo5a7PZ5OfnZz5ngRz5vbZfzcfHR88++6wiIiLUuXNnTZ48WSdPniy2Pq+VX98ZGRkaNGiQ6tatK29vb5UvX1579+4tca/5zZs3t3ttDA0N1cGDB83TNzVp0sRRreUrv/fUZ599Vjt27FBwcLD69eunVatWFXt/rVu31tq1a2UYhtavX6/HHntMdevW1YYNG/T999/L399ftWrVKtQ6r97fypUrJ09PT4e8nhbm84Gj9p+CPv5ZWVl69913FRISIh8fH5UvX14rV640n6cNGjTQgw8+qJCQED3++OP6+OOPdfbs2WIbx42en7eKq/dtX19fSVJISIjdtAsXLig9Pd3SbZUpU0aVKlXKtS3pr9fygnx+7NWrl77++mvzNEhz585Vjx495OSU+yt/ZmamfvnlF0VHR9t953rvvfeK5LTEV49V+ut9Kq/XjJLwmnmtgr7OFPTzQ3EoyHe9q18Ti3t/KIzr7Ts//vijMjIyVKlSJbueDx065JCe+/Tpo1WrVum3336T9NdpuZ599lnZbDbt3bvXbv+R/nr+lrTvsdd7rPfu3avq1aurevXq5rx69erJ29vb4WOw4vlZEn5/Kqh+/frpvffeU4sWLfT2229r586dxbr9/F7Lv/32Wz344IO68847VaFCBT399NM6ffq0+Rh26tRJZcuWNU9b+/XXX8vT01Ph4eGS/vp/+Pnnn1WhQgXz/8HHx0cXLlwoluf09T7n7Nq1S1lZWapdu7bdPvL99987/PXxavl9TuvTp4+++OILXbhwQZcuXdK8efPM05Oi+HD1STjE1Rf5y3mRyDlncUZGhkaOHKnHHnss13Jubm7F0l/nzp0VEBCgjz/+2Dyfcv369XXp0iWzJr8xlHQFGR9wrQoVKmjbtm1au3atVq1apeHDh2vEiBHasmWLed2Akuzai4vabLZS85xF8SnMa/vs2bPVr18/xcXFaf78+Ro2bJji4+PVvHnzYun1avn1PWjQIMXHx2vcuHG6++675e7urm7dupW61/xy5co5uoU85fee2qhRIx06dEjffPONvv32Wz3xxBMKDw/XV199VWz9tWnTRp9++ql+/PFHlS1bVnXq1FGbNm20du1anT17Vq1bty70Okvj66mj9p+CPv5jx47V5MmTNWnSJPMc6v379zefp2XKlFF8fLw2bdqkVatWaerUqXrzzTeVmJhoXmPFUWw2m3me9ByXL192UDd/T16vpUX1mT+v59Hf2Vbnzp1lGIaWL1+u+++/X+vXr9fEiRPzrM05L//HH3+c64/GypQpU+AxFFRBXzNKwmvmzSpJ3w0L8l3v6tfE4t4fCuN6+05GRoaqVq2a53UYHPG95L777lODBg30+eefq3379tqzZ4+WL19eoGVzQtKrX0cd8RpaGt/bC6qk//5UUC+88IIiIiK0fPlyrVq1SqNGjdL48eP1yiuvFMv2r7ePHD58WA8//LBeeuklvf/++/Lx8dGGDRsUHR2tS5cuycPDQy4uLurWrZvmzZunHj16aN68eerevbucnf/6WTojI0ONGzc2r0l1tTvuuKNYxpeXjIwMlSlTRklJSbleD8uXL++grgqnc+fOcnV11aJFi+Ti4qLLly+X6Gv53qoIYFCkXFxcCv2XcY0aNdL+/ft19913F1FX+Tt9+rT279+vjz/+WA888IAkFfpirXXr1lViYqLdtB9++MGyHv8OK8ZX3HIuWLhx40YFBARI+utD6ZYtW0rUhb3zcu1zoG7duvr6669lGIb54W/jxo2qUKGCqlWr5qg2C8zZ2Vnh4eEKDw/X22+/LW9vb61ZsybPD6yw1s28nuL6rHo877vvPt13330aOnSoQkNDNW/evCINYG6m740bN+rZZ5/Vo48+KumvLxLXXtCyJOxfeb1v1qpVy+E//uSnIO+pnp6e6t69u7p3765u3bqpQ4cOOnPmjHx8fIqlxwceeEB//vmnJk6caP7Y36ZNG40ePVpnz57VwIED81yuJOwTN1IaPh8U9PHfuHGjunTpoqeeekrSXz8MHThwQPXq1TPXZbPZ1KJFC7Vo0ULDhw9XQECAFi1apAEDBhT5OPJ7ft5xxx12RwAePHjQ7q+GXVxcJKnE708lWUE+P7q5uemxxx7T3Llz9fPPPys4OFiNGjXKc32+vr7y9/fXr7/+ql69ehXbOArC0a+Z1yoNrzNXu5nveiV5f7ieRo0aKTk5Wc7OzuYRPo72wgsvaNKkSfrtt98UHh5uHjFSt25dbdy4Ub179zZrN27caL6+5/y4fPLkSd13332SpB07dhRv8/moW7eujh07pmPHjplj+umnn5SammqOwVGfGax4fjr696frud5jWr16db344ot68cUXNXToUH388cfFFsBcT1JSkrKzszV+/HgzUPzvf/+bq65Xr1566KGHtGfPHq1Zs0bvvfeeOa9Ro0aaP3++qlSpIk9Pz2LrPcf1Pufcd999ysrK0qlTp8zX1JLoRt+jevfurdmzZ8vFxUU9evSQu7u7I9q8rRHAoEgFBgYqMTFRhw8fVvny5Qv0FxTDhw/Xww8/rBo1aqhbt25ycnLSjz/+qN27d9u9QBeVihUrqlKlSpo1a5aqVq2qo0ePasiQIYVaR79+/dSiRQuNGzdOXbp00cqVKxUXF1dEHReOFeMrbuXKldNLL72kwYMHy8fHRzVq1NCYMWN07tw5RUdHO7q9fF37HHj55Zc1adIkvfLKK4qNjdX+/fv19ttva8CAAXmeIqIkWbZsmX799Ve1atVKFStW1IoVK5Sdna3g4GBHt3ZbCAwM1Lp169SjRw+5urqqcuXKjm6pVLuZ96erHTp0SLNmzdIjjzwif39/7d+/XwcPHtQzzzxTRB3/5Wb6rlWrlhYuXKjOnTvLZrPprbfeyrVcSdi/jh49qgEDBugf//iHtm3bpqlTp2r8+PHF3kdh3Og9dcKECapataruu+8+OTk5acGCBfLz8yvWv86tWLGi7r33Xs2dO1cffvihJKlVq1Z64okndPny5eseARMYGKhDhw5px44dqlatmipUqCBXV9di67sgSsPng4I+/rVq1dJXX32lTZs2qWLFipowYYJSUlLMH7cSExO1evVqtW/fXlWqVFFiYqJ+//131a1bt1jGkd/zs127dvrwww8VGhqqrKwsvfHGG3Z/JVulShW5u7srLi5O1apVk5ubm7y8vIql71tFQT8/9urVSw8//LD27NljhnnXM3LkSPXr109eXl7q0KGDLl68qK1bt+rs2bPFEurlpSS8Zl7rRq8zP/74o8N6y8vNftcriftDfsLDwxUaGqqoqCiNGTNGtWvX1okTJ7R8+XI9+uijDjnt5JNPPqlBgwbp448/1ueff25OHzx4sJ544gndd999Cg8P1//+9z8tXLhQ3377rSTJ3d1dzZs31+jRoxUUFKRTp05p2LBhxd7/9YSHhyskJES9evXSpEmTdOXKFb388stq3bq1+Tg76jODFc9PR//+dD15fTbv37+/OnbsqNq1a+vs2bP67rvviu1zQH7uvvtuXb58WVOnTlXnzp21ceNGzZw5M1ddq1at5Ofnp169eikoKMjuiLtevXpp7Nix6tKli9555x1Vq1ZNR44c0cKFC/X6668X+R+rXu9zTu3atdWrVy8988wzGj9+vO677z79/vvvWr16te69915FRkYWaV8FdaPvUS+88IK5r2zcuNFRbd7WSvavfSj1Bg0apDJlyqhevXq64447CnS++YiICC1btkyrVq3S/fffr+bNm2vixInmXzQUNScnJ3355ZdKSkpS/fr19dprr2ns2LGFWkfz5s318ccfa/LkyWrQoIFWrVpVYj5EWTE+Rxg9erS6du2qp59+Wo0aNdLPP/+slStXqmLFio5uLV/XPgcuX76sFStWaPPmzWrQoIFefPFFRUdHl5j9Iz/e3t5auHCh2rVrp7p162rmzJn64osvdM899zi6tdvCO++8o8OHD6tmzZoOPQz7VnEz709X8/Dw0L59+9S1a1fVrl1bMTEx6tu3r/7xj38UUcd/uZm+J0yYoIoVKyosLEydO3dWRERErr+KLgn71zPPPKPz58+radOm6tu3r1599VXFxMQ4pJeCutF7aoUKFTRmzBg1adJE999/vw4fPqwVK1YUe+DeunVrZWVlqU2bNpL+uoZRvXr15Ofnd90QvWvXrurQoYPatm2rO+64Q1988UUxdlxwpeHzQUEe/2HDhqlRo0aKiIhQmzZt5Ofnp6ioKHMdnp6eWrdunTp16qTatWtr2LBhGj9+vDp27FgsY8jv+Tl+/HhVr15dDzzwgPkDpIeHh7mss7OzpkyZoo8++kj+/v7q0qVLsfR8K7nzzjsL9PmxXbt28vHx0f79+/Xkk0/mu84XXnhBn3zyiWbPnq2QkBC1bt1ac+bMcegp7UrKa+a1SsPrTI6b/a5XEveH/NhsNq1YsUKtWrXSc889p9q1a6tHjx46cuSIef2k4ubl5aWuXbuqfPnydq/fUVFRmjx5ssaNG6d77rlHH330kWbPnm2+J0jSp59+qitXrqhx48bq37+/Q3/4v5bNZtOSJUtUsWJFtWrVSuHh4brrrrs0f/58s8aRnxn+7vPT0b8/XU9en82zsrLUt29f1a1bVx06dFDt2rU1ffp0h/Yp/XWdugkTJuiDDz5Q/fr1NXfuXI0aNSpXnc1mU8+ePfXjjz/mOtrOw8ND69atU40aNczr5UVHR+vChQvFckRMfp9zZs+erWeeeUYDBw5UcHCwoqKitGXLFtWoUaPI+yqoG32PqlWrlsLCwlSnTp1cp5pE8bAZ156wFwAAAAAAAECBPfjgg7rnnns0ZcoUR7cCACbDMFSrVi29/PLLJfKoxtsBpyADAAAAAAAAbsLZs2e1du1arV27tkQckQAAOX7//Xd9+eWXSk5O1nPPPefodm5bBDAAAAAAAADATbjvvvt09uxZffDBB1wfE0CJUqVKFVWuXFmzZs0qkafOvF1wCjIAAAAAAAAAAACLOfZqdgAAAAAAAAAAALcgAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAABAkvTss88qMDDQ0W0AAAAAtwQCGAAAAAC52Gy2At3Wrl1bpH2cP39e0dHRql+/vry8vFS+fHk1aNBAkydP1uXLl+1qT548qSFDhqht27aqUKHCTff3559/6vXXX1dQUJBcXV115513qlu3bjp37pxdXWpqqmJiYnTHHXeoXLlyatu2rbZt23bD9Xfq1EkVK1aUYRh207dv3y6bzaaAgIBcy6xZs0Y2m02zZs0q9HgAAAAAOIazoxsAAAAAUPL8+9//trv/+eefKz4+Ptf0unXrFmkf58+f1549e9SpUycFBgbKyclJmzZt0muvvabExETNmzfPrN2/f78++OAD1apVSyEhIUpISCj09tLS0tS6dWsdP35cMTExuvvuu/X7779r/fr1unjxojw8PCRJ2dnZioyM1I8//qjBgwercuXKmj59utq0aaOkpCTVqlXrutto2bKlvvnmG+3evVshISHm9I0bN8rZ2VlHjx7V8ePHVa1aNbt5OcsCAAAAKB0IYAAAAADk8tRTT9nd/+GHHxQfH59relHz8fHRDz/8YDftxRdflJeXlz788ENNmDBBfn5+kqTGjRvr9OnT8vHx0VdffaXHH3+80NsbOnSojhw5om3btikoKMic/sYbb9jVffXVV9q0aZMWLFigbt26SZKeeOIJ1a5dW2+//bZdMHStnBBlw4YNuQKYTp06ac2aNdqwYYN69OhhztuwYYMqVar0twOvCxcuyMXFRU5OnAwBAAAAKGp86gYAAABwUzIzMzVw4EBVr15drq6uCg4O1rhx43KdWstmsyk2NlZz585VcHCw3Nzc1LhxY61bt+6mt51znZLU1FRzWoUKFeTj43PT60xNTdXs2bMVExOjoKAgXbp0SRcvXsyz9quvvpKvr68ee+wxc9odd9yhJ554QkuWLLnucpLUtGlTubi4mEe15Ni4caNatWqlpk2b2s3Lzs7WDz/8oLCwMNlsNknSr7/+qscff1w+Pj7y8PBQ8+bNtXz5crv1rV27VjabTV9++aWGDRumO++8Ux4eHkpPT5ckLV68WPXr15ebm5vq16+vRYsW5dnvl19+qcaNG6tChQry9PRUSEiIJk+enM8jCQAAAEAigAEAAABwEwzD0COPPKKJEyeqQ4cOmjBhgoKDgzV48GANGDAgV/3333+v/v3766mnntI777yj06dPq0OHDtq9e3eBtnfp0iX98ccfOnbsmBYtWqRx48YpICBAd999t2Vj2rBhgy5cuKC7775b3bp1k4eHh9zd3dWiRQvt2LHDrnb79u1q1KhRriNJmjZtqnPnzunAgQPX3U5OALVhwwZz2rFjx3Ts2DGFhYUpLCzMLoDZtWuX0tPTzSNnUlJSFBYWppUrV+rll1/W+++/rwsXLuiRRx7JM0R59913tXz5cg0aNEj/+te/5OLiolWrVqlr166y2WwaNWqUoqKi9Nxzz2nr1q12y8bHx6tnz56qWLGiPvjgA40ePVpt2rTJFR4BAAAAyI1TkAEAAAAotKVLl2rNmjV677339Oabb0qS+vbtq8cff1yTJ09WbGysatasadbv3r1bW7duVePGjSVJPXr0UHBwsIYPH66FCxfecHsLFy5Uz549zftNmjTRp59+Kmdn677SHDx4UNJfpyGrWbOmPv/8c6WlpWnkyJFq166d9uzZo6pVq0qSTp48qVatWuVaR878EydO2J1e7FotW7bU2LFj9dtvv+nOO+/Uxo0bzWAmNTVVo0aN0p9//qkKFSqYQU1OADN69GilpKRo/fr15rQ+ffro3nvv1YABA9SlSxe7YOjChQvaunWr3N3dzWlvvPGGfH19tWHDBnl5eUmSWrdurfbt2ysgIMCsW758uTw9PbVy5UqVKVOm8A8qAAAAcBvjCBgAAAAAhbZixQqVKVNG/fr1s5s+cOBAGYahb775xm56aGioGb5IUo0aNdSlSxetXLlSWVlZN9xe27ZtFR8frwULFujFF19U2bJllZmZac1g/n8ZGRmS/jpl2urVq/Xkk0/qpZde0uLFi3X27FlNmzbNrD1//rxcXV1zrcPNzc2cn5+c4GT9+vWS/jr9WOPGjeXi4qLQ0FDztGM589zc3NSkSRNJfz32TZs2NdchSeXLl1dMTIwOHz6sn376yW5bvXv3tgtfTp48qR07dqh3795m+CJJDz30kOrVq2e3rLe3tzIzMxUfH5/veAAAAADkRgADAAAAoNCOHDkif39/VahQwW56zkXijxw5Yje9Vq1audZRu3ZtnTt3Tr///vsNt+fr66vw8HB169ZNM2bM0MMPP6yHHnpIycnJhe79zJkzSk5ONm9paWmSZIYUnTt3Vvny5c365s2bKygoSJs2bTKnubu753mdlwsXLtit63patGghm81mnspr48aNatGihaS/Qo969erZzbv//vvl4uIi6a/HNjg4ONc6r/fYBwUF2d3PmZ/X/8m163355ZdVu3ZtdezYUdWqVdPzzz+vuLi4fMcGAAAA4C8EMAAAAABKnW7duikjI0NLliwp9LKPPfaYqlatat5effVVSZK/v7+kv8Kea1WpUkVnz54171etWlUnT57MVZczLWdd11OpUiXVqVNHGzZsUEZGhnbu3KmwsDBzflhYmDZs2KDjx4/r6NGjdke7FNaNwqD8VKlSRTt27NDSpUv1yCOP6LvvvlPHjh3Vu3fvm14nAAAAcLvgGjAAAAAACi0gIEDffvuteZ2SHPv27TPnXy3n+ipXO3DggDw8PHTHHXcUevs5p/jKOXqlMMaPH28XpuSEJTmnSPvtt99yLXPixAnVqVPHvN+wYUOtX79e2dnZdtdbSUxMlIeHh2rXrn3DPlq2bKlPP/1Uq1atUlZWVq4A5osvvtDatWvN2hwBAQHav39/rvVd77G/Vs78vP5P8lqvi4uLOnfurM6dOys7O1svv/yyPvroI7311lu6++67bzhOAAAA4HbFETAAAAAACq1Tp07KysrShx9+aDd94sSJstls6tixo930hIQEbdu2zbx/7NgxLVmyRO3bt8/34u5//PGHDMPINf2TTz6RJPO6KIXRuHFjhYeHm7ec654EBwerQYMGWrJkif744w+zftWqVTp27Jgeeughc1q3bt2UkpKihQsX2vW6YMECde7cOc/rw1yrZcuWysrK0rhx41SrVi27ICosLEwZGRmaPn26nJyc7MKZTp06afPmzUpISDCnZWZmatasWQoMDMx1HZdrVa1aVQ0bNtRnn31mF2DFx8fnun7M6dOn7e47OTnp3nvvlaQ8T8EGAAAA4P/hCBgAAAAAhda5c2e1bdtWb775pg4fPqwGDRpo1apVWrJkifr376+aNWva1devX18RERHq16+fXF1dNX36dEnSyJEj893Of/7zH82cOVNRUVG666679Oeff2rlypWKj49X586d1a5dO7v69957T5K0Z88eSdK///1vbdiwQZI0bNiwG45r4sSJeuihh9SyZUv94x//UFpamiZMmKDatWvrpZdeMuu6deum5s2b67nnntNPP/2kypUra/r06crKyrrhmHLkHNWSkJCgZ5991m5e7dq1VblyZSUkJCgkJETe3t7mvCFDhuiLL75Qx44d1a9fP/n4+Oizzz7ToUOH9PXXX9sdkXM9o0aNUmRkpFq2bKnnn39eZ86c0dSpU3XPPfcoIyPDrHvhhRd05swZtWvXTtWqVdORI0c0depUNWzY0LzmDAAAAIC82Yy8/pwMAAAAAK4SGxuradOm2R2NkpGRoeHDh2v+/Pn6/fffFRgYqJiYGA0cOFA2m82ss9ls6tu3r0JDQzVy5EgdPXpU9erV04QJE9SmTZt8t7t161aNGTNGiYmJSklJkbOzs4KDg/XUU0/plVdekbOz/d+UXb3daxX0q8+3336rt956Szt27JCHh4ciIyM1ZswY+fn52dWdPXtWgwcP1uLFi3X+/Hndf//9GjduXKGOyrnzzjt14sQJzZo1S3369LGb16VLFy1dulQvvfSSGVjl+PXXX/XGG2/o22+/1YULF3Tvvfdq+PDhioyMNGvWrl2rtm3basGCBerWrVuubS9cuFDDhg3Tr7/+qpo1a+q9997TkiVLtHbtWh0+fFiS9PXXX2vWrFnasWOHUlNT5efnp44dO2rEiBG5Hg8AAAAA9ghgAAAAABSpnADm2tOVAQAAAMCtjGvAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABZzvnEJAAAAANw8LjsJAAAA4HbEETAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGKcgy0d2drZOnDihChUqyGazObodAAAAAAAAAADgQIZh6M8//5S/v7+cnPI/xoUAJh8nTpxQ9erVHd0GAAAAAAAAAAAoQY4dO6Zq1arlW0MAk48KFSpI+uuB9PT0dHA3AAAAAAAAAADAkdLT01W9enUzP8gPAUw+ck475unpSQADAAAAAAAAAAAkqUCXLcn/BGUAAAAAAAAAAAAoNAIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWIwABgAAAAAAAAAAwGIEMAAAAAAAAAAAABYjgAEAAAAAAAAAALAYAQwAAAAAAAAAAIDFCGAAAAAAAAAAAAAsRgADAAAAAAAAAABgMQIYAAAAAAAAAAAAixHAAAAAAAAAAAAAWMzZ0Q2g9AocstzRLVzX4dGRjm4BAAAAAAAAAHAbI4DBbY0QCQAAAAAAAABQFAhggFKOEAkAAAAAAAAASh6uAQMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsJizoxsAgMAhyx3dwnUdHh3p6BYAAAAAAAAAlEIcAQMAAAAAAAAAAGAxAhgAAAAAAAAAAACLEcAAAAAAAAAAAABYjAAGAAAAAAAAAADAYgQwAAAAAAAAAAAAFiOAAQAAAAAAAAAAsBgBDAAAAAAAAAAAgMUIYAAAAAAAAAAAACxGAAMAAAAAAAAAAGAxZ0c3AAC3gsAhyx3dwnUdHh3p6BYAAAAAAACA2w5HwAAAAAAAAAAAAFiMAAYAAAAAAAAAAMBiBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxZwd3QAAwPEChyx3dAv5Ojw60tEtAAAAAAAAAIXCETAAAAAAAAAAAAAWI4ABAAAAAAAAAACwmEMCmKysLL311lsKCgqSu7u7atasqXfffVeGYZg1hmFo+PDhqlq1qtzd3RUeHq6DBw/arefMmTPq1auXPD095e3trejoaGVkZNjV7Ny5Uw888IDc3NxUvXp1jRkzpljGCAAAAAAAAAAAbl8OCWA++OADzZgxQx9++KH27t2rDz74QGPGjNHUqVPNmjFjxmjKlCmaOXOmEhMTVa5cOUVEROjChQtmTa9evbRnzx7Fx8dr2bJlWrdunWJiYsz56enpat++vQICApSUlKSxY8dqxIgRmjVrVrGOFwAAAAAAAAAA3F6cHbHRTZs2qUuXLoqM/OuiyoGBgfriiy+0efNmSX8d/TJp0iQNGzZMXbp0kSR9/vnn8vX11eLFi9WjRw/t3btXcXFx2rJli5o0aSJJmjp1qjp16qRx48bJ399fc+fO1aVLl/Tpp5/KxcVF99xzj3bs2KEJEybYBTUAAAAAAAAAAABWcsgRMGFhYVq9erUOHDggSfrxxx+1YcMGdezYUZJ06NAhJScnKzw83FzGy8tLzZo1U0JCgiQpISFB3t7eZvgiSeHh4XJyclJiYqJZ06pVK7m4uJg1ERER2r9/v86ePVvk4wQAAAAAAAAAALcnhxwBM2TIEKWnp6tOnToqU6aMsrKy9P7776tXr16SpOTkZEmSr6+v3XK+vr7mvOTkZFWpUsVuvrOzs3x8fOxqgoKCcq0jZ17FihXt5l28eFEXL14076enp//doQIAAAAAAAAAgNuQQ46A+e9//6u5c+dq3rx52rZtmz777DONGzdOn332mSPaMY0aNUpeXl7mrXr16g7tBwAAAAAAAAAAlE4OCWAGDx6sIUOGqEePHgoJCdHTTz+t1157TaNGjZIk+fn5SZJSUlLslktJSTHn+fn56dSpU3bzr1y5ojNnztjV5LWOq7dxtaFDhyotLc28HTt2zILRAgAAAAAAAACA241DAphz587Jycl+02XKlFF2drYkKSgoSH5+flq9erU5Pz09XYmJiQoNDZUkhYaGKjU1VUlJSWbNmjVrlJ2drWbNmpk169at0+XLl82a+Ph4BQcH5zr9mCS5urrK09PT7gYAAAAAAAAAAFBYDglgOnfurPfff1/Lly/X4cOHtWjRIk2YMEGPPvqoJMlms6l///567733tHTpUu3atUvPPPOM/P39FRUVJUmqW7euOnTooD59+mjz5s3auHGjYmNj1aNHD/n7+0uSnnzySbm4uCg6Olp79uzR/PnzNXnyZA0YMMARwwYAAAAAAAAAALcJZ0dsdOrUqXrrrbf08ssv69SpU/L399c//vEPDR8+3Kx5/fXXlZmZqZiYGKWmpqply5aKi4uTm5ubWTN37lzFxsbqwQcflJOTk7p27aopU6aY8728vLRq1Sr17dtXjRs3VuXKlTV8+HDFxMQU63gBAAAAAAAAAMDtxSEBTIUKFTRp0iRNmjTpujU2m03vvPOO3nnnnevW+Pj4aN68eflu695779X69etvtlUAAAAAAAAAAIBCc8gpyAAAAAAAAAAAAG5lBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALEYAAwAAAAAAAAAAYDECGAAAAAAAAAAAAIsRwAAAAAAAAAAAAFiMAAYAAAAAAAAAAMBiBDAAAAAAAAAAAAAWI4ABAAAAAAAAAACwGAEMAAAAAAAAAACAxQhgAAAAAAAAAAAALEYAAwAAAAAAAAAAYDFnRzcAAIAVAocsd3QL+To8OtLRLQAAAAAAAKAYEcAAAFBClOQQiQAJAAAAAACgcDgFGQAAAAAA/x97dx4mRXnuj/sZlhnWYVMGEATighBRBFwGjKCiIyLRuESjUVTQaECCeFw4x4OIydGoiEZR48aYxD3uYFjEgAqIiGJwCUSjQsJmVBhBBYT6/eFv+svIrjXTA9z3dfUFXfV29fNOdy3dn36rAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEhZtWwXAADsOFpdMTbbJWzSh9f1ynYJAAAAwE7ECBgAAAAAAICUGQEDALAeo3gAAACANBgBAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAyqpluwAAANLV6oqx2S5hkz68rle2SwAAAIAKYQQMAAAAAABAyoyAAQCg0jGKBwAAgO2dETAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKqmW7AAAA2BG1umJstkvYpA+v65XtEgAAAHZ4WRsB8+9//zt+/vOfR6NGjaJmzZrRvn37eO211zLzkySJoUOHRtOmTaNmzZrRo0eP+Mc//lFmGZ9++mmcccYZkZ+fH/Xr14++ffvGihUryrT529/+Fj/60Y+iRo0a0aJFi7j++usrpH8AAAAAAMDOKysBzGeffRZdu3aN6tWrx1/+8pd45513YsSIEdGgQYNMm+uvvz5+97vfxZ133hkzZsyI2rVrR1FRUXz11VeZNmeccUa8/fbbMXHixBgzZky8+OKLcf7552fml5SUxNFHHx0tW7aMWbNmxQ033BDDhg2Lu+66q0L7CwAAAAAA7Fyycgqy3/72t9GiRYsYPXp0Zlrr1q0z/0+SJG6++ea48sor4/jjj4+IiD/84Q9RUFAQTz31VJx22mnx7rvvxrhx42LmzJnRuXPniIi49dZb49hjj40bb7wxmjVrFg888ECsXr067rvvvsjNzY0f/vCHMXv27LjpppvKBDUAAAAAAABpysoImGeeeSY6d+4cp5xySjRu3DgOOOCAuPvuuzPzP/jgg1i8eHH06NEjM61evXpx8MEHx/Tp0yMiYvr06VG/fv1M+BIR0aNHj6hSpUrMmDEj0+awww6L3NzcTJuioqKYO3dufPbZZxvUtWrVqigpKSlzAwAAAAAA2FZZCWD++c9/xh133BF77bVXjB8/Pi688MIYOHBg3H///RERsXjx4oiIKCgoKPO4goKCzLzFixdH48aNy8yvVq1aNGzYsEybjS1j/edY37XXXhv16tXL3Fq0aJFCbwEAAAAAgJ1NVk5Btm7duujcuXP83//9X0REHHDAAfHWW2/FnXfeGX369MlGSRERMWTIkBg8eHDmfklJiRAGAICdVqsrxma7hE368Lpe2S4BAABgs7IyAqZp06bRrl27MtPatm0b8+fPj4iIJk2aRETEkiVLyrRZsmRJZl6TJk1i6dKlZeZ//fXX8emnn5Zps7FlrP8c68vLy4v8/PwyNwAAAAAAgG2VlREwXbt2jblz55aZNm/evGjZsmVERLRu3TqaNGkSkyZNig4dOkTEN6NRZsyYERdeeGFERBQWFsayZcti1qxZ0alTp4iIeOGFF2LdunVx8MEHZ9r8z//8T6xZsyaqV68eERETJ06MNm3aRIMGDSqiqwAAQBbtCKN4doQ+AADAzigrAczFF18cXbp0if/7v/+Ln/70p/Hqq6/GXXfdFXfddVdEROTk5MSgQYPi17/+dey1117RunXr+N///d9o1qxZnHDCCRHxzYiZY445Js4777y48847Y82aNTFgwIA47bTTolmzZhERcfrpp8fVV18dffv2jcsvvzzeeuutuOWWW2LkyJHZ6DYAAMBOSYgEAMDOKCsBzIEHHhhPPvlkDBkyJIYPHx6tW7eOm2++Oc4444xMm8suuyxWrlwZ559/fixbtiwOPfTQGDduXNSoUSPT5oEHHogBAwbEkUceGVWqVImTTjopfve732Xm16tXLyZMmBD9+/ePTp06xS677BJDhw6N888/v0L7CwAAwPZNiAQAwLbKSgATEXHcccfFcccdt8n5OTk5MXz48Bg+fPgm2zRs2DAefPDBzT7PfvvtFy+99NJ3rhMAAAC2d5U5QIoQIgEAO6asBTAAAAAAW0uIBABsb6pkuwAAAAAAAIAdjQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASFm1bBcAAAAAsDNodcXYbJewSR9e1yvbJQDADscIGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBl1bJdAAAAAADbh1ZXjM12CZv04XW9sl0CAJRhBAwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQsmrZLgAAAAAAKkqrK8Zmu4RN+vC6XtkuAYAUGQEDAAAAAACQMiNgAAAAAGA7YhQPwPZBAAMAAAAAVCghErAzcAoyAAAAAACAlBkBAwAAAACwjYziAbbECBgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUlYt2wUAAAAAAFDxWl0xNtslbNKH1/XKdgnwvRkBAwAAAAAAkDIjYAAAAAAA2C4ZxUNlZgQMAAAAAABAyoyAAQAAAACALDGKZ8dlBAwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkLKsBzDXXXdd5OTkxKBBgzLTvvrqq+jfv380atQo6tSpEyeddFIsWbKkzOPmz58fvXr1ilq1akXjxo3j0ksvja+//rpMm8mTJ0fHjh0jLy8v9txzzyguLq6AHgEAAAAAADu7rAYwM2fOjN///vex3377lZl+8cUXx7PPPhuPPfZYTJkyJRYuXBgnnnhiZv7atWujV69esXr16pg2bVrcf//9UVxcHEOHDs20+eCDD6JXr15x+OGHx+zZs2PQoEHRr1+/GD9+fIX1DwAAAAAA2DllLYBZsWJFnHHGGXH33XdHgwYNMtOXL18e9957b9x0001xxBFHRKdOnWL06NExbdq0eOWVVyIiYsKECfHOO+/En/70p+jQoUP07Nkzrrnmmhg1alSsXr06IiLuvPPOaN26dYwYMSLatm0bAwYMiJNPPjlGjhyZlf4CAAAAAAA7j6wFMP37949evXpFjx49ykyfNWtWrFmzpsz0ffbZJ3bfffeYPn16RERMnz492rdvHwUFBZk2RUVFUVJSEm+//XamzbeXXVRUlFnGxqxatSpKSkrK3AAAAAAAALZVtWw86cMPPxyvv/56zJw5c4N5ixcvjtzc3Khfv36Z6QUFBbF48eJMm/XDl9L5pfM216akpCS+/PLLqFmz5gbPfe2118bVV1/9nfsFAAAAAAAQkYURMAsWLIhf/epX8cADD0SNGjUq+uk3a8iQIbF8+fLMbcGCBdkuCQAAAAAA2A5VeAAza9asWLp0aXTs2DGqVasW1apViylTpsTvfve7qFatWhQUFMTq1atj2bJlZR63ZMmSaNKkSURENGnSJJYsWbLB/NJ5m2uTn5+/0dEvERF5eXmRn59f5gYAAAAAALCtKjyAOfLII2POnDkxe/bszK1z585xxhlnZP5fvXr1mDRpUuYxc+fOjfnz50dhYWFERBQWFsacOXNi6dKlmTYTJ06M/Pz8aNeuXabN+ssobVO6DAAAAAAAgPJS4deAqVu3buy7775lptWuXTsaNWqUmd63b98YPHhwNGzYMPLz8+Oiiy6KwsLCOOSQQyIi4uijj4527drFmWeeGddff30sXrw4rrzyyujfv3/k5eVFRMQFF1wQt912W1x22WVx7rnnxgsvvBCPPvpojB07tmI7DAAAAAAA7HQqPIDZGiNHjowqVarESSedFKtWrYqioqK4/fbbM/OrVq0aY8aMiQsvvDAKCwujdu3a0adPnxg+fHimTevWrWPs2LFx8cUXxy233BLNmzePe+65J4qKirLRJQAAAAAAYCdSKQKYyZMnl7lfo0aNGDVqVIwaNWqTj2nZsmU899xzm11u9+7d44033kijRAAAAAAAgK1W4deAAQAAAAAA2NEJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlWQlgrr322jjwwAOjbt260bhx4zjhhBNi7ty5Zdp89dVX0b9//2jUqFHUqVMnTjrppFiyZEmZNvPnz49evXpFrVq1onHjxnHppZfG119/XabN5MmTo2PHjpGXlxd77rlnFBcXl3f3AAAAAACAnVxWApgpU6ZE//7945VXXomJEyfGmjVr4uijj46VK1dm2lx88cXx7LPPxmOPPRZTpkyJhQsXxoknnpiZv3bt2ujVq1esXr06pk2bFvfff38UFxfH0KFDM20++OCD6NWrVxx++OExe/bsGDRoUPTr1y/Gjx9fof0FAAAAAAB2LtWy8aTjxo0rc7+4uDgaN24cs2bNisMOOyyWL18e9957bzz44INxxBFHRETE6NGjo23btvHKK6/EIYccEhMmTIh33nknnn/++SgoKIgOHTrENddcE5dffnkMGzYscnNz484774zWrVvHiBEjIiKibdu28fLLL8fIkSOjqKiowvsNAAAAAADsHCrFNWCWL18eERENGzaMiIhZs2bFmjVrokePHpk2++yzT+y+++4xffr0iIiYPn16tG/fPgoKCjJtioqKoqSkJN5+++1Mm/WXUdqmdBkAAAAAAADlISsjYNa3bt26GDRoUHTt2jX23XffiIhYvHhx5ObmRv369cu0LSgoiMWLF2farB++lM4vnbe5NiUlJfHll19GzZo1y8xbtWpVrFq1KnO/pKTk+3cQAAAAAADY6WR9BEz//v3jrbfeiocffjjbpcS1114b9erVy9xatGiR7ZIAAAAAAIDtUFYDmAEDBsSYMWPir3/9azRv3jwzvUmTJrF69epYtmxZmfZLliyJJk2aZNosWbJkg/ml8zbXJj8/f4PRLxERQ4YMieXLl2duCxYs+N59BAAAAAAAdj5ZCWCSJIkBAwbEk08+GS+88EK0bt26zPxOnTpF9erVY9KkSZlpc+fOjfnz50dhYWFERBQWFsacOXNi6dKlmTYTJ06M/Pz8aNeuXabN+ssobVO6jG/Ly8uL/Pz8MjcAAAAAAIBtlZVrwPTv3z8efPDBePrpp6Nu3bqZa7bUq1cvatasGfXq1Yu+ffvG4MGDo2HDhpGfnx8XXXRRFBYWxiGHHBIREUcffXS0a9cuzjzzzLj++utj8eLFceWVV0b//v0jLy8vIiIuuOCCuO222+Kyyy6Lc889N1544YV49NFHY+zYsdnoNgAAAAAAsJPIygiYO+64I5YvXx7du3ePpk2bZm6PPPJIps3IkSPjuOOOi5NOOikOO+ywaNKkSTzxxBOZ+VWrVo0xY8ZE1apVo7CwMH7+85/HWWedFcOHD8+0ad26dYwdOzYmTpwY+++/f4wYMSLuueeeKCoqqtD+AgAAAAAAO5esjIBJkmSLbWrUqBGjRo2KUaNGbbJNy5Yt47nnntvscrp37x5vvPHGNtcIAAAAAADwXWVlBAwAAAAAAMCOTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApGynCGBGjRoVrVq1iho1asTBBx8cr776arZLAgAAAAAAdmA7fADzyCOPxODBg+Oqq66K119/Pfbff/8oKiqKpUuXZrs0AAAAAABgB7XDBzA33XRTnHfeeXHOOedEu3bt4s4774xatWrFfffdl+3SAAAAAACAHVS1bBdQnlavXh2zZs2KIUOGZKZVqVIlevToEdOnT9+g/apVq2LVqlWZ+8uXL4+IiJKSkvIvdju0btUX2S5hk7b2NdOH8qUPlcPW9KEy1x+hD5XBzrIuROhDedOHykEfKgd9qBx2lj5U5voj9KEy2FnWhQh9KG/6UDnoQ+WwM/VhZ1L6N0mSZIttc5KtabWdWrhwYey2224xbdq0KCwszEy/7LLLYsqUKTFjxowy7YcNGxZXX311RZcJAAAAAABsRxYsWBDNmzffbJsdegTMthoyZEgMHjw4c3/dunXx6aefRqNGjSInJyeLle3YSkpKokWLFrFgwYLIz8/PdjnfiT5UDvpQOehD5aAPlYM+VA7bex+29/oj9KGy0IfKQR8qB32oHPShctCHymF778P2Xn+EPrD1kiSJzz//PJo1a7bFtjt0ALPLLrtE1apVY8mSJWWmL1myJJo0abJB+7y8vMjLyyszrX79+uVZIuvJz8/f7jcM+lA56EPloA+Vgz5UDvpQOWzvfdje64/Qh8pCHyoHfagc9KFy0IfKQR8qh+29D9t7/RH6wNapV6/eVrWrUs51ZFVubm506tQpJk2alJm2bt26mDRpUplTkgEAAAAAAKRphx4BExExePDg6NOnT3Tu3DkOOuiguPnmm2PlypVxzjnnZLs0AAAAAABgB7XDBzCnnnpqfPzxxzF06NBYvHhxdOjQIcaNGxcFBQXZLo3/X15eXlx11VUbnP5te6IPlYM+VA76UDnoQ+WgD5XD9t6H7b3+CH2oLPShctCHykEfKgd9qBz0oXLY3vuwvdcfoQ+Uj5wkSZJsFwEAAAAAALAj2aGvAQMAAAAAAJANAhgAAAAAAICUCWAAAAAAAABSJoABtnvFxcVRv379bJdRRpIkcf7550fDhg0jJycnZs+ene2SUtG9e/cYNGhQtsv4XiZPnhw5OTmxbNmybJfynewIr8GOYP3XoVWrVnHzzTdn5uXk5MRTTz2Vlbp2Jh9++OEOtX2l8qiMxxWVxbe3d+w8dqT1Yv19+BdffBEnnXRS5OfnV6rjw7PPPjtOOOGEbJdRLraHvm3vnxegPG3N/mBb1vOKPKZPa93O5uc926ftkwAG2IAvtb6/cePGRXFxcYwZMyYWLVoU++67b7ZL2mkJLChvM2fOjPPPPz/bZVCOKnuoNmzYsOjQoUO2ywDYosqwPX3iiSfimmuuiYiI+++/P1566aWYNm1aLFq0KOrVq5fV2krdcsstUVxcnMqyBKdb5vNC5bc9BHfZVNm+lE9zG/Z9lNe6vWjRoujZs2fqy92Yb/ehS5culWp/xdaplu0CAHZE77//fjRt2jS6dOmy0fmrV6+O3NzcCq6q8vF3YEew6667ZruErFmzZk1Ur14922WwnUuSJNauXRvVqvloAqUcI5Wfhg0bZv7//vvvR9u2bSvdj6V8sbZjctyUfZVt21rZ6knLjr4Na9KkyWbnl+e6npubu8Xnp/IxAga2wbhx4+LQQw+N+vXrR6NGjeK4446L999/PyL+36iRJ554Ig4//PCoVatW7L///jF9+vQsV71xm+tL69atIyLigAMOiJycnOjevXuF1zdmzJioX79+rF27NiIiZs+eHTk5OXHFFVdk2vTr1y9+/vOfZ+6PHz8+2rZtG3Xq1IljjjkmFi1alJm3bt26GD58eDRv3jzy8vKiQ4cOMW7cuHKp/eyzz46LLroo5s+fHzk5OdGqVavo3r17DBgwIAYNGhS77LJLFBUVRUTElClT4qCDDoq8vLxo2rRpXHHFFfH1119nltW9e/e46KKLYtCgQdGgQYMoKCiIu+++O1auXBnnnHNO1K1bN/bcc8/4y1/+Ui592Zh169bFZZddFg0bNowmTZrEsGHDMvOWLVsW/fr1i1133TXy8/PjiCOOiDfffDMzv/RX2vfcc0+0bt06atSoUa61nn322TFlypS45ZZbIicnJ3JycuLDDz+MiIhZs2ZF586do1atWtGlS5eYO3dumcc+/fTT0bFjx6hRo0b84Ac/iKuvvjrz2px77rlx3HHHlWm/Zs2aaNy4cdx7773l2qeIzb8GN910U7Rv3z5q164dLVq0iF/+8pexYsWKzPyPPvooevfuHQ0aNIjatWvHD3/4w3juuefKveYt+fOf/xzt27ePmjVrRqNGjaJHjx6xcuXKCl13v6st/bL0qquuiqZNm8bf/va3iIh4+eWX40c/+lHUrFkzWrRoEQMHDoyVK1eWe5133XVXNGvWLNatW1dm+vHHHx/nnntuRGz+fR/xzS+X77jjjvjxj38ctWvXjl//+tex5557xo033lhmmaXb7Pfee+971by5fVWpv//979GlS5eoUaNG7LvvvjFlypQy87e0nd3Y69ehQ4fMetWqVauIiPjJT36S2aanbdWqVTFw4MBo3Lhx1KhRIw499NCYOXNmRGz8NA9PPfVU5OTkZOZfffXV8eabb2a2c5XhF4eb61PprzT/8pe/RKdOnSIvLy9efvnlcq0n7eOKiIh77rkn2rZtGzVq1Ih99tknbr/99sy88j4u/Pzzz+OMM86I2rVrR9OmTWPkyJFlfiH52WefxVlnnRUNGjSIWrVqRc+ePeMf//hHmWU8/vjj8cMf/jDy8vKiVatWMWLEiDLzly5dGr17946aNWtG69at44EHHkil9u+6vS/9mz766KOZbeiBBx4Y8+bNi5kzZ0bnzp2jTp060bNnz/j444/LPOfmXqvv4rscn23NMd/GjhXfeuut6NmzZ9SpUycKCgrizDPPjP/85z/fq/5Saa8XM2fOjKOOOip22WWXqFevXnTr1i1ef/31zPyK2J5ujdJ1pXv37jFixIh48cUXs/aZZ1PW/7X/lvZTSZLEsGHDYvfdd4+8vLxo1qxZDBw4MCK+6etHH30UF198cWYfUVE2ta6XuvHGG6Np06bRqFGj6N+/f6xZsyYzb9WqVfFf//Vfsdtuu0Xt2rXj4IMPjsmTJ5dLneX1eSFiw+Om3/zmN1v1uLRtyzYrSZJyPbbbko29by699NK4//774+mnn868RqXvhzlz5sQRRxyRaX/++eeX+exTui795je/iWbNmkWbNm1i+PDhGw1dO3ToEP/7v//7verf0v65VatWcc0118RZZ50V+fn5mVH0W/p88Mc//jE6d+4cdevWjSZNmsTpp58eS5cujYhv9o+HH354REQ0aNAgcnJy4uyzz96mutPeH3x7xNK6devi+uuvjz333DPy8vJi9913z6wPpf75z3+mesxU3ut26WjO0uOTRx55JLp16xY1atRI7ZhpY30oLi4uM9qp9LPCmDFjok2bNlGrVq04+eST44svvoj7778/WrVqFQ0aNIiBAwdmXt+Iit3OEhEJsNX+/Oc/J48//njyj3/8I3njjTeS3r17J+3bt0/Wrl2bfPDBB0lEJPvss08yZsyYZO7cucnJJ5+ctGzZMlmzZk22S9/A5vry6quvJhGRPP/888miRYuSTz75pMLrW7ZsWVKlSpVk5syZSZIkyc0335zssssuycEHH5xps+eeeyZ33313Mnr06KR69epJjx49kpkzZyazZs1K2rZtm5x++umZtjfddFOSn5+fPPTQQ8nf//735LLLLkuqV6+ezJs3r1xqHz58eNK8efNk0aJFydKlS5Nu3bolderUSS699NLk73//e/L3v/89+de//pXUqlUr+eUvf5m8++67yZNPPpnssssuyVVXXZVZVrdu3ZK6desm11xzTTJv3rzkmmuuSapWrZr07Nkzueuuu5J58+YlF154YdKoUaNk5cqVqffl27p165bk5+cnw4YNS+bNm5fcf//9SU5OTjJhwoQkSZKkR48eSe/evZOZM2cm8+bNSy655JKkUaNGmffQVVddldSuXTs55phjktdffz158803y7XeZcuWJYWFhcl5552XLFq0KFm0aFHy/PPPJxGRHHzwwcnkyZOTt99+O/nRj36UdOnSJfO4F198McnPz0+Ki4uT999/P5kwYULSqlWrZNiwYUmSJMnUqVOTqlWrJgsXLsw85oknnkhq166dfP755+Xapy29BiNHjkxeeOGF5IMPPkgmTZqUtGnTJrnwwgszj+/Vq1dy1FFHJX/729+S999/P3n22WeTKVOmlGvNW7Jw4cKkWrVqyU033ZR88MEHyd/+9rdk1KhRyeeff16h6+626NatW/KrX/0qSZIkadmyZTJy5MjMvIhInnzyyWTdunXJgAEDklatWiX/+Mc/kiRJkvfeey+pXbt2MnLkyGTevHnJ1KlTkwMOOCA5++yzy73mTz/9NMnNzU2ef/75zLRPPvkkM21L7/vSvjVu3Di57777kvfffz/56KOPkt/85jdJu3btyjzXwIEDk8MOO+x717w1+93mzZsnf/7zn5N33nkn6devX1K3bt3kP//5T5IkyVZtZ7/9+iVJkuy///6ZNkuXLk0iIhk9enRmm562gQMHJs2aNUuee+655O2330769OmTNGjQIPnkk0+S0aNHJ/Xq1SvT/sknn0xKD+O/+OKL5JJLLkl++MMfZrZzX3zxReo1bqvN9emvf/1rEhHJfvvtl0yYMCF57733yv1YI+3jij/96U9J06ZNk8cffzz55z//mTz++ONJw4YNk+Li4iRJknI/LuzXr1/SsmXL5Pnnn0/mzJmT/OQnP0nq1q2b2S79+Mc/Ttq2bZu8+OKLyezZs5OioqJkzz33TFavXp0kSZK89tprSZUqVZLhw4cnc+fOTUaPHp3UrFkzGT16dOY5evbsmey///7J9OnTk9deey3p0qVLUrNmzQ3Wl23xfbb36/9Nx40bl7zzzjvJIYccknTq1Cnp3r178vLLLyevv/56sueeeyYXXHBB5jm39Fp9F9t6fLa1x3zfPlb87LPPkl133TUZMmRI8u677yavv/56ctRRRyWHH374d659fWmvF5MmTUr++Mc/Ju+++27yzjvvJH379k0KCgqSkpKSJEkqZnu6NUr34Z988kly3nnnJYWFhVn7zLMpffr0SY4//vgkSba8n3rssceS/Pz85Lnnnks++uijZMaMGcldd92VJMk3+/nmzZsnw4cPz+wjKsLm1vU+ffok+fn5yQUXXJC8++67ybPPPpvUqlUrU3OSfLON69KlS/Liiy8m7733XnLDDTckeXl55fbZrTw+LyTJxo+btuZxadvWbVZ5HtttzubeNz/96U+TY445JvMarVq1KlmxYkXStGnT5MQTT0zmzJmTTJo0KWndunXSp0+fzDL79OmT1KlTJznzzDOTt956K3nrrbeSBQsWJFWqVEleffXVTLvXX389ycnJSd5///3v1Yct7Z9btmyZ5OfnJzfeeGPy3nvvZW5b+nxw7733Js8991zy/vvvJ9OnT08KCwuTnj17JkmSJF9//XXy+OOPJxGRzJ07N1m0aFGybNmybao77f3B+tuwJEmSyy67LGnQoEFSXFycvPfee8lLL72U3H333UmSlN8xU3mv208++WSZ+lu1apU51lj/e4LvY3N9+Oyzz5IkSTKvx1FHHZW8/vrryZQpU5JGjRolRx99dPLTn/40efvtt5Nnn302yc3NTR5++OHMsityO0uSCGDge/j444+TiEjmzJmT2ejec889mflvv/12EhHJu+++m8Uqt87G+vLGG29ktaaOHTsmN9xwQ5IkSXLCCSckv/nNb5Lc3Nzk888/T/71r38lEZHMmzcvGT16dBIRyXvvvZd57KhRo5KCgoLM/WbNmiW/+c1vyiz/wAMPTH75y1+WS+0jR45MWrZsmbnfrVu35IADDijT5r//+7+TNm3aJOvWrStTd506dZK1a9dmHnfooYdm5n/99ddJ7dq1kzPPPDMzbdGiRUlEJNOnTy+Xvqzv2/UkyTd/x8svvzx56aWXkvz8/OSrr74qM3+PPfZIfv/73ydJ8k0AU7169Qr9wL3+F+VJkmS++Fv/S+ixY8cmEZF8+eWXSZIkyZFHHpn83//9X5nl/PGPf0yaNm2aud+uXbvkt7/9beZ+7969K+RL9M29Bhvz2GOPJY0aNcrcb9++fbl+wPsuZs2alURE8uGHH24wr6LX3a21pQDmscceS04//fSkbdu2yb/+9a/MvL59+ybnn39+mWW99NJLSZUqVTLvv/J0/PHHJ+eee27m/u9///ukWbNmydq1a7fqfR8RyaBBg8q0+fe//51UrVo1mTFjRpIkSbJ69epkl112+V5fbm7KxvZV1113XWb+mjVrkubNm2fWza3Zzm7pi60kKfshK20rVqxIqlevnjzwwAOZaatXr06aNWuWXH/99VsMYJLkm23r/vvvXy71fRdb6lPpdvipp56q0LrSPK7YY489kgcffLDM8q+55pqksLAwSZKkXI8LS0pKkurVqyePPfZYZtqyZcuSWrVqJb/61a+SefPmJRGRTJ06NTP/P//5T1KzZs3k0UcfTZIkSU4//fTkqKOOKrPcSy+9NPOF29y5c5OIKPPl1LvvvptExPcKYL7P9n5jf9OHHnooiYhk0qRJmWnXXntt0qZNm8z9Lb1W38W2Hp9t7THft48Vr7nmmuToo48uM23BggWZL9nSkOZ68W1r165N6tatmzz77LOZaeW5Pd1a6+/Df/WrXyXdunXLaj0bsy0BzIgRI5K99947E7B+28YeX942t6736dMnadmyZfL1119npp1yyinJqaeemiRJknz00UdJ1apVk3//+99lHnfkkUcmQ4YMKZd6y+vzwsaOm7bmcWnb1m1WRR7brW9L75v1v9BPkiS56667kgYNGiQrVqzITBs7dmxSpUqVZPHixZnHFRQUJKtWrSrz2J49e5b5kdpFF12UdO/e/XvVv6X9c5J8sz6ecMIJZR73XT4fzJw5M4mIzI//St+zpV/Kfxdp7g/Wf71KSkqSvLy8TODybeV5zFSe6/a3A5ibb775e9W6rX1YP4D59uvxi1/8IqlVq1aZH4cWFRUlv/jFL5Ikyc52dmfnFGSwDf7xj3/Ez372s/jBD34Q+fn5mWHz8+fPz7TZb7/9Mv9v2rRpRERmaGhlsjV9ybZu3brF5MmTI0mSeOmll+LEE0+Mtm3bxssvvxxTpkyJZs2axV577RUREbVq1Yo99tgj89imTZtm/u4lJSWxcOHC6Nq1a5nld+3aNd59990K60+nTp3K3H/33XejsLCwzKkAunbtGitWrIh//etfmWnrv6eqVq0ajRo1ivbt22emFRQURETFvc/Wryfi//2t33zzzVixYkU0atQo6tSpk7l98MEHZU4Z1LJly0pxzYzNratvvvlmDB8+vEw/zjvvvFi0aFF88cUXEfHNEOzRo0dHRMSSJUviL3/5S+Y0ThVZe2n9pbU///zzceSRR8Zuu+0WdevWjTPPPDM++eSTTN0DBw6MX//619G1a9e46qqrMqfFyqb9998/jjzyyGjfvn2ccsopcffdd8dnn31Wadbd7+Liiy+OGTNmxIsvvhi77bZbZvqbb74ZxcXFZd5bRUVFsW7duvjggw/Kva4zzjgjHn/88Vi1alVERDzwwANx2mmnRZUqVbbqfR8R0blz5zLLbNasWfTq1Svuu+++iIh49tlnY9WqVXHKKad873q3Zl9VWFiY+X+1atWic+fOmffH1m5ns+n999+PNWvWlHmfV69ePQ466KBK/z7flK3t07ffS+UtreOKlStXxvvvvx99+/Yts778+te/3uAUeeVxXPjPf/4z1qxZEwcddFBmWr169aJNmzYR8c37vlq1anHwwQdn5jdq1CjatGlTZt3Y2Lb1H//4R6xduzazjPWPXfbZZ58NToe3rdLY3q//Ny09Bvr2cdF3ea221bYcn23ttujbx4pvvvlm/PWvfy1T+z777BMR8b3rL5XWehHxzfHQeeedF3vttVfUq1cv8vPzY8WKFZXq88WO6JRTTokvv/wyfvCDH8R5550XTz75ZLmezmprbGpdL/XDH/4wqlatmrm//ntpzpw5sXbt2th7773LvPenTJmS2vt+a33fzwsRG+7rtvZx5dmXLW2zyvPYbnO29L75tnfffTf233//qF27dmZa165dY926dWVOKdW+ffsNrrNy3nnnxUMPPRRfffVVrF69Oh588MHv/VluS/vnUht7T2zp88GsWbOid+/esfvuu0fdunWjW7duEZHu9zdp7g/W9+6778aqVaviyCOP3OzzV+R3aWms299W0ce16/v261FQUBCtWrWKOnXqlJlWGbezOwtXuoRt0Lt372jZsmXcfffdmfPo77vvvrF69epMm/UvtFX6Ievb59uvDLamL9nWvXv3uO++++LNN9+M6tWrxz777BPdu3ePyZMnx2effZY56IiIDS5wlpOTE0mSVHTJm7X+geG22Fjfsvk+21g969atixUrVkTTpk03et7Q9b+w+a5/h7Rt7m+4YsWKuPrqq+PEE0/c4HGl160566yz4oorrojp06fHtGnTonXr1vGjH/2oAirf9Gvw4YcfxnHHHRcXXnhh/OY3v4mGDRvGyy+/HH379o3Vq1dHrVq1ol+/flFUVBRjx46NCRMmxLXXXhsjRoyIiy66qEJq35iqVavGxIkTY9q0aTFhwoS49dZb43/+539i4sSJWavp+zrqqKPioYceivHjx8cZZ5yRmb5ixYr4xS9+kTk3+/p23333cq+rd+/ekSRJjB07Ng488MB46aWXYuTIkZnatvS+j9j4OtyvX78488wzY+TIkTF69Og49dRTo1atWqnUW977qipVqmywv1j/PPTZVtnr+z4qen+Q1nFF6bnl77777jIhR0SU+ULx28upzMeFFSWN7f3G/qbfnrb+/jxi616rbVUex2ffXidWrFgRvXv3jt/+9rcbtC39wuj7SvN4u0+fPvHJJ5/ELbfcEi1btoy8vLwoLCysVJ8vtkdb2g+0aNEi5s6dG88//3xMnDgxfvnLX8YNN9wQU6ZMydoF3ze1rs+YMSMiNn0sG/HN+75q1aoxa9asDdbT9b9MrAjf9/NCxMbX6615XNq2dZtVXsd2m7Ol9813tbHjjd69e0deXl48+eSTkZubG2vWrImTTz75ez3Pd61nS58PVq5cGUVFRVFUVBQPPPBA7LrrrjF//vwoKipKdftaXt+/1KxZc6uevyKPmdJYt78tm99zbGn9Lp1WGbezOwsBDGylTz75JObOnRt333135kvW8r5gbHnZUl9Kfx2y/gW6suFHP/pRfP755zFy5MjMzr579+5x3XXXxWeffRaXXHLJVi0nPz8/mjVrFlOnTi1z0DB16tQyv06paG3bto3HH388kiTJ7PSnTp0adevWjebNm2etru+qY8eOsXjx4qhWrVrWLqq6Mbm5udv8Xu7YsWPMnTs39txzz022adSoUZxwwgkxevTomD59epxzzjnft9TvbdasWbFu3boYMWJEVKnyzSDXRx99dIN2LVq0iAsuuCAuuOCCGDJkSNx9991ZDWAivjkg7Nq1a3Tt2jWGDh0aLVu2jEmTJlXKdXdr/PjHP47evXvH6aefHlWrVo3TTjstIr55b73zzjubfW+Vpxo1asSJJ54YDzzwQLz33nvRpk2b6NixY6a2Lb3vN+XYY4+N2rVrxx133BHjxo2LF1988XvXurX73VdeeSUOO+ywiIj4+uuvY9asWTFgwICI2Lrt7K677lrmoqElJSUbjEaqXr16ue0T99hjj8jNzY2pU6dGy5YtI+KbL9ZmzpwZgwYNil133TU+//zzWLlyZeaD3ezZs8ss47ts58rTlvqULWkdVxQUFESzZs3in//8Z5mAtaL84Ac/iOrVq8fMmTMzwe3y5ctj3rx5cdhhh0Xbtm3j66+/jhkzZkSXLl0i4v+tT+3atYuIb9aNqVOnllnu1KlTY++9946qVavGPvvsk1mfDjzwwIiImDt3buaCr99HRW7vs/1alfqux3wdO3aMxx9/PFq1ahXVqpXPR/e01ouIb/p0++23x7HHHhsREQsWLIj//Oc/ZdqU5/Z0R7U1+6maNWtG7969o3fv3tG/f//YZ599Ys6cOdGxY8es7SM2tq4/+eSTW3zcAQccEGvXro2lS5dW2I+byuvzQpqPq2jlcWy3NTb1vtnYa9S2bdsoLi4uc4w0derUqFKlygajTr6tWrVq0adPnxg9enTk5ubGaaedttVBwaZsaf+8KVv6fDBnzpz45JNP4rrrrosWLVpERMRrr71Wpk0a3+GkuT9Y31577RU1a9aMSZMmRb9+/b5zfd9FRa7b5aU8tuHZ2M7u7AQwsJUaNGgQjRo1irvuuiuaNm0a8+fPjyuuuCLbZX0nW+pL48aNo2bNmjFu3Lho3rx51KhRI+rVq5eVOvfbb7944IEH4rbbbouIiMMOOyx++tOfxpo1a8p8QN+SSy+9NK666qrYY489okOHDjF69OiYPXt2PPDAA+VV/hb98pe/jJtvvjkuuuiiGDBgQMydOzeuuuqqGDx4cObL8+1Jjx49orCwME444YS4/vrrY++9946FCxfG2LFj4yc/+UnWhuS2atUqZsyYER9++GHUqVNnq35FM3To0DjuuONi9913j5NPPjlzeqa33norfv3rX2fa9evXL4477rhYu3Zt9OnTpzy7sVX23HPPWLNmTdx6663Ru3fvmDp1atx5551l2gwaNCh69uwZe++9d3z22Wfx17/+Ndq2bZulir8xY8aMmDRpUhx99NHRuHHjmDFjRnz88cfRtm3bSrnubq2f/OQn8cc//jHOPPPMqFatWpx88slx+eWXxyGHHBIDBgyIfv36Re3ateOdd96JiRMnZrZz5e2MM86I4447Lt5+++34+c9/npm+te/7jalatWqcffbZMWTIkNhrr73KnBbsu9ra/e6oUaNir732irZt28bIkSPjs88+y5xCYmu2s0cccUQUFxdH7969o379+jF06NANfgnWqlWrmDRpUnTt2jXy8vKiQYMG37t/pWrXrh0XXnhhXHrppdGwYcPYfffd4/rrr48vvvgi+vbtG0mSRK1ateK///u/Y+DAgTFjxowoLi7eoL4PPvggZs+eHc2bN4+6detGXl5eajVuqy316c0338xKXWkeV1x99dUxcODAqFevXhxzzDGxatWqeO211+Kzzz6LwYMHl1cXIiKibt260adPn8zft3HjxnHVVVdFlSpVIicnJ/baa684/vjj47zzzovf//73Ubdu3bjiiitit912i+OPPz4iIi655JI48MAD45prrolTTz01pk+fHrfddlvcfvvtERHRpk2bOOaYY+IXv/hF3HHHHVGtWrUYNGjQ9/5yKhvb+2y+VqW+6zFf//794+67746f/exncdlll0XDhg3jvffei4cffjjuueee7z2KJyLd9WKvvfaKP/7xj9G5c+coKSmJSy+9dIP3THluT3dUW9pPFRcXx9q1a+Pggw+OWrVqxZ/+9KeoWbNmJgBv1apVvPjii3HaaadFXl5e7LLLLuVe8+bW9S2d/nbvvfeOM844I84666wYMWJEHHDAAfHxxx/HpEmTYr/99otevXqlXm95fl5I63EVrTyO7bZkc++br776KsaPHx9z586NRo0aRb169eKMM86Iq666Kvr06RPDhg2Ljz/+OC666KI488wzM6dU25x+/fplPgd9+0cJ38WW9s+bsqXPB7vvvnvk5ubGrbfeGhdccEG89dZbcc0115RZRsuWLSMnJyfGjBkTxx57bNSsWXObRzKkuT9YX40aNeLyyy+Pyy67LHJzc6Nr167x8ccfx9tvvx19+/b9TsvcWhW5bpeX79KHLcnGdnZnt/19wwdZUqVKlXj44Ydj1qxZse+++8bFF18cN9xwQ7bL+k621Jdq1arF7373u/j9738fzZo1y3xYz4Zu3brF2rVro3v37hER0bBhw2jXrl00adJki79qWd/AgQNj8ODBcckll0T79u1j3Lhx8cwzz2TOYZoNu+22Wzz33HPx6quvxv777x8XXHBB9O3bN6688sqs1fR95OTkxHPPPReHHXZYnHPOObH33nvHaaedFh999NFWHQCXl//6r/+KqlWrRrt27TLDtbekqKgoxowZExMmTIgDDzwwDjnkkBg5cmTmg2ypHj16RNOmTaOoqCiaNWtWXl3Yavvvv3/cdNNN8dvf/jb23XffeOCBB+Laa68t02bt2rXRv3//aNu2bRxzzDGx9957Z75wy5b8/Px48cUX49hjj4299947rrzyyhgxYkT07NmzUq672+Lkk0+O+++/P84888x44oknYr/99ospU6bEvHnz4kc/+lEccMABMXTo0Ap9/xxxxBHRsGHDmDt3bpx++umZ6Vv7vt+U0lPdpTUabGv3u9ddd11cd911sf/++8fLL78czzzzTObLpa3Zzg4ZMiS6desWxx13XPTq1StOOOGEMudQjogYMWJETJw4MVq0aBEHHHBAKv37dh9OOumkOPPMM6Njx47x3nvvxfjx46NBgwbRsGHD+NOf/hTPPfdctG/fPh566KEYNmxYmcefdNJJccwxx8Thhx8eu+66azz00EOp17itNtenbErruKJfv35xzz33xOjRo6N9+/bRrVu3KC4ujtatW5dT5WXddNNNUVhYGMcdd1z06NEjunbtGm3bts2cGmP06NHRqVOnOO6446KwsDCSJInnnnsuczqKjh07xqOPPhoPP/xw7LvvvjF06NAYPnx4nH322ZnnGD16dDRr1iy6desWJ554Ypx//vnRuHHj71V3Nrb32X6tIr77MV/pqKC1a9fG0UcfHe3bt49BgwZF/fr1U/2xTlrrxb333hufffZZdOzYMc4888wYOHDgBu+Z8t6e7oi2tJ+qX79+3H333dG1a9fYb7/94vnnn49nn302GjVqFBERw4cPjw8//DD22GOPCrsO4+bW9a0xevToOOuss+KSSy6JNm3axAknnFBmVEHayvPzQlqPy4a0j+22ZHPvm/POOy/atGkTnTt3jl133TWmTp0atWrVivHjx8enn34aBx54YJx88slx5JFHbvWPmvbaa6/o0qVL7LPPPhucpvK72tL+eWO29Plg1113jeLi4njssceiXbt2cd1118WNN95YZhm77bZbXH311XHFFVdEQUFBZjT4tkprf/Bt//u//xuXXHJJDB06NNq2bRunnnpqhVzDtiLX7fLyXfqwNSp6O7uzy0kq20USAGA7sWLFithtt91i9OjRGz1HLOxMXnrppTjyyCNjwYIFWQ1dYWe0cuXK2G233WLEiBHl/mtSoPz97Gc/i6pVq8af/vSnbJfCTmxHP7ZLkiT22muv+OUvf1luIyLtn4EIpyADgG22bt26+M9//hMjRoyI+vXrx49//ONslwRZs2rVqvj4449j2LBhccopp+yQH9ChsnnjjTfi73//exx00EGxfPnyGD58eEREVkctA9/f119/HfPmzYvp06fHL37xi2yXw05qZzi2+/jjj+Phhx+OxYsXpzrCx/4Z2BgBDABso/nz50fr1q2jefPmUVxcXG4XxoXtwUMPPRR9+/aNDh06xB/+8IdslwM7jRtvvDHmzp0bubm50alTp3jppZcq5NoOQPl56623okuXLnH44YfHBRdckO1y2EntDMd2jRs3jl122SXuuuuu1E+Pav8MfJtTkAEAAAAAAKQsvSv3AQAAAAAAEBECGAAAAAAAgNQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAgB3Q2WefHa1atcp2GQAAsNMSwAAAAKnJycnZqtvkyZPLtY4vv/wy+vbtG/vuu2/Uq1cv6tSpE/vvv3/ccsstsWbNmg3aL1u2LM4///zYddddo3bt2nH44YfH66+/vsXnOfbYY6NBgwaRJEmZ6W+88Ubk5OREy5YtN3jMCy+8EDk5OXHXXXd99w4CAACVXrVsFwAAAOw4/vjHP5a5/4c//CEmTpy4wfS2bduWax1ffvllvP3223HsscdGq1atokqVKjFt2rS4+OKLY8aMGfHggw9m2q5bty569eoVb775Zlx66aWxyy67xO233x7du3ePWbNmxV577bXJ5zn00EPjL3/5S7z11lvRvn37zPSpU6dGtWrVYv78+fGvf/0rmjdvXmZe6WMBAIAdlwAGAABIzc9//vMy91955ZWYOHHiBtPLW8OGDeOVV14pM+2CCy6IevXqxW233RY33XRTNGnSJCIi/vznP8e0adPisccei5NPPjkiIn7605/G3nvvHVdddVWZsObbSkOUl19+eYMA5thjj40XXnghXn755TjttNMy815++eVo1KjR9w6hvvrqq8jNzY0qVZzYAAAAKiNH6gAAQIVauXJlXHLJJdGiRYvIy8uLNm3axI033rjBabxycnJiwIAB8cADD0SbNm2iRo0a0alTp3jxxRe/83OXXhNl2bJlmWl//vOfo6CgIE488cTMtF133TV++tOfxtNPPx2rVq3a5PIOOuigyM3NzYxqKTV16tQ47LDD4qCDDiozb926dfHKK69Ely5dIicnJyIi/vnPf8Ypp5wSDRs2jFq1asUhhxwSY8eOLbO8yZMnR05OTjz88MNx5ZVXxm677Ra1atWKkpKSiIh46qmnYt99940aNWrEvvvuG08++eRG63344YejU6dOUbdu3cjPz4/27dvHLbfcsuU/HAAAsM2MgAEAACpMkiTx4x//OP76179G3759o0OHDjF+/Pi49NJL49///neMHDmyTPspU6bEI488EgMHDoy8vLy4/fbb45hjjolXX3019t133y0+3+rVq6OkpCS+/PLLeO211+LGG2+Mli1bxp577plp88Ybb0THjh03GEly0EEHxV133RXz5s0rM7plfaWh0Msvv5yZtmDBgliwYEF06dIlli1bViZMmTNnTpSUlGRGzixZsiS6dOkSX3zxRQwcODAaNWoU999/f/z4xz+OP//5z/GTn/ykzPNdc801kZubG//1X/8Vq1atitzc3JgwYUKcdNJJ0a5du7j22mvjk08+iXPOOafMac8iIiZOnBg/+9nP4sgjj4zf/va3ERHx7rvvxtSpU+NXv/rVFv+WAADAthHAAAAAFeaZZ56JF154IX7961/H//zP/0RERP/+/eOUU06JW265JQYMGBB77LFHpv1bb70Vr732WnTq1CkiIk477bRo06ZNDB06NJ544oktPt8TTzwRP/vZzzL3O3fuHPfdd19Uq/b/PgotWrQoDjvssA0e27Rp04iIWLhw4SYDmIhvTkN2ww03xL///e/YbbfdYurUqZlgZtmyZXHttdfG559/HnXr1s0ENaUBzHXXXRdLliyJl156KTPtvPPOi/322y8GDx4cxx9/fJlg6KuvvorXXnstatasmZl2+eWXR0FBQbz88stRr169iIjo1q1bHH300dGyZctMu7Fjx0Z+fn6MHz8+qlatusW/HQAA8P04BRkAAFBhnnvuuahatWoMHDiwzPRLLrkkkiSJv/zlL2WmFxYWZsKXiIjdd989jj/++Bg/fnysXbt2i893+OGHx8SJE+Oxxx6LCy64IKpXrx4rV64s0+bLL7+MvLy8DR5bo0aNzPzNKQ1OXnrppYj45vRjnTp1itzc3CgsLMycdqx0Xo0aNaJz586Zv8dBBx2UWUZERJ06deL888+PDz/8MN55550yz9WnT58y4cuiRYti9uzZ0adPn0z4EhFx1FFHRbt27co8tn79+rFy5cqYOHHiZvsDAACkQwADAABUmI8++iiaNWsWdevWLTO99IL0H330UZnpe+211wbL2HvvveOLL76Ijz/+eIvPV1BQED169IiTTz457rjjjjjuuOPiqKOOisWLF2fa1KxZc6PXefnqq68y8zena9eukZOTk7nWy9SpU6Nr164R8U3o0a5duzLzDjzwwMjNzc30t02bNhssc1N/j9atW5e5Xzp/Y3+nby/3l7/8Zey9997Rs2fPaN68eZx77rkxbty4zfYNAAD47gQwAADATuPkk0+OFStWxNNPP52Z1rRp01i0aNEGbUunNWvWbLPLbNSoUeyzzz7x8ssvx4oVK+Jvf/tbdOnSJTO/S5cu8fLLL8e//vWvmD9/fpnRLttqS2HQ5jRu3Dhmz54dzzzzTOY6PD179ow+ffp852UCAACbJoABAAAqTMuWLWPhwoXx+eefl5n+97//PTN/ff/4xz82WMa8efOiVq1aseuuu27z85eeTmz58uWZaR06dIjXX3891q1bV6btjBkzolatWrH33ntvcbmHHnpozJkzJyZMmBBr167dIICZMWNGTJ48OdO2VMuWLWPu3LkbLG9Tf49vK52/sb/Txpabm5sbvXv3jttvvz3ef//9+MUvfhF/+MMf4r333ttiHwEAgG0jgAEAACrMscceG2vXro3bbrutzPSRI0dGTk5O9OzZs8z06dOnx+uvv565v2DBgnj66afj6KOP3uyF5P/zn/9EkiQbTL/nnnsiIjLXYIn4ZlTMkiVL4oknnijz+Mceeyx69+690evDfNuhhx4aa9eujRtvvDH22muvMuFQly5dYsWKFXH77bdHlSpVyoQzxx57bLz66qsxffr0zLSVK1fGXXfdFa1atdrgOi7f1rRp0+jQoUPcf//9ZUKliRMnbnD9mE8++aTM/SpVqsR+++0XEbHRU7ABAADfT7VsFwAAAOw8evfuHYcffnj8z//8T3z44Yex//77x4QJE+Lpp5+OQYMGxR577FGm/b777htFRUUxcODAyMvLi9tvvz0iIq6++urNPs+f/vSnuPPOO+OEE06IH/zgB/H555/H+PHjY+LEidG7d+844ogjMm1PPvnkOOSQQ+Kcc86Jd955J3bZZZe4/fbbY+3atVt8nlKlo1qmT58eZ599dpl5e++9d+yyyy4xffr0aN++fdSvXz8z74orroiHHnooevbsGQMHDoyGDRvG/fffHx988EE8/vjjUaXKln8zd+2110avXr3i0EMPjXPPPTc+/fTTuPXWW+OHP/xhrFixItOuX79+8emnn8YRRxwRzZs3j48++ihuvfXW6NChQ+aaMwAAQHoEMAAAQIWpUqVKPPPMMzF06NB45JFHYvTo0dGqVau44YYb4pJLLtmgfbdu3aKwsDCuvvrqmD9/frRr1y6Ki4szIzc25dBDD41p06bFQw89FEuWLIlq1apFmzZt4qabboqLLrqoTNuqVavGc889F5deemn87ne/iy+//DIOPPDAKC4u3uBC9pvygx/8IJo1axYLFy4sM8KlVJcuXeKZZ57Z4PovBQUFMW3atLj88svj1ltvja+++ir222+/ePbZZ6NXr15b9dzHHHNMPPbYY3HllVfGkCFDYo899ojRo0fH008/nTntWUTEz3/+87jrrrvi9ttvj2XLlkWTJk3i1FNPjWHDhm1V0AMAAGybnGRj4/IBAACyLCcnJ/r377/B6coAAAC2B37mBAAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACmrlu0CAAAANsblKgEAgO2ZETAAAAAAAAApE8AAAAAAAACkzCnINmPdunWxcOHCqFu3buTk5GS7HAAAAAAAIIuSJInPP/88mjVrFlWqbH6MiwBmMxYuXBgtWrTIdhkAAAAAAEAlsmDBgmjevPlm2whgNqNu3boR8c0fMj8/P8vVAAAAAAAA2VRSUhItWrTI5AebI4DZjNLTjuXn5wtgAAAAAACAiIitumzJ5k9QBgAAAAAAwDYTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMqqZbsAtl+trhib7RI26cPremW7BAAAAAAAdmJGwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkLJq2S4AsqnVFWOzXcImfXhdr2yXAAAAAADAdySAge2cEAkAAAAAoPIRwABZJ0QCAAAAAHY0rgEDAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApKxatgsA2BG0umJstkvYpA+v65XtEgAAAABgp2MEDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkrFq2CwAg+1pdMTbbJWzWh9f1ynYJAAAAALBNjIABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASFm1bBcAAGlodcXYbJewWR9e1yvbJQAAAABQgYyAAQAAAAAASJkRMABQSVTmUTxG8AAAAABsGyNgAAAAAAAAUmYEDACQmh1hFM+O0AcAAAAg+7I+Aua6666LnJycGDRoUGbaV199Ff37949GjRpFnTp14qSTToolS5aUedz8+fOjV69eUatWrWjcuHFceuml8fXXX5dpM3ny5OjYsWPk5eXFnnvuGcXFxRXQIwAAAAAAYGeX1QBm5syZ8fvf/z7222+/MtMvvvjiePbZZ+Oxxx6LKVOmxMKFC+PEE0/MzF+7dm306tUrVq9eHdOmTYv7778/iouLY+jQoZk2H3zwQfTq1SsOP/zwmD17dgwaNCj69esX48ePr7D+AQAAAAAAO6esBTArVqyIM844I+6+++5o0KBBZvry5cvj3nvvjZtuuimOOOKI6NSpU4wePTqmTZsWr7zySkRETJgwId55553405/+FB06dIiePXvGNddcE6NGjYrVq1dHRMSdd94ZrVu3jhEjRkTbtm1jwIABcfLJJ8fIkSOz0l8AAAAAAGDnkbUApn///tGrV6/o0aNHmemzZs2KNWvWlJm+zz77xO677x7Tp0+PiIjp06dH+/bto6CgINOmqKgoSkpK4u233860+fayi4qKMssAAAAAAAAoL9Wy8aQPP/xwvP766zFz5swN5i1evDhyc3Ojfv36ZaYXFBTE4sWLM23WD19K55fO21ybkpKS+PLLL6NmzZobPPeqVati1apVmfslJSXb3jkAAAAAAGCnV+EjYBYsWBC/+tWv4oEHHogaNWpU9NNv1rXXXhv16tXL3Fq0aJHtkgAAAAAAgO1QhY+AmTVrVixdujQ6duyYmbZ27dp48cUX47bbbovx48fH6tWrY9myZWVGwSxZsiSaNGkSERFNmjSJV199tcxylyxZkplX+m/ptPXb5Ofnb3T0S0TEkCFDYvDgwZn7JSUlQhgAYLvT6oqx2S5hkz68rtdWtdsR+gAAAMDOrcJHwBx55JExZ86cmD17dubWuXPnOOOMMzL/r169ekyaNCnzmLlz58b8+fOjsLAwIiIKCwtjzpw5sXTp0kybiRMnRn5+frRr1y7TZv1llLYpXcbG5OXlRX5+fpkbAAAAAADAtqrwETB169aNfffdt8y02rVrR6NGjTLT+/btG4MHD46GDRtGfn5+XHTRRVFYWBiHHHJIREQcffTR0a5duzjzzDPj+uuvj8WLF8eVV14Z/fv3j7y8vIiIuOCCC+K2226Lyy67LM4999x44YUX4tFHH42xYyvvrykBAAAAAIAdQ4UHMFtj5MiRUaVKlTjppJNi1apVUVRUFLfffntmftWqVWPMmDFx4YUXRmFhYdSuXTv69OkTw4cPz7Rp3bp1jB07Ni6++OK45ZZbonnz5nHPPfdEUVFRNroEAMBOxmnUAAAAdm6VIoCZPHlymfs1atSIUaNGxahRozb5mJYtW8Zzzz232eV279493njjjTRKBAAAAAAA2GoVfg0YAAAAAACAHV2lGAEDAABUPk6jBgAA8N0JYAAAgB2WEAkAAMgWpyADAAAAAABImREwAAAAlZhRPAAAsH0yAgYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABIWbVsFwAAAMCOrdUVY7NdwiZ9eF2vbJcAAMAOyggYAAAAAACAlAlgAAAAAAAAUuYUZAAAALAFTqMGAMC2EsAAAADADq4yB0gRQiQAYMfkFGQAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAyqpluwAAAACALWl1xdhsl7BZH17XK9slAACVjBEwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACmrlu0CAAAAAHYGra4Ym+0SNunD63pluwQA2OEYAQMAAAAAAJAyAQwAAAAAAEDKnIIMAAAAgK3iNGoAsPWMgAEAAAAAAEiZAAYAAAAAACBlTkEGAAAAwE7DadQAqCgCGAAAAADYjgiRALYPTkEGAAAAAACQMiNgAAAAAIAKZRQPsDMQwAAAAAAAbCMhErAlAhgAAAAAgJ2QEAnKlwAGAAAAAIDtkhCJyqxKtgsAAAAAAADY0QhgAAAAAAAAUiaAAQAAAAAASJlrwAAAAAAAQJa4js2OywgYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSlpUA5o477oj99tsv8vPzIz8/PwoLC+Mvf/lLZv5XX30V/fv3j0aNGkWdOnXipJNOiiVLlpRZxvz586NXr15Rq1ataNy4cVx66aXx9ddfl2kzefLk6NixY+Tl5cWee+4ZxcXFFdE9AAAAAABgJ5eVAKZ58+Zx3XXXxaxZs+K1116LI444Io4//vh4++23IyLi4osvjmeffTYee+yxmDJlSixcuDBOPPHEzOPXrl0bvXr1itWrV8e0adPi/vvvj+Li4hg6dGimzQcffBC9evWKww8/PGbPnh2DBg2Kfv36xfjx4yu8vwAAAAAAwM6lWjaetHfv3mXu/+Y3v4k77rgjXnnllWjevHnce++98eCDD8YRRxwRERGjR4+Otm3bxiuvvBKHHHJITJgwId555514/vnno6CgIDp06BDXXHNNXH755TFs2LDIzc2NO++8M1q3bh0jRoyIiIi2bdvGyy+/HCNHjoyioqIK7zMAAAAAALDzyPo1YNauXRsPP/xwrFy5MgoLC2PWrFmxZs2a6NGjR6bNPvvsE7vvvntMnz49IiKmT58e7du3j4KCgkyboqKiKCkpyYyimT59eplllLYpXcbGrFq1KkpKSsrcAAAAAAAAtlXWApg5c+ZEnTp1Ii8vLy644IJ48skno127drF48eLIzc2N+vXrl2lfUFAQixcvjoiIxYsXlwlfSueXzttcm5KSkvjyyy83WtO1114b9erVy9xatGiRRlcBAAAAAICdTNYCmDZt2sTs2bNjxowZceGFF0afPn3inXfeyVY5ERExZMiQWL58eea2YMGCrNYDAAAAAABsn7JyDZiIiNzc3Nhzzz0jIqJTp04xc+bMuOWWW+LUU0+N1atXx7Jly8qMglmyZEk0adIkIiKaNGkSr776apnlLVmyJDOv9N/Saeu3yc/Pj5o1a260pry8vMjLy0ulfwAAAAAAwM4r69eAKbVu3bpYtWpVdOrUKapXrx6TJk3KzJs7d27Mnz8/CgsLIyKisLAw5syZE0uXLs20mThxYuTn50e7du0ybdZfRmmb0mUAAAAAAACUl6yMgBkyZEj07Nkzdt999/j888/jwQcfjMmTJ8f48eOjXr160bdv3xg8eHA0bNgw8vPz46KLLorCwsI45JBDIiLi6KOPjnbt2sWZZ54Z119/fSxevDiuvPLK6N+/f2YEywUXXBC33XZbXHbZZXHuuefGCy+8EI8++miMHTs2G10GAAAAAAB2IlkJYJYuXRpnnXVWLFq0KOrVqxf77bdfjB8/Po466qiIiBg5cmRUqVIlTjrppFi1alUUFRXF7bffnnl81apVY8yYMXHhhRdGYWFh1K5dO/r06RPDhw/PtGndunWMHTs2Lr744rjllluiefPmcc8990RRUVGF9xcAAAAAANi5ZCWAuffeezc7v0aNGjFq1KgYNWrUJtu0bNkynnvuuc0up3v37vHGG298pxoBAAAAAAC+q0pzDRgAAAAAAIAdhQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZVkJYK699to48MADo27dutG4ceM44YQTYu7cuWXafPXVV9G/f/9o1KhR1KlTJ0466aRYsmRJmTbz58+PXr16Ra1ataJx48Zx6aWXxtdff12mzeTJk6Njx46Rl5cXe+65ZxQXF5d39wAAAAAAgJ1cVgKYKVOmRP/+/eOVV16JiRMnxpo1a+Loo4+OlStXZtpcfPHF8eyzz8Zjjz0WU6ZMiYULF8aJJ56Ymb927dro1atXrF69OqZNmxb3339/FBcXx9ChQzNtPvjgg+jVq1ccfvjhMXv27Bg0aFD069cvxo8fX6H9BQAAAAAAdi7VsvGk48aNK3O/uLg4GjduHLNmzYrDDjssli9fHvfee288+OCDccQRR0RExOjRo6Nt27bxyiuvxCGHHBITJkyId955J55//vkoKCiIDh06xDXXXBOXX355DBs2LHJzc+POO++M1q1bx4gRIyIiom3btvHyyy/HyJEjo6ioqML7DQAAAAAA7BwqxTVgli9fHhERDRs2jIiIWbNmxZo1a6JHjx6ZNvvss0/svvvuMX369IiImD59erRv3z4KCgoybYqKiqKkpCTefvvtTJv1l1HapnQZ37Zq1aooKSkpcwMAAAAAANhWWQ9g1q1bF4MGDYquXbvGvvvuGxERixcvjtzc3Khfv36ZtgUFBbF48eJMm/XDl9L5pfM216akpCS+/PLLDWq59tpro169eplbixYtUukjAAAAAACwc8l6ANO/f/9466234uGHH852KTFkyJBYvnx55rZgwYJslwQAAAAAAGyHsnINmFIDBgyIMWPGxIsvvhjNmzfPTG/SpEmsXr06li1bVmYUzJIlS6JJkyaZNq+++mqZ5S1ZsiQzr/Tf0mnrt8nPz4+aNWtuUE9eXl7k5eWl0jcAAAAAAGDnlZURMEmSxIABA+LJJ5+MF154IVq3bl1mfqdOnaJ69eoxadKkzLS5c+fG/Pnzo7CwMCIiCgsLY86cObF06dJMm4kTJ0Z+fn60a9cu02b9ZZS2KV0GAAAAAABAecjKCJj+/fvHgw8+GE8//XTUrVs3c82WevXqRc2aNaNevXrRt2/fGDx4cDRs2DDy8/PjoosuisLCwjjkkEMiIuLoo4+Odu3axZlnnhnXX399LF68OK688sro379/ZhTLBRdcELfddltcdtllce6558YLL7wQjz76aIwdOzYb3QYAAAAAAHYSWRkBc8cdd8Ty5cuje/fu0bRp08ztkUceybQZOXJkHHfccXHSSSfFYYcdFk2aNIknnngiM79q1aoxZsyYqFq1ahQWFsbPf/7zOOuss2L48OGZNq1bt46xY8fGxIkTY//9948RI0bEPffcE0VFRRXaXwAAAAAAYOeSlREwSZJssU2NGjVi1KhRMWrUqE22admyZTz33HObXU737t3jjTfe2OYaAQAAAAAAvqusjIABAAAAAADYkQlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUiaAAQAAAAAASJkABgAAAAAAIGUCGAAAAAAAgJQJYAAAAAAAAFImgAEAAAAAAEiZAAYAAAAAACBlAhgAAAAAAICUCWAAAAAAAABSJoABAAAAAABImQAGAAAAAAAgZQIYAAAAAACAlAlgAAAAAAAAUpaVAObFF1+M3r17R7NmzSInJyeeeuqpMvOTJImhQ4dG06ZNo2bNmtGjR4/4xz/+UabNp59+GmeccUbk5+dH/fr1o2/fvrFixYoybf72t7/Fj370o6hRo0a0aNEirr/++vLuGgAAAAAAQHYCmJUrV8b+++8fo0aN2uj866+/Pn73u9/FnXfeGTNmzIjatWtHUVFRfPXVV5k2Z5xxRrz99tsxceLEGDNmTLz44otx/vnnZ+aXlJTE0UcfHS1btoxZs2bFDTfcEMOGDYu77rqr3PsHAAAAAADs3Kpl40l79uwZPXv23Oi8JEni5ptvjiuvvDKOP/74iIj4wx/+EAUFBfHUU0/FaaedFu+++26MGzcuZs6cGZ07d46IiFtvvTWOPfbYuPHGG6NZs2bxwAMPxOrVq+O+++6L3Nzc+OEPfxizZ8+Om266qUxQAwAAAAAAkLZKdw2YDz74IBYvXhw9evTITKtXr14cfPDBMX369IiImD59etSvXz8TvkRE9OjRI6pUqRIzZszItDnssMMiNzc306aoqCjmzp0bn3322Uafe9WqVVFSUlLmBgAAAAAAsK0qXQCzePHiiIgoKCgoM72goCAzb/HixdG4ceMy86tVqxYNGzYs02Zjy1j/Ob7t2muvjXr16mVuLVq0+P4dAgAAAAAAdjqVLoDJpiFDhsTy5csztwULFmS7JAAAAAAAYDtU6QKYJk2aRETEkiVLykxfsmRJZl6TJk1i6dKlZeZ//fXX8emnn5Zps7FlrP8c35aXlxf5+fllbgAAAAAAANuq0gUwrVu3jiZNmsSkSZMy00pKSmLGjBlRWFgYERGFhYWxbNmymDVrVqbNCy+8EOvWrYuDDz440+bFF1+MNWvWZNpMnDgx2rRpEw0aNKig3gAAAAAAADujrAQwK1asiNmzZ8fs2bMjIuKDDz6I2bNnx/z58yMnJycGDRoUv/71r+OZZ56JOXPmxFlnnRXNmjWLE044ISIi2rZtG8ccc0ycd9558eqrr8bUqVNjwIABcdppp0WzZs0iIuL000+P3Nzc6Nu3b7z99tvxyCOPxC233BKDBw/ORpcBAAAAAICdSLVsPOlrr70Whx9+eOZ+aSjSp0+fKC4ujssuuyxWrlwZ559/fixbtiwOPfTQGDduXNSoUSPzmAceeCAGDBgQRx55ZFSpUiVOOumk+N3vfpeZX69evZgwYUL0798/OnXqFLvssksMHTo0zj///IrrKAAAAAAAsFPKSgDTvXv3SJJkk/NzcnJi+PDhMXz48E22adiwYTz44IObfZ799tsvXnrppe9cJwAAAAAAwHdR6a4BAwAAAAAAsL0TwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRMAAMAAAAAAJAyAQwAAAAAAEDKBDAAAAAAAAApE8AAAAAAAACkTAADAAAAAACQMgEMAAAAAABAygQwAAAAAAAAKRPAAAAAAAAApEwAAwAAAAAAkDIBDAAAAAAAQMoEMAAAAAAAACkTwAAAAAAAAKRspwhgRo0aFa1atYoaNWrEwQcfHK+++mq2SwIAAAAAAHZgO3wA88gjj8TgwYPjqquuitdffz3233//KCoqiqVLl2a7NAAAAAAAYAe1wwcwN910U5x33nlxzjnnRLt27eLOO++MWrVqxX333Zft0gAAAAAAgB3UDh3ArF69OmbNmhU9evTITKtSpUr06NEjpk+fnsXKAAAAAACAHVm1bBdQnv7zn//E2rVro6CgoMz0goKC+Pvf/75B+1WrVsWqVasy95cvXx4RESUlJeVb6HZq3aovsl3CJm3ta6YP5UsfKoet6UNlrj9CHyqDnWVdiNCH8qYPlYM+VA76UDnsLH2ozPVH6ENlsLOsCxH6UN70oXLQh8phZ+rDzqT0b5IkyRbb5iRb02o7tXDhwthtt91i2rRpUVhYmJl+2WWXxZQpU2LGjBll2g8bNiyuvvrqii4TAAAAAADYjixYsCCaN2++2TY79AiYXXbZJapWrRpLliwpM33JkiXRpEmTDdoPGTIkBg8enLm/bt26+PTTT6NRo0aRk5NT7vXurEpKSqJFixaxYMGCyM/Pz3Y534k+VA76UDnoQ+WgD5WDPlQO23sftvf6I/ShstCHykEfKgd9qBz0oXLQh8phe+/D9l5/hD6w9ZIkic8//zyaNWu2xbY7dACTm5sbnTp1ikmTJsUJJ5wQEd+EKpMmTYoBAwZs0D4vLy/y8vLKTKtfv34FVEpERH5+/na/YdCHykEfKgd9qBz0oXLQh8phe+/D9l5/hD5UFvpQOehD5aAPlYM+VA76UDls733Y3uuP0Ae2Tr169baq3Q4dwEREDB48OPr06ROdO3eOgw46KG6++eZYuXJlnHPOOdkuDQAAAAAA2EHt8AHMqaeeGh9//HEMHTo0Fi9eHB06dIhx48ZFQUFBtksDAAAAAAB2UDt8ABMRMWDAgI2ecozKIS8vL6666qoNTv+2PdGHykEfKgd9qBz0oXLQh8phe+/D9l5/hD5UFvpQOehD5aAPlYM+VA76UDls733Y3uuP0AfKR06SJEm2iwAAAAAAANiRVMl2AQAAAAAAADsaAQwAAAAAAEDKBDBQAVq1ahU333xz5n5OTk489dRTWatnR/Hhhx9GTk5OzJ49O9ullJtv93Hy5MmRk5MTy5Yty2pd39fWvHbZ7mtxcXHUr18/c3/YsGHRoUOHzP2zzz47TjjhhAqva3vXvXv3GDRoUKrL/PZrVZl9+30E27strdOOeSqH8tj2lods7/srq29/ligvSZLE+eefHw0bNoycnJyoX7/+dvG+Wd/28l7n+7Fv2bgtrcMVtS1Jw46wLutD9lTWuitrXZQ/AQwAbMSpp54a8+bNy3YZANu1RYsWRc+ePbNdRtZUdFi/vQUYvoioXMaNGxfFxcUxZsyYWLRoUcybNy+uueaa77XMiv6i/IknntjqmneGH3ORfRX5Q6HyWId3RNvbvvL/a+++o6uoFrePP0kgjTRCSUIxoEAIAqFICTXSQhVUFBGlSLkgRTpyRaqKIsWGBVRAL4iiIlyCVKWHTgABQxEELwkgLQSkJfv9gzfz40AICUw4lO9nrbNgZvaZ2ftkTznznJkBcO/L4ewKAMD96uLFi3J3d3d2NXCLvLy85OXl5exqALgD2F5nn+DgYGdXAdmE9eb+s2/fPoWEhKhatWqZKn839oHAwEBnVwFwmqyuwwCAO4MrYHDHpHe5a7ly5TR8+HBJV34d9cknn6hRo0by8vLSww8/rO+///7OV1TSvHnzFBAQoJSUFElSXFycXFxc9Oqrr1plOnXqpBdeeEGStGrVKtWsWVNeXl4qXLiwevXqpbNnzzql7tdKTU3VmDFjVKxYMXl4eOihhx7Sm2++KUkaNGiQSpQoIW9vbz388MN6/fXXdenSJeu9abfK+frrr1WkSBH5+/vrueee05kzZ+5Y/RcsWKAaNWooICBAefLkUdOmTbVv3750y548eVJt2rRRvnz55OXlpeLFi2vKlCnW9O3bt6tOnTry8vJSnjx51KVLFyUnJ9tW16ioKPXo0UO9e/dW3rx5FR0drd9++02NGjWSj4+PgoKC9OKLL+rvv/++pfZd6+zZs/Lz87tuPfnpp5+UK1euLP2dstrnf/jhBz366KPy8PBQkSJFNG7cOIf5pfdrx4CAAE2dOvWGdZg/f75KlCghLy8vPf744zpw4ECm659ZWWnn3X5bq3t5O5WamqqBAwcqMDBQwcHB1n5AksaPH68yZcooV65cKly4sF5++eXr1tOpU6fqoYcekre3t5588kkdP378jtX9woUL6tWrl/Lnzy9PT0/VqFFDGzZskPR/v6ZbunSpHnvsMXl7e6tatWqKj49Pd14rVqxQzpw5lZiY6DC+d+/eqlmzZra3Rbqy3erZs6d69+6t3LlzKygoSJMnT9bZs2fVoUMH+fr6qlixYvr555+t99xsu5Yd7O7vRYoU0ahRo9S2bVv5+fmpS5cumXrf7UpNTdXo0aNVtGhReXl5KSIiQt9//71SU1NVqFAhffLJJw7lt2zZIldXV/3555+SpFOnTqlTp07Kly+f/Pz8VKdOHW3dutUq76z9dkbr9NX7g7Rfm3/33XfW51ypUiXt3r1bGzZs0GOPPSYfHx81atRIx44dy5a63kqfX758uSpXriwPDw+FhITo1Vdf1eXLl63p33//vcqUKWMdX9SrV09nz57V8OHDNW3aNM2ZM0cuLi5ycXHRsmXLbrsNN9oOHThwQI8//rgkKXfu3HJxcVH79u2t92X0d5Iy378+//xzFS1aVJ6enrfVjvbt22v58uV6//33rc8nbd+/adOmG25H9+3bp+bNmysoKEg+Pj6qVKmSlixZ4jDvIkWK6K233tJLL70kX19fPfTQQ5o0adJt1TdNVvtQescTP/30k1xcXBzG/fe//1WlSpXk6empvHnz6sknn3SYfu7cuWxpT5r27durZ8+eOnjwoFxcXFSkSJHrrlBKb9t58eJF9ejRQyEhIfL09FRoaKhGjx5tlZekJ5980ppndru6zjfrB0WLFpUklS9fXi4uLoqKipJ0ZV0ZOXKkChUqJA8PD5UrV04LFizI9rpnJCoqSr169brhOnzw4EE1b95cPj4+8vPz07PPPqsjR45kSz169OihHj16yN/fX3nz5tXrr78uY4ykK9un/v37q2DBgsqVK5eqVKly3XbvZt8j0vpZ69atlStXLhUsWFATJ07MsF6HDh3Ss88+q4CAAAUGBqp58+a2fZc4c+aM2rRpo1y5cikkJEQTJkxw6GcZtXnZsmXq0KGDTp8+bW3nrt322iUz6/C1XFxc9Nlnn6lp06by9vZWeHi4YmNjtXfvXkVFRSlXrlyqVq2aw/fTrVu36vHHH5evr6/8/PxUsWJFbdy4MVvadPny5Vvua3/++aeaNWum3LlzK1euXHr00Uc1f/78m+4r7ZbRvjej9fb06dNyc3OzPtvU1FQFBgaqatWq1vv/85//qHDhwtlW92udPHlSbdu2Ve7cueXt7a1GjRppz549kqSkpCR5eXk5HD9J0uzZs+Xr66tz585Jyt519Vq303+kzH2fuJVjjdut1+rVqxUVFSVvb2/lzp1b0dHROnnypKSbn19K7+qvtO9VaX+HG607aZzxXfC+YIA7JDQ01EyYMMFhXEREhBk2bJgxxhhJJk+ePGby5MkmPj7eDBkyxLi5uZmdO3fe8bqeOnXKuLq6mg0bNhhjjHnvvfdM3rx5TZUqVawyxYoVM5MnTzZ79+41uXLlMhMmTDC7d+82q1evNuXLlzft27e3yl7bdklm9uzZd6QtAwcONLlz5zZTp041e/fuNStXrjSTJ082xhgzatQos3r1arN//34zd+5cExQUZN555x3rvcOGDTM+Pj7mqaeeMtu3bzcrVqwwwcHB5t///vcdqbsxxnz//ffmhx9+MHv27DFbtmwxzZo1M2XKlDEpKSlm//79RpLZsmWLMcaY7t27m3LlypkNGzaY/fv3m8WLF5u5c+caY4xJTk42ISEhVluWLl1qihYtatq1a2dbXWvXrm18fHzMgAEDzO+//27Wrl1r8uXLZwYPHmx27dplNm/ebOrXr28ef/zxTLXPGHNdG3/99VcjyZw8edIYY0znzp1N48aNHerxxBNPmLZt22ap7lnp8xs3bjSurq5m5MiRJj4+3kyZMsV4eXmZKVOmWGXT6+P+/v5WmWvbdfDgQePh4WH69u1rfv/9d/Of//zHBAUFObTVDllp55QpU4y/v781ftiwYSYiIsIabteunWnevLltdcsqu7dTd0rt2rWNn5+fGT58uNm9e7eZNm2acXFxMYsWLTLGGDNhwgTzyy+/mP3795ulS5easLAw061bN+v9a9euNa6uruadd94x8fHx5v333zcBAQEOf6vs1KtXL1OgQAEzf/58s2PHDtOuXTuTO3duc/z4cWv9rFKlilm2bJnZsWOHqVmzpqlWrZr1/mv7UYkSJcyYMWOs4YsXL5q8efOaL7/88o60p3bt2sbX19eMGjXK7N6924waNcq4ubmZRo0amUmTJpndu3ebbt26mTx58pizZ8+akydP3nS7lh2yY7/s5+dnxo4da/bu3Wu9sns9eeONN0zJkiXNggULzL59+8yUKVOMh4eHWbZsmenfv7+pUaOGQ/l+/fo5jKtXr55p1qyZ2bBhg9m9e7fp16+fyZMnjzl+/Lgxxjn77Zut01fvD9K2/Wmfwc6dO03VqlVNxYoVTVRUlFm1apXZvHmzKVasmOnatWu21Tcrff6vv/4y3t7e5uWXXza7du0ys2fPNnnz5rWOXw8fPmxy5Mhhxo8fb/bv32+2bdtmJk6caM6cOWPOnDljnn32WdOwYUOTkJBgEhISzIULF267DTfaDv3999/mhx9+MJJMfHy8SUhIMKdOnbLandHfyZjM9a9cuXKZhg0bms2bN5utW7feVjtOnTplIiMjTefOna3PZ8mSJTfdjsbFxZlPP/3UbN++3ezevdsMGTLEeHp6mj///NMqExoaagIDA83EiRPNnj17zOjRo42rq6v5/fffb6vOxmS9D117PGGMMbNnzzZXfxWfN2+ecXNzM0OHDjU7d+40cXFx5q233roj7Ulz6tQpM3LkSFOoUCGTkJBgjh49amrXrm1eeeUVh3pcu+189913TeHChc2KFSvMgQMHzMqVK82MGTOMMcYcPXrUSDJTpkyx5pndrq7zzT639evXG0lmyZIlJiEhwerr48ePN35+fuabb74xv//+uxk4cKDJmTOn2b17d7bX/0YyWodTUlJMuXLlTI0aNczGjRvN2rVrTcWKFU3t2rWzpR4+Pj7mlVdesY7Zvb29zaRJk4wxxnTq1MlUq1bNrFixwuofHh4e1meXme8RoaGhxtfX14wePdrEx8ebDz74wLi5uTlsr67et1y8eNGEh4ebl156yWzbts3s3LnTPP/88yYsLMyWbW6nTp1MaGioWbJkidm+fbt58sknja+vr9XPMmrzhQsXzHvvvWf8/Pys7dyZM2duu07pyew6fO15iYIFC5pvv/3WxMfHmxYtWpgiRYqYOnXqOOynGzZsaL3n0UcfNS+88ILZtWuX2b17t/nuu+9MXFyc7e253b7WpEkTU79+fbNt2zazb98+89///tcsX77cXL58+Yb7yuxow+2stxUqVDDvvvuuMebKvi8wMNC4u7tbfahTp06mTZs22VL3q9uQ1oeeeOIJEx4eblasWGHi4uJMdHS0KVasmLl48aIxxpiWLVuaF154weH9Tz/9tDUuu9fVa+t9O/0ns98nsrpvvt16bdmyxXh4eJhu3bqZuLg489tvv5kPP/zQHDt2zBhz8/NL155PSpunJLN//35jzI3XHWOM074L3g8IYHDHZCaAufbLdpUqVRxOvN1JV+/sWrRoYd58801rZ/fXX38ZSWb37t2mY8eOpkuXLg7vXblypXF1dTX//POPMcZ5AUxSUpLx8PCwApebeffdd03FihWt4WHDhhlvb2+TlJRkjRswYIDDCa877dixY0aS2b59+3Un8Zs1a2Y6dOiQ7vsmTZpkcufObZKTk61xMTExxtXV1SQmJtpSt9q1a5vy5ctbw6NGjTINGjRwKHPo0CHrYC89V7fPmJsHMOvWrTNubm7m8OHDxhhjjhw5YnLkyGGWLVuW5fpnts8///zzpn79+g7vHTBggClVqpQ1nNUAZvDgwQ7vN8aYQYMG2R7AZKWdd3sAY4y926k7pXbt2tedZK5UqZIZNGhQuuVnzZpl8uTJYw23bt36utCxVatWdySASU5ONjlz5jTTp0+3xl28eNEUKFDAjBkzxlo/lyxZYk2PiYkxkqzP+dp+9M4775jw8HBr+IcffjA+Pj4O26rsdO3f4/LlyyZXrlzmxRdftMYlJCQYSSY2NvaWtmt2sXu/3KJFC4cy2b2enD9/3nh7e5s1a9Zct9zWrVubLVu2GBcXF+skckpKiilYsKD55JNPrLr4+fmZ8+fPO7z/kUceMZ999pkxxjn77Zut0+kFMJ9//rlV9ptvvjGSzNKlS61xo0ePNmFhYXekvjfr8//+979NWFiYSU1NtaZPnDjR+Pj4mJSUFLNp0yYjyRw4cCDd5dm9r8jsdujafefN/k6Z7V85c+a09ST6tScHM7MdTc+jjz5qPvzwQ2s4NDTU4SRQamqqyZ8/v7U+3W6ds9KHMhPAREZGZngSLTvbc7UJEyaY0NBQazi9k7fXbjt79uxp6tSp47COXO1O/vDMmOsDmIw+t2uPR9MUKFDAvPnmmw7jKlWqZF5++eVsrXtGMlqHFy1aZNzc3MzBgwetaTt27DCSzPr1622vR3h4uMPfe9CgQSY8PNz8+eefxs3Nzfzvf/9zeE/dunXN4MGDjTEmU98jQkNDHU74G3PlWK9Ro0bW8NX96uuvv75uO33hwgXj5eVlFi5ceFvtTUpKMjlz5jSzZs2yxp06dcp4e3ubV155JVNtTm8bkF0ysw5fe15iyJAh1nBsbKyRZL744gtr3DfffGM8PT2tYV9fXzN16tRsqf/VbrevlSlTxgwfPjzded9oX2m3211v+/bta5o0aWKMufLjo1atWpmIiAjz888/G2Ou/Pgo7cR9drbhlVdeMbt37zaSzOrVq61pf//9t/Hy8jLfffedMebKvs3Hx8ecPXvWGGPM6dOnjaenp1Xf7FxX06v37fSfzH6fyOq++Xbr1bp1a1O9evVMfw7Xnl/KTACT0brjzO+C9zpuQYa7SmRk5HXDu3btckpdateurWXLlskYo5UrV+qpp55SeHi4Vq1apeXLl6tAgQIqXry4tm7dqqlTp8rHx8d6RUdHKzU1Vfv373dK3dPs2rVLFy5cUN26ddOd/u2336p69eoKDg6Wj4+PhgwZooMHDzqUKVKkiHx9fa3hkJAQHT16NFvrfbU9e/aodevWevjhh+Xn52fduuDaekpSt27dNHPmTJUrV04DBw7UmjVrrGm7du1SRESEcuXKZY2rXr26UlNTb3h7oFtRsWJF6/9bt27Vr7/+6tA3SpYsKUnWZaBZaV96KleurEcffVTTpk2TdOUy5NDQUNWqVSvLdc9sn9+1a5eqV6/u8N7q1atrz5491u2BsmrXrl2qUqWKw7hrtwd2yWw77wX36naqbNmyDsNXb1eWLFmiunXrqmDBgvL19dWLL76o48ePW5et38m+cq19+/bp0qVLDv0/Z86cqly5ssO+6ur2hYSESNINt5vt27fX3r17tXbtWklXblXz7LPPOmyrstvV9XVzc1OePHlUpkwZa1xQUJCkK23IzHYtu9jd3x977DGH+Wf3erJ3716dO3dO9evXd1jGV199pX379qlcuXIKDw/XjBkzJF257dXRo0f1zDPPWPVLTk5Wnjx5HN6/f/9+h8/eGfvtjNbpm5VP61/X9rnsrHNW+vyuXbsUGRnpcLuo6tWrKzk5WX/99ZciIiJUt25dlSlTRs8884wmT55s3QYiO2R2O5SejP5Ome1foaGhypcvn40tunldr92OJicnq3///goPD1dAQIB8fHy0a9eu646drp6Hi4uLgoODbetXWelDmREXF3fD4/X0lml3e7Li2m1n+/btFRcXp7CwMPXq1UuLFi2643XKSFY/t6SkJB0+fDjdY11nfS9Nc6N1eNeuXSpcuLDDrYhKlSqlgICAbKlz1apVHbaJkZGR2rNnj7Zv366UlBSVKFHCYTuyfPlyazuS2e8RWTkvsHXrVu3du1e+vr7WMgMDA3X+/PnbPjb5448/dOnSJVWuXNka5+/vr7CwMEnKVJvvdpnZJ58/f15JSUmSpL59+6pTp06qV6+e3n777Wxt5+30tV69eumNN95Q9erVNWzYMG3bti3b6pmR21lva9eurVWrViklJUXLly9XVFSUoqKitGzZMh0+fNi6VdydsGvXLuXIkcPhe1iePHkUFhZm1bdx48bKmTOn5s6dK+nK7Qb9/PxUr149Sdm7rqbndvpPZr8X3Mq++XbqdbPjhds9vyRlvO4487vgvS6HsyuAB4erq6t1X8M0Vz9v5G4TFRWlL7/8Ulu3blXOnDlVsmRJa2d38uRJ1a5dW9KVL4H/+te/1KtXr+vm8dBDD93pajvI6AHisbGxatOmjUaMGKHo6Gj5+/tr5syZ192DN2fOnA7DLi4uSk1NzZb6pqdZs2YKDQ3V5MmTVaBAAaWmpqp06dK6ePHidWUbNWqkP//8U/Pnz9fixYtVt25dde/eXWPHjr1j9b36pGlycrKaNWumd95557pyaScTstK+G+nUqZMmTpyoV199VVOmTFGHDh2uu694ZmS2z2eGi4vLXbu+29lOZ7tXt1M32q4cOHBATZs2Vbdu3fTmm28qMDBQq1atUseOHXXx4kV5e3vf8breiqvbl7Yu3mi7mT9/fjVr1kxTpkxR0aJF9fPPP9vyjIisSO/vcaM2ZGa7ll3s7u/XhlzZvZ6kPcsoJiZGBQsWdJjm4eEhSWrTpo1mzJihV199VTNmzFDDhg2VJ08e6/0hISHp9o+rny/hjP12VpeZXv+6dlx21jkrff5m3NzctHjxYq1Zs0aLFi3Shx9+qNdee03r1q2zni9xt8jo75TZ/nWnwuGM/h79+/fX4sWLNXbsWBUrVkxeXl5q2bLldcdO2bkuZKUPZeY7UEbH7Bkt804ek6e5tg9UqFBB+/fv188//6wlS5bo2WefVb169Zz2LM9r3S2fmx3u9rYkJyfLzc1NmzZtkpubm8M0Hx+fbF1uxYoVNX369OumZXdg7Kw22ykz+2Tp/7bBw4cP1/PPP6+YmBj9/PPPGjZsmGbOnHndc6uyU2Y+906dOik6OloxMTFatGiRRo8erXHjxqlnz553rJ7S7a23tWrV0pkzZ7R582atWLFCb731loKDg/X2228rIiLirvvhoLu7u1q2bKkZM2boueee04wZM9SqVSvlyHHl1LMz19WrZab/ZPZ7gZ3b5czU62bHCzc7v+TqeuU6jKuPS649Jslo3XHmd8F7HQEM7ph8+fIpISHBGk5KSrruF6Vr165V27ZtHYbLly9/x+p4tZo1a+rMmTOaMGGCdVInKipKb7/9tk6ePKl+/fpJuvKlY+fOnSpWrJhT6pmR4sWLy8vLS0uXLlWnTp0cpq1Zs0ahoaF67bXXrHFpD/m9Wxw/flzx8fGaPHmy9UDqVatWZfiefPnyqV27dmrXrp1q1qypAQMGaOzYsQoPD9fUqVN19uxZ64vj6tWr5erqav2CyW4VKlTQDz/8oCJFilgHHVe7lfal54UXXtDAgQP1wQcfaOfOnWrXrt0t1TezfT48PFyrV692eO/q1atVokQJ60Dh2vV9z5491hUM6QkPD7d+KZMm7YoAu2W2nfeC+2E7dbVNmzYpNTVV48aNsw4Ov/vuO4cy4eHhWrduncO47Oor13rkkUfk7u6u1atXKzQ0VNKVA9YNGzZk+IDTm+nUqZNat26tQoUK6ZFHHrnul6F3k5tt17JTdvf37F5PSpUqJQ8PDx08ePCGQe/zzz+vIUOGaNOmTfr+++/16aefOtQvMTFROXLkuCMPssYV4eHh+uGHH2SMsU5CrV69Wr6+vipUqJCkK1+2q1evrurVq2vo0KEKDQ3V7Nmz1bdvX7m7u9/y1aHpudl2yN3dXZKyvExn9a9b+XxWr16t9u3bWyf7kpOTs+0BvnbIly+fzpw543AMGhcX51CmbNmyWrp0qTp06OCEGt4+Pz8/tWrVSq1atVLLli3VsGFDnThxQoGBgcqZM6et64Cd0ltf/Pz8VKBAAa1evdphW7169WqHqyDuJuHh4Tp06JAOHTpk/Zp+586dOnXqlEqVKmX78tI7DitevLjKly+vlJQUHT161Ppuk15db/Y9Im2e1y4jPDw83XlWqFBB3377rfLnzy8/P79badINPfzww8qZM6c2bNhgnXQ9ffq0du/erVq1amWqzXbvB+4GJUqUUIkSJdSnTx+1bt1aU6ZMyZYA5nb6miQVLlxYXbt2VdeuXTV48GBNnjxZPXv2vOV9pZ0ys94GBASobNmy+uijj6wfH+XPn1+tWrXSvHnz7ugPB8PDw3X58mWtW7dO1apVk/R/5zOu3s60adNG9evX144dO/TLL7/ojTfesKZl57qantvpP9n5veB26pV2vDBixIjrpmXm/FJa0JWQkKDcuXNLuv6YRLrxuuPM74L3Om5BhjumTp06+vrrr7Vy5Upt375d7dq1uy7VnTVrlr788kvt3r1bw4YN0/r169WjRw+n1Dd37twqW7aspk+fbl3WWatWLW3evFm7d++2dnaDBg3SmjVr1KNHD8XFxWnPnj2aM2eO0+p9NU9PTw0aNEgDBw60bnGydu1affHFFypevLgOHjyomTNnat++ffrggw80e/ZsZ1fZQe7cuZUnTx5NmjRJe/fu1S+//KK+ffvesPzQoUM1Z84c7d27Vzt27NC8efOsA/U2bdrI09NT7dq102+//aZff/1VPXv21Isvvmhdam237t2768SJE2rdurU2bNigffv2aeHCherQoYNSUlKy3L4byZ07t5566ikNGDBADRo0sE4I3cp8MtPn+/Xrp6VLl2rUqFHavXu3pk2bpo8++kj9+/e35lWnTh199NFH2rJlizZu3KiuXbte9+uQq3Xt2lV79uzRgAEDFB8frxkzZmjq1Km31A672nkvuB+2U1crVqyYLl26pA8//FB//PGHvv76a4cT0NKVS6IXLFigsWPHas+ePfroo4+0YMGCO1K/XLlyqVu3bhowYIAWLFignTt3qnPnzjp37pw6dux4y/ONjo6Wn5+f3njjjbv+5NvNtmvZKbv7e3avJ76+vurfv7/69OmjadOmad++fdq8ebM+/PBD6zaSRYoUUbVq1dSxY0elpKToiSeesN5fr149RUZGqkWLFlq0aJEOHDigNWvW6LXXXtPGjRttqSOu9/LLL+vQoUPq2bOnfv/9d82ZM0fDhg1T37595erqqnXr1umtt97Sxo0bdfDgQf344486duyYdfxRpEgRbdu2TfHx8fr7779v+2rQm22HQkND5eLionnz5unYsWPWlVc346z+VaRIEa1bt04HDhzQ33//nalfjRYvXlw//vij4uLitHXrVj3//PN31VUA16pSpYq8vb3173//W/v27Uv3GGfYsGH65ptvNGzYMO3atUvbt29P99eld6Px48frm2++0e+//67du3dr1qxZCg4Otq6cKlKkiJYuXarExMRsvT3frcifP7+8vLy0YMECHTlyRKdPn5YkDRgwQO+8846+/fZbxcfH69VXX1VcXJxeeeUVJ9c4ffXq1VOZMmXUpk0bbd68WevXr1fbtm1Vu3bt624ZZ4eDBw+qb9++io+P1zfffKMPP/xQr7zyikqUKKE2bdqobdu2+vHHH7V//36tX79eo0ePVkxMjKTMfY+QroQyY8aM0e7duzVx4kTNmjXrhp9/mzZtlDdvXjVv3lwrV67U/v37tWzZMvXq1Ut//fXXbbXV19dX7dq104ABA/Trr79qx44d6tixo1xdXeXi4pKpNhcpUkTJyclaunSp/v777wx/lHa3++eff9SjRw8tW7ZMf/75p1avXq0NGzbcMBy7XbfT13r37q2FCxdq//792rx5s3799Vernre6r7RTZtfbqKgoTZ8+3TrODQwMVHh4uL799ts7+r21ePHiat68uTp37qxVq1Zp69ateuGFF1SwYEE1b97cKlerVi0FBwerTZs2Klq0qMMty7JzXU3P7fSf7PxecDv1Gjx4sDZs2KCXX35Z27Zt0++//65PPvlEf//9d6bOLxUrVkyFCxfW8OHDtWfPHsXExFx3F5yM1h1nfhe81xHA4I4ZPHiwateuraZNm6pJkyZq0aKFHnnkEYcyI0aM0MyZM1W2bFl99dVX+uabb7LlVzuZVbt2baWkpFgnegIDA1WqVCkFBwdbV02ULVtWy5cv1+7du1WzZk2VL19eQ4cOVYECBZxW76u9/vrr6tevn4YOHarw8HC1atVKR48e1RNPPKE+ffqoR48eKleunNasWaPXX3/d2dV14OrqqpkzZ2rTpk0qXbq0+vTpo3ffffeG5d3d3TV48GCVLVtWtWrVkpubm2bOnClJ8vb21sKFC3XixAlVqlRJLVu2VN26dfXRRx9lW/3Tfj2XkpKiBg0aqEyZMurdu7cCAgLk6uqa5fZlJO0WTS+99NJt1Tkzfb5ChQr67rvvNHPmTJUuXVpDhw7VyJEj1b59e2s+48aNU+HChVWzZk09//zz6t+/f4a3j3rooYf0ww8/6KefflJERIQ+/fRTvfXWW7fVlttt573ifthOpYmIiND48eP1zjvvqHTp0po+fbpGjx7tUKZq1aqaPHmy3n//fUVERGjRokUaMmTIHavj22+/raefflovvviiKlSooL1792rhwoXWL4huhaurq9q3b6+UlBSHq0DvRjfbrmW37Ozvd2I9GTVqlF5//XWNHj1a4eHhatiwoWJiYhxuVdWmTRtt3bpVTz75pMNtBlxcXDR//nzVqlVLHTp0UIkSJfTcc8/pzz//zLYfEkAqWLCg5s+fr/Xr1ysiIkJdu3ZVx44dre2On5+fVqxYocaNG6tEiRIaMmSIxo0bp0aNGkmSOnfurLCwMD322GPKly/fdb/8vhUZbYcKFiyoESNG6NVXX1VQUFCmTxQ4q3/1799fbm5uKlWqlPLly5epe5SPHz9euXPnVrVq1dSsWTNFR0erQoUK2VbH2xUYGKj//Oc/mj9/vsqUKaNvvvlGw4cPdygTFRWlWbNmae7cuSpXrpzq1Kmj9evXO6fCWeTr66sxY8boscceU6VKlXTgwAHNnz/f2ieMGzdOixcvVuHChZ12Z4MbyZEjhz744AN99tlnKlCggHUSsVevXurbt6/69eunMmXKaMGCBZo7d+5ddaufq7m4uGjOnDnKnTu3atWqpXr16unhhx/Wt99+my3La9u2rf755x9VrlxZ3bt31yuvvKIuXbpIkqZMmaK2bduqX79+CgsLU4sWLRyuHsnM9wjpSlCzceNGlS9fXm+88YbGjx+v6OjodOvj7e2tFStW6KGHHrKeD9exY0edP3/ell/Zjx8/XpGRkWratKnq1aun6tWrKzw8XJ6enplqc7Vq1dS1a1e1atVK+fLl05gxY267Ts7i5uam48ePq23btipRooSeffZZNWrUKN1f49vhdvpaSkqKunfvbh1vlShRQh9//LEk3fK+0k6ZXW+vPfaVruwzrh13J0yZMkUVK1ZU06ZNFRkZKWOM5s+ff90t61q3bq2tW7eqTZs2Du/P7nX1WrfTf7Lze8Ht1KtEiRJatGiRtm7dqsqVKysyMlJz5sxRjhw5MnV+KWfOnNaPJsqWLat33nnH4SolKeN1x9nfBe9lLubaG9ICTuLi4qLZs2erRYsWzq4KcM/5+uuv1adPHx0+fNi6pBrAvaNjx446duzYdbfiAwAAuFtERUWpXLlyeu+997JtGUWKFFHv3r1v6/au2ens2bMqWLCgxo0bd1tXQAMAHhzcsA0A7mHnzp1TQkKC3n77bf3rX/8ifAHuMadPn9b27ds1Y8YMwhcAAIC7zJYtW/T777+rcuXKOn36tEaOHClJDrddAgAgI1wfBAD3sDFjxqhkyZIKDg7W4MGDnV0dAFnUvHlzNWjQQF27dlX9+vWdXR0AAABcY+zYsYqIiFC9evV09uxZrVy5Unnz5nV2tQAA9whuQQYAAAAAAAAAAGAzroABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAIElq3769ihQp4uxqAAAAAPcFAhgAAAAA13FxccnUa9myZdlaj3/++UcdO3ZU6dKl5e/vLx8fH0VEROj999/XpUuXHMomJCTo1Vdf1eOPPy5fX99brt+ZM2c0cOBAFS1aVB4eHipYsKBatmypc+fOOZQ7deqUunTponz58ilXrlx6/PHHtXnz5pvOv3HjxsqdO7eMMQ7jt2zZIhcXF4WGhl73nl9++UUuLi6aNGlSltsDAAAAwDlyOLsCAAAAAO4+X3/9tcPwV199pcWLF183Pjw8PFvr8c8//2jHjh1q3LixihQpIldXV61ZvOGfigAAQ2JJREFUs0Z9+vTRunXrNGPGDKtsfHy83nnnHRUvXlxlypRRbGxslpd3+vRp1a5dW3/99Ze6dOmiYsWK6dixY1q5cqUuXLggb29vSVJqaqqaNGmirVu3asCAAcqbN68+/vhjRUVFadOmTSpevPgNl1GjRg39/PPP+u2331SmTBlr/OrVq5UjRw4dPHhQf/31lwoVKuQwLe29AAAAAO4NBDAAAAAArvPCCy84DK9du1aLFy++bnx2CwwM1Nq1ax3Gde3aVf7+/vroo480fvx4BQcHS5IqVqyo48ePKzAwUN9//72eeeaZLC9v8ODB+vPPP7V582YVLVrUGj9o0CCHct9//73WrFmjWbNmqWXLlpKkZ599ViVKlNCwYcMcgqFrpYUoq1atui6Aady4sX755RetWrVKzz33nDVt1apVypMnz20HXufPn5e7u7tcXbkZAgAAAJDdOOoGAAAAcEvOnj2rfv36qXDhwvLw8FBYWJjGjh173a21XFxc1KNHD02fPl1hYWHy9PRUxYoVtWLFiltedtpzSk6dOmWN8/X1VWBg4C3P89SpU5oyZYq6dOmiokWL6uLFi7pw4UK6Zb///nsFBQXpqaeessbly5dPzz77rObMmXPD90lS5cqV5e7ubl3Vkmb16tWqVauWKleu7DAtNTVVa9euVbVq1eTi4iJJ+uOPP/TMM88oMDBQ3t7eqlq1qmJiYhzmt2zZMrm4uGjmzJkaMmSIChYsKG9vbyUlJUmSfvrpJ5UuXVqenp4qXbq0Zs+enW59Z86cqYoVK8rX11d+fn4qU6aM3n///Qw+SQAAAAASAQwAAACAW2CM0RNPPKEJEyaoYcOGGj9+vMLCwjRgwAD17dv3uvLLly9X79699cILL2jkyJE6fvy4GjZsqN9++y1Ty7t48aL+/vtvHTp0SLNnz9bYsWMVGhqqYsWK2damVatW6fz58ypWrJhatmwpb29veXl5qXr16oqLi3Mou2XLFlWoUOG6K0kqV66sc+fOaffu3TdcTloAtWrVKmvcoUOHdOjQIVWrVk3VqlVzCGC2b9+upKQk68qZI0eOqFq1alq4cKFefvllvfnmmzp//ryeeOKJdEOUUaNGKSYmRv3799dbb70ld3d3LVq0SE8//bRcXFw0evRotWjRQh06dNDGjRsd3rt48WK1bt1auXPn1jvvvKO3335bUVFR14VHAAAAAK7HLcgAAAAAZNncuXP1yy+/6I033tBrr70mSerevbueeeYZvf/+++rRo4ceeeQRq/xvv/2mjRs3qmLFipKk5557TmFhYRo6dKh+/PHHmy7vxx9/VOvWra3hxx57TF9++aVy5LDvK82ePXskXbkN2SOPPKKvvvpKp0+f1ogRI1SnTh3t2LFDISEhkqSEhATVqlXrunmkTT98+LDD7cWuVaNGDb377rv63//+p4IFC2r16tVWMHPq1CmNHj1aZ86cka+vrxXUpAUwb7/9to4cOaKVK1da4zp37qyyZcuqb9++at68uUMwdP78eW3cuFFeXl7WuEGDBikoKEirVq2Sv7+/JKl27dpq0KCBQkNDrXIxMTHy8/PTwoUL5ebmlvUPFQAAAHiAcQUMAAAAgCybP3++3Nzc1KtXL4fx/fr1kzFGP//8s8P4yMhIK3yRpIceekjNmzfXwoULlZKSctPlPf7441q8eLFmzZqlrl27KmfOnDp79qw9jfn/kpOTJV25ZdrSpUv1/PPPq1u3bvrpp5908uRJTZw40Sr7zz//yMPD47p5eHp6WtMzkhacrFy5UtKV249VrFhR7u7uioyMtG47ljbN09NTjz32mKQrn33lypWteUiSj4+PunTpogMHDmjnzp0Oy2rXrp1D+JKQkKC4uDi1a9fOCl8kqX79+ipVqpTDewMCAnT27FktXrw4w/YAAAAAuB4BDAAAAIAs+/PPP1WgQAH5+vo6jE97SPyff/7pML548eLXzaNEiRI6d+6cjh07dtPlBQUFqV69emrZsqU++eQTNW3aVPXr11diYmKW637ixAklJiZar9OnT0uSFVI0a9ZMPj4+VvmqVauqaNGiWrNmjTXOy8sr3ee8nD9/3mFeN1K9enW5uLhYt/JavXq1qlevLulK6FGqVCmHaZUqVZK7u7ukK59tWFjYdfO80WdftGhRh+G06en9Ta6d78svv6wSJUqoUaNGKlSokF566SUtWLAgw7YBAAAAuIIABgAAAMA9p2XLlkpOTtacOXOy/N6nnnpKISEh1uuVV16RJBUoUEDSlbDnWvnz59fJkyet4ZCQECUkJFxXLm1c2rxuJE+ePCpZsqRWrVql5ORkbdu2TdWqVbOmV6tWTatWrdJff/2lgwcPOlztklU3C4Mykj9/fsXFxWnu3Ll64okn9Ouvv6pRo0Zq167dLc8TAAAAeFDwDBgAAAAAWRYaGqolS5ZYzylJ8/vvv1vTr5b2fJWr7d69W97e3sqXL1+Wl592i6+0q1eyYty4cQ5hSlpYknaLtP/973/Xvefw4cMqWbKkNVyuXDmtXLlSqampDs9bWbdunby9vVWiRImb1qNGjRr68ssvtWjRIqWkpFwXwHzzzTdatmyZVTZNaGio4uPjr5vfjT77a6VNT+9vkt583d3d1axZMzVr1kypqal6+eWX9dlnn+n1119XsWLFbtpOAAAA4EHFFTAAAAAAsqxx48ZKSUnRRx995DB+woQJcnFxUaNGjRzGx8bGavPmzdbwoUOHNGfOHDVo0CDDh7v//fffMsZcN/7zzz+XJOu5KFlRsWJF1atXz3qlPfckLCxMERERmjNnjv7++2+r/KJFi3To0CHVr1/fGteyZUsdOXJEP/74o0NdZ82apWbNmqX7fJhr1ahRQykpKRo7dqyKFy/uEERVq1ZNycnJ+vjjj+Xq6uoQzjRu3Fjr169XbGysNe7s2bOaNGmSihQpct1zXK4VEhKicuXKadq0aQ4B1uLFi697fszx48cdhl1dXVW2bFlJSvcWbAAAAAD+D1fAAAAAAMiyZs2a6fHHH9drr72mAwcOKCIiQosWLdKcOXPUu3dvPfLIIw7lS5curejoaPXq1UseHh76+OOPJUkjRozIcDn/+c9/9Omnn6pFixZ6+OGHdebMGS1cuFCLFy9Ws2bNVKdOHYfyb7zxhiRpx44dkqSvv/5aq1atkiQNGTLkpu2aMGGC6tevrxo1auhf//qXTp8+rfHjx6tEiRLq1q2bVa5ly5aqWrWqOnTooJ07dypv3rz6+OOPlZKSctM2pUm7qiU2Nlbt27d3mFaiRAnlzZtXsbGxKlOmjAICAqxpr776qr755hs1atRIvXr1UmBgoKZNm6b9+/frhx9+cLgi50ZGjx6tJk2aqEaNGnrppZd04sQJffjhh3r00UeVnJxslevUqZNOnDihOnXqqFChQvrzzz/14Ycfqly5ctYzZwAAAACkz8Wk93MyAAAAALhKjx49NHHiRIerUZKTkzV06FB9++23OnbsmIoUKaIuXbqoX79+cnFxscq5uLioe/fuioyM1IgRI3Tw4EGVKlVK48ePV1RUVIbL3bhxo8aMGaN169bpyJEjypEjh8LCwvTCCy+oZ8+eypHD8TdlVy/3Wpn96rNkyRK9/vrriouLk7e3t5o0aaIxY8YoODjYodzJkyc1YMAA/fTTT/rnn39UqVIljR07NktX5RQsWFCHDx/WpEmT1LlzZ4dpzZs319y5c9WtWzcrsErzxx9/aNCgQVqyZInOnz+vsmXLaujQoWrSpIlVZtmyZXr88cc1a9YstWzZ8rpl//jjjxoyZIj++OMPPfLII3rjjTc0Z84cLVu2TAcOHJAk/fDDD5o0aZLi4uJ06tQpBQcHq1GjRho+fPh1nwcAAAAARwQwAAAAALJVWgBz7e3KAAAAAOB+xjNgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJvluHkRAAAAALh1PHYSAAAAwIOIK2AAAAAAAAAAAABsRgADAAAAAAAAAABgM25BloHU1FQdPnxYvr6+cnFxcXZ1AAAAAAAAAACAExljdObMGRUoUECurhlf40IAk4HDhw+rcOHCzq4GAAAAAAAAAAC4ixw6dEiFChXKsAwBTAZ8fX0lXfkg/fz8nFwbAAAAAAAAAADgTElJSSpcuLCVH2SEACYDabcd8/PzI4ABAAAAAAAAAACSlKnHlmR8gzIAAAAAAAAAAABkGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbJbD2RXAvavIqzHOrgKc6MDbTZxdBQAAAAAAAAC4a3EFDAAAAAAAAAAAgM2cEsB88sknKlu2rPz8/OTn56fIyEj9/PPP1vTz58+re/fuypMnj3x8fPT000/ryJEjDvM4ePCgmjRpIm9vb+XPn18DBgzQ5cuXHcosW7ZMFSpUkIeHh4oVK6apU6feieYBAAAAAAAAAIAHnFNuQVaoUCG9/fbbKl68uIwxmjZtmpo3b64tW7bo0UcfVZ8+fRQTE6NZs2bJ399fPXr00FNPPaXVq1dLklJSUtSkSRMFBwdrzZo1SkhIUNu2bZUzZ0699dZbkqT9+/erSZMm6tq1q6ZPn66lS5eqU6dOCgkJUXR0tDOaDcBG3ALvwebsW+DR/x5szu5/AAAAAADg3uBijDHOroQkBQYG6t1331XLli2VL18+zZgxQy1btpQk/f777woPD1dsbKyqVq2qn3/+WU2bNtXhw4cVFBQkSfr00081aNAgHTt2TO7u7ho0aJBiYmL022+/Wct47rnndOrUKS1YsCBTdUpKSpK/v79Onz4tPz8/+xt9j+ME5IPN2Scg6X8PNvofnIn+B2dydv8DAAAAgAddVnIDpz8DJiUlRTNnztTZs2cVGRmpTZs26dKlS6pXr55VpmTJknrooYcUGxsrSYqNjVWZMmWs8EWSoqOjlZSUpB07dlhlrp5HWpm0eQAAAAAAAAAAAGQXp9yCTJK2b9+uyMhInT9/Xj4+Ppo9e7ZKlSqluLg4ubu7KyAgwKF8UFCQEhMTJUmJiYkO4Uva9LRpGZVJSkrSP//8Iy8vr+vqdOHCBV24cMEaTkpKuu12AgAAAAAAAACAB4/TroAJCwtTXFyc1q1bp27duqldu3bauXOns6ojSRo9erT8/f2tV+HChZ1aHwAAAAAAAAAAcG9yWgDj7u6uYsWKqWLFiho9erQiIiL0/vvvKzg4WBcvXtSpU6ccyh85ckTBwcGSpODgYB05cuS66WnTMirj5+eX7tUvkjR48GCdPn3aeh06dMiOpgIAAAAAAAAAgAeM058BkyY1NVUXLlxQxYoVlTNnTi1dutSaFh8fr4MHDyoyMlKSFBkZqe3bt+vo0aNWmcWLF8vPz0+lSpWyylw9j7QyafNIj4eHh/z8/BxeAAAAAAAAAAAAWeWUZ8AMHjxYjRo10kMPPaQzZ85oxowZWrZsmRYuXCh/f3917NhRffv2VWBgoPz8/NSzZ09FRkaqatWqkqQGDRqoVKlSevHFFzVmzBglJiZqyJAh6t69uzw8PCRJXbt21UcffaSBAwfqpZde0i+//KLvvvtOMTExzmgyAAAAAAAAAAB4gDglgDl69Kjatm2rhIQE+fv7q2zZslq4cKHq168vSZowYYJcXV319NNP68KFC4qOjtbHH39svd/NzU3z5s1Tt27dFBkZqVy5cqldu3YaOXKkVaZo0aKKiYlRnz599P7776tQoUL6/PPPFR0dfcfbCwAAAAAAAAAAHixOCWC++OKLDKd7enpq4sSJmjhx4g3LhIaGav78+RnOJyoqSlu2bLmlOgIAAABwVORVriZ/kB14u4lTl0//g7P7IAAAQFY5JYABAAAAAAC4lxACPtgIAAEAt4IABgAAAAAAALiLEQA+2AgAgXuXq7MrAAAAAAAAAAAAcL8hgAEAAAAAAAAAALAZtyADAAAAAAAAAKSLW+A92LgF3u3hChgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGzmlABm9OjRqlSpknx9fZU/f361aNFC8fHxDmWioqLk4uLi8OratatDmYMHD6pJkyby9vZW/vz5NWDAAF2+fNmhzLJly1ShQgV5eHioWLFimjp1anY3DwAAAAAAAAAAPOCcEsAsX75c3bt319q1a7V48WJdunRJDRo00NmzZx3Kde7cWQkJCdZrzJgx1rSUlBQ1adJEFy9e1Jo1azRt2jRNnTpVQ4cOtcrs379fTZo00eOPP664uDj17t1bnTp10sKFC+9YWwEAAAAAAAAAwIMnhzMWumDBAofhqVOnKn/+/Nq0aZNq1apljff29lZwcHC681i0aJF27typJUuWKCgoSOXKldOoUaM0aNAgDR8+XO7u7vr0009VtGhRjRs3TpIUHh6uVatWacKECYqOjs6+BgIAAAAAAAAAgAfaXfEMmNOnT0uSAgMDHcZPnz5defPmVenSpTV48GCdO3fOmhYbG6syZcooKCjIGhcdHa2kpCTt2LHDKlOvXj2HeUZHRys2Njbdely4cEFJSUkOLwAAAAAAAAAAgKxyyhUwV0tNTVXv3r1VvXp1lS5d2hr//PPPKzQ0VAUKFNC2bds0aNAgxcfH68cff5QkJSYmOoQvkqzhxMTEDMskJSXpn3/+kZeXl8O00aNHa8SIEba3EQAAAAAAAAAAPFicHsB0795dv/32m1atWuUwvkuXLtb/y5Qpo5CQENWtW1f79u3TI488ki11GTx4sPr27WsNJyUlqXDhwtmyLAAAAAAAAAAAcP9y6i3IevTooXnz5unXX39VoUKFMixbpUoVSdLevXslScHBwTpy5IhDmbThtOfG3KiMn5/fdVe/SJKHh4f8/PwcXgAAAAAAAAAAAFnllADGGKMePXpo9uzZ+uWXX1S0aNGbvicuLk6SFBISIkmKjIzU9u3bdfToUavM4sWL5efnp1KlSlllli5d6jCfxYsXKzIy0qaWAAAAAAAAAAAAXM8pAUz37t31n//8RzNmzJCvr68SExOVmJiof/75R5K0b98+jRo1Sps2bdKBAwc0d+5ctW3bVrVq1VLZsmUlSQ0aNFCpUqX04osvauvWrVq4cKGGDBmi7t27y8PDQ5LUtWtX/fHHHxo4cKB+//13ffzxx/ruu+/Up08fZzQbAAAAAAAAAAA8IJwSwHzyySc6ffq0oqKiFBISYr2+/fZbSZK7u7uWLFmiBg0aqGTJkurXr5+efvpp/fe//7Xm4ebmpnnz5snNzU2RkZF64YUX1LZtW40cOdIqU7RoUcXExGjx4sWKiIjQuHHj9Pnnnys6OvqOtxkAAAAAAAAAADw4cjhjocaYDKcXLlxYy5cvv+l8QkNDNX/+/AzLREVFacuWLVmqHwAAAAAAAAAAwO1wyhUwAAAAAAAAAAAA9zMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmTglgRo8erUqVKsnX11f58+dXixYtFB8f71Dm/Pnz6t69u/LkySMfHx89/fTTOnLkiEOZgwcPqkmTJvL29lb+/Pk1YMAAXb582aHMsmXLVKFCBXl4eKhYsWKaOnVqdjcPAAAAAAAAAAA84JwSwCxfvlzdu3fX2rVrtXjxYl26dEkNGjTQ2bNnrTJ9+vTRf//7X82aNUvLly/X4cOH9dRTT1nTU1JS1KRJE128eFFr1qzRtGnTNHXqVA0dOtQqs3//fjVp0kSPP/644uLi1Lt3b3Xq1EkLFy68o+0FAAAAAAAAAAAPlhzOWOiCBQschqdOnar8+fNr06ZNqlWrlk6fPq0vvvhCM2bMUJ06dSRJU6ZMUXh4uNauXauqVatq0aJF2rlzp5YsWaKgoCCVK1dOo0aN0qBBgzR8+HC5u7vr008/VdGiRTVu3DhJUnh4uFatWqUJEyYoOjr6jrcbAAAAAAAAAAA8GO6KZ8CcPn1akhQYGChJ2rRpky5duqR69epZZUqWLKmHHnpIsbGxkqTY2FiVKVNGQUFBVpno6GglJSVpx44dVpmr55FWJm0e17pw4YKSkpIcXgAAAAAAAAAAAFnl9AAmNTVVvXv3VvXq1VW6dGlJUmJiotzd3RUQEOBQNigoSImJiVaZq8OXtOlp0zIqk5SUpH/++ee6uowePVr+/v7Wq3Dhwra0EQAAAAAAAAAAPFicHsB0795dv/32m2bOnOnsqmjw4ME6ffq09Tp06JCzqwQAAAAAAAAAAO5BTnkGTJoePXpo3rx5WrFihQoVKmSNDw4O1sWLF3Xq1CmHq2COHDmi4OBgq8z69esd5nfkyBFrWtq/aeOuLuPn5ycvL6/r6uPh4SEPDw9b2gYAAAAAAAAAAB5cTrkCxhijHj16aPbs2frll19UtGhRh+kVK1ZUzpw5tXTpUmtcfHy8Dh48qMjISElSZGSktm/frqNHj1plFi9eLD8/P5UqVcoqc/U80sqkzQMAAAAAAAAAACA7OOUKmO7du2vGjBmaM2eOfH19rWe2+Pv7y8vLS/7+/urYsaP69u2rwMBA+fn5qWfPnoqMjFTVqlUlSQ0aNFCpUqX04osvasyYMUpMTNSQIUPUvXt36yqWrl276qOPPtLAgQP10ksv6ZdfftF3332nmJgYZzQbAAAAAAAAAAA8IJxyBcwnn3yi06dPKyoqSiEhIdbr22+/tcpMmDBBTZs21dNPP61atWopODhYP/74ozXdzc1N8+bNk5ubmyIjI/XCCy+obdu2GjlypFWmaNGiiomJ0eLFixUREaFx48bp888/V3R09B1tLwAAAAAAAAAAeLA45QoYY8xNy3h6emrixImaOHHiDcuEhoZq/vz5Gc4nKipKW7ZsyXIdAQAAAAAAAAAAbpVTroABAAAAAAAAAAC4nxHAAAAAAAAAAAAA2IwABgAAAAAAAAAAwGYEMAAAAAAAAAAAADYjgAEAAAAAAAAAALAZAQwAAAAAAAAAAIDNCGAAAAAAAAAAAABsRgADAAAAAAAAAABgMwIYAAAAAAAAAAAAmxHAAAAAAAAAAAAA2IwABgAAAAAAAAAAwGYEMAAAAAAAAAAAADYjgAEAAAAAAAAAALAZAQwAAAAAAAAAAIDNCGAAAAAAAAAAAABsRgADAAAAAAAAAABgMwIYAAAAAAAAAAAAmxHAAAAAAAAAAAAA2IwABgAAAAAAAAAAwGYEMAAAAAAAAAAAADYjgAEAAAAAAAAAALAZAQwAAAAAAAAAAIDNCGAAAAAAAAAAAABsRgADAAAAAAAAAABgMwIYAAAAAAAAAAAAmxHAAAAAAAAAAAAA2IwABgAAAAAAAAAAwGYEMAAAAAAAAAAAADYjgAEAAAAAAAAAALAZAQwAAAAAAAAAAIDNCGAAAAAAAAAAAABsRgADAAAAAAAAAABgMwIYAAAAAAAAAAAAmxHAAAAAAAAAAAAA2IwABgAAAAAAAAAAwGYEMAAAAAAAAAAAADZzSgCzYsUKNWvWTAUKFJCLi4t++uknh+nt27eXi4uLw6thw4YOZU6cOKE2bdrIz89PAQEB6tixo5KTkx3KbNu2TTVr1pSnp6cKFy6sMWPGZHfTAAAAAAAAAAAAnBPAnD17VhEREZo4ceINyzRs2FAJCQnW65tvvnGY3qZNG+3YsUOLFy/WvHnztGLFCnXp0sWanpSUpAYNGig0NFSbNm3Su+++q+HDh2vSpEnZ1i4AAAAAAAAAAABJyuGMhTZq1EiNGjXKsIyHh4eCg4PTnbZr1y4tWLBAGzZs0GOPPSZJ+vDDD9W4cWONHTtWBQoU0PTp03Xx4kV9+eWXcnd316OPPqq4uDiNHz/eIagBAAAAAAAAAACw2137DJhly5Ypf/78CgsLU7du3XT8+HFrWmxsrAICAqzwRZLq1asnV1dXrVu3zipTq1Ytubu7W2Wio6MVHx+vkydPprvMCxcuKCkpyeEFAAAAAAAAAACQVXdlANOwYUN99dVXWrp0qd555x0tX75cjRo1UkpKiiQpMTFR+fPnd3hPjhw5FBgYqMTERKtMUFCQQ5m04bQy1xo9erT8/f2tV+HChe1uGgAAAAAAAAAAeAA45RZkN/Pcc89Z/y9TpozKli2rRx55RMuWLVPdunWzbbmDBw9W3759reGkpCRCGAAAAAAAAAAAkGV35RUw13r44YeVN29e7d27V5IUHByso0ePOpS5fPmyTpw4YT03Jjg4WEeOHHEokzZ8o2fLeHh4yM/Pz+EFAAAAAAAAAACQVfdEAPPXX3/p+PHjCgkJkSRFRkbq1KlT2rRpk1Xml19+UWpqqqpUqWKVWbFihS5dumSVWbx4scLCwpQ7d+472wAAAAAAAAAAAPBAcUoAk5ycrLi4OMXFxUmS9u/fr7i4OB08eFDJyckaMGCA1q5dqwMHDmjp0qVq3ry5ihUrpujoaElSeHi4GjZsqM6dO2v9+vVavXq1evTooeeee04FChSQJD3//PNyd3dXx44dtWPHDn377bd6//33HW4xBgAAAAAAAAAAkB2cEsBs3LhR5cuXV/ny5SVJffv2Vfny5TV06FC5ublp27ZteuKJJ1SiRAl17NhRFStW1MqVK+Xh4WHNY/r06SpZsqTq1q2rxo0bq0aNGpo0aZI13d/fX4sWLdL+/ftVsWJF9evXT0OHDlWXLl3ueHsBAAAAAAAAAMCDJYczFhoVFSVjzA2nL1y48KbzCAwM1IwZMzIsU7ZsWa1cuTLL9QMAAAAAAAAAALgd98QzYAAAAAAAAAAAAO4lBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwmVMCmBUrVqhZs2YqUKCAXFxc9NNPPzlMN8Zo6NChCgkJkZeXl+rVq6c9e/Y4lDlx4oTatGkjPz8/BQQEqGPHjkpOTnYos23bNtWsWVOenp4qXLiwxowZk91NAwAAAAAAAAAAcE4Ac/bsWUVERGjixInpTh8zZow++OADffrpp1q3bp1y5cql6OhonT9/3irTpk0b7dixQ4sXL9a8efO0YsUKdenSxZqelJSkBg0aKDQ0VJs2bdK7776r4cOHa9KkSdnePgAAAAAAAAAA8GDL4YyFNmrUSI0aNUp3mjFG7733noYMGaLmzZtLkr766isFBQXpp59+0nPPPaddu3ZpwYIF2rBhgx577DFJ0ocffqjGjRtr7NixKlCggKZPn66LFy/qyy+/lLu7ux599FHFxcVp/PjxDkENAAAAAAAAAACA3e66Z8Ds379fiYmJqlevnjXO399fVapUUWxsrCQpNjZWAQEBVvgiSfXq1ZOrq6vWrVtnlalVq5bc3d2tMtHR0YqPj9fJkyfvUGsAAAAAAAAAAMCDyClXwGQkMTFRkhQUFOQwPigoyJqWmJio/PnzO0zPkSOHAgMDHcoULVr0unmkTcudO/d1y75w4YIuXLhgDSclJd1mawAAAAAAAAAAwIPorrsCxplGjx4tf39/61W4cGFnVwkAAAAAAAAAANyD7roAJjg4WJJ05MgRh/FHjhyxpgUHB+vo0aMO0y9fvqwTJ044lElvHlcv41qDBw/W6dOnrdehQ4duv0EAAAAAAAAAAOCBc9cFMEWLFlVwcLCWLl1qjUtKStK6desUGRkpSYqMjNSpU6e0adMmq8wvv/yi1NRUValSxSqzYsUKXbp0ySqzePFihYWFpXv7MUny8PCQn5+fwwsAAAAAAAAAACCrnBLAJCcnKy4uTnFxcZKk/fv3Ky4uTgcPHpSLi4t69+6tN954Q3PnztX27dvVtm1bFShQQC1atJAkhYeHq2HDhurcubPWr1+v1atXq0ePHnruuedUoEABSdLzzz8vd3d3dezYUTt27NC3336r999/X3379nVGkwEAAAAAAAAAwAMkhzMWunHjRj3++OPWcFoo0q5dO02dOlUDBw7U2bNn1aVLF506dUo1atTQggUL5Onpab1n+vTp6tGjh+rWrStXV1c9/fTT+uCDD6zp/v7+WrRokbp3766KFSsqb968Gjp0qLp06XLnGgoAAAAAAAAAAB5ITglgoqKiZIy54XQXFxeNHDlSI0eOvGGZwMBAzZgxI8PllC1bVitXrrzlegIAAAAAAAAAANyKu+4ZMAAAAAAAAAAAAPc6AhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAQAAAAAAAAAAsBkBDAAAAAAAAAAAgM0IYAAAAAAAAAAAAGxGAAMAAAAAAAAAAGAzAhgAAAAAAAAAAACbEcAAAAAAAAAAAADYjAAGAAAAAAAAAADAZndlADN8+HC5uLg4vEqWLGlNP3/+vLp37648efLIx8dHTz/9tI4cOeIwj4MHD6pJkyby9vZW/vz5NWDAAF2+fPlONwUAAAAAAAAAADyAcji7Ajfy6KOPasmSJdZwjhz/V9U+ffooJiZGs2bNkr+/v3r06KGnnnpKq1evliSlpKSoSZMmCg4O1po1a5SQkKC2bdsqZ86ceuutt+54WwAAAAAAAAAAwIPlrg1gcuTIoeDg4OvGnz59Wl988YVmzJihOnXqSJKmTJmi8PBwrV27VlWrVtWiRYu0c+dOLVmyREFBQSpXrpxGjRqlQYMGafjw4XJ3d7/TzQEAAAAAAAAAAA+Qu/IWZJK0Z88eFShQQA8//LDatGmjgwcPSpI2bdqkS5cuqV69elbZkiVL6qGHHlJsbKwkKTY2VmXKlFFQUJBVJjo6WklJSdqxY8edbQgAAAAAAAAAAHjg3JVXwFSpUkVTp05VWFiYEhISNGLECNWsWVO//fabEhMT5e7uroCAAIf3BAUFKTExUZKUmJjoEL6kTU+bdiMXLlzQhQsXrOGkpCSbWgQAAAAAAAAAAB4kd2UA06hRI+v/ZcuWVZUqVRQaGqrvvvtOXl5e2bbc0aNHa8SIEdk2fwAAAAAAAAAA8GC4a29BdrWAgACVKFFCe/fuVXBwsC5evKhTp045lDly5Ij1zJjg4GAdOXLkuulp025k8ODBOn36tPU6dOiQvQ0BAAAAAAAAAAAPhHsigElOTta+ffsUEhKiihUrKmfOnFq6dKk1PT4+XgcPHlRkZKQkKTIyUtu3b9fRo0etMosXL5afn59KlSp1w+V4eHjIz8/P4QUAAAAAAAAAAJBVd+UtyPr3769mzZopNDRUhw8f1rBhw+Tm5qbWrVvL399fHTt2VN++fRUYGCg/Pz/17NlTkZGRqlq1qiSpQYMGKlWqlF588UWNGTNGiYmJGjJkiLp37y4PDw8ntw4AAAAAAAAAANzv7soA5q+//lLr1q11/Phx5cuXTzVq1NDatWuVL18+SdKECRPk6uqqp59+WhcuXFB0dLQ+/vhj6/1ubm6aN2+eunXrpsjISOXKlUvt2rXTyJEjndUkAAAAAAAAAADwALkrA5iZM2dmON3T01MTJ07UxIkTb1gmNDRU8+fPt7tqAAAAAAAAAAAAN3VPPAMGAAAAAAAAAADgXkIAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANjsgQhgJk6cqCJFisjT01NVqlTR+vXrnV0lAAAAAAAAAABwH7vvA5hvv/1Wffv21bBhw7R582ZFREQoOjpaR48edXbVAAAAAAAAAADAfeq+D2DGjx+vzp07q0OHDipVqpQ+/fRTeXt768svv3R21QAAAAAAAAAAwH0qh7MrkJ0uXryoTZs2afDgwdY4V1dX1atXT7GxsdeVv3Dhgi5cuGANnz59WpKUlJSU/ZW9B6VeOOfsKsCJnL1e0P8ebPQ/OBP9D85E/4Mz0f/gbPRBOBP9D85E/4MzObv/3Y3SPhNjzE3LupjMlLpHHT58WAULFtSaNWsUGRlpjR84cKCWL1+udevWOZQfPny4RowYcaerCQAAAAAAAAAA7iGHDh1SoUKFMixzX18Bk1WDBw9W3759reHU1FSdOHFCefLkkYuLixNrhrtNUlKSChcurEOHDsnPz8/Z1cEDhv4HZ6L/wZnof3Am+h+cif4HZ6MPwpnof3Am+h/SY4zRmTNnVKBAgZuWva8DmLx588rNzU1HjhxxGH/kyBEFBwdfV97Dw0MeHh4O4wICArKzirjH+fn5sfGF09D/4Ez0PzgT/Q/ORP+DM9H/4Gz0QTgT/Q/ORP/Dtfz9/TNVzjWb6+FU7u7uqlixopYuXWqNS01N1dKlSx1uSQYAAAAAAAAAAGCn+/oKGEnq27ev2rVrp8cee0yVK1fWe++9p7Nnz6pDhw7OrhoAAAAAAAAAALhP3fcBTKtWrXTs2DENHTpUiYmJKleunBYsWKCgoCBnVw33MA8PDw0bNuy6W9YBdwL9D85E/4Mz0f/gTPQ/OBP9D85GH4Qz0f/gTPQ/3C4XY4xxdiUAAAAAAAAAAADuJ/f1M2AAAAAAAAAAAACcgQAGAAAAAAAAAADAZgQwAAAAAAAAAAAANiOAAbIoKipKvXv3dnY18AD4/fffVbVqVXl6eqpcuXLOrg4eEFdv44oUKaL33nvPmpaYmKj69esrV65cCggIcEr9AMBOy5Ytk4uLi06dOuXsqgC3bPjw4Rwrwunat2+vFi1aOLsauIdkZh98K9u3a7/DAICzEcAAwF1q2LBhypUrl+Lj47V06VJNnTqVk964ozZs2KAuXbpYwxMmTFBCQoLi4uK0e/duJ9YMAG4NP6TB/ah///5aunSps6sBABm6lX0w2zdkJ44LcafkcHYFAADp27dvn5o0aaLQ0FBb55uSkiIXFxe5upLBI2P58uVzGN63b58qVqyo4sWLO6lGAADgWj4+PvLx8XF2NQDAdmzfANwPOPsGZODs2bNq27atfHx8FBISonHjxjlMP3nypNq2bavcuXPL29tbjRo10p49e5xUW9xrFixYoBo1aiggIEB58uRR06ZNtW/fPkmSi4uLNm3apJEjR8rFxUVRUVHq0KGDTp8+LRcXF7m4uGj48OGSpAsXLqh///4qWLCgcuXKpSpVqmjZsmXWctKunJk7d65KlSolDw8PHTx40Aktxr3m6sv3ixQpoh9++EFfffWVXFxc1L59e0nSqVOn1KlTJ+XLl09+fn6qU6eOtm7d6rxK464VFRWlnj17qnfv3sqdO7eCgoI0efJknT17Vh06dJCvr6+KFSumn3/+WdKVsLhjx44qWrSovLy8FBYWpvfff99hnmm3Oxk7dqxCQkKUJ08ede/eXZcuXZIkjRw5UqVLl76uLuXKldPrr7+e/Y3GXaV9+/Zavny53n//fWtfeuDAAUnSpk2b9Nhjj8nb21vVqlVTfHy8w3vnzJmjChUqyNPTUw8//LBGjBihy5cvW9NdXFz02WefqWnTpvL29lZ4eLhiY2O1d+9eRUVFKVeuXKpWrZq1n8f9K6vbOklavny5KleuLA8PD4WEhOjVV1+1+tekSZNUoEABpaamOiynefPmeumllySlf4uezz//XOHh4fL09FTJkiX18ccfW9MuXryoHj16KCQkRJ6engoNDdXo0aOz6ROBs2XH/jclJUV9+/a1vscMHDhQxhiHMqmpqRo9erQ1n4iICH3//fd3rN24u9zqPvja7dvNjv3S8/nnnysgIIAraeAgvT6ZN29ejR071irTokUL5cyZU8nJyZKkv/76Sy4uLtq7d68kzgki8whggAwMGDBAy5cv15w5c7Ro0SItW7ZMmzdvtqa3b99eGzdu1Ny5cxUbGytjjBo3bpzhzh9Ic/bsWfXt21cbN27U0qVL5erqqieffFKpqalKSEjQo48+qn79+ikhIUFz587Ve++9Jz8/PyUkJCghIUH9+/eXJPXo0UOxsbGaOXOmtm3bpmeeeUYNGzZ02PGfO3dO77zzjj7//HPt2LFD+fPnd1azcY/asGGDGjZsqGeffVYJCQnWF/FnnnlGR48e1c8//6xNmzapQoUKqlu3rk6cOOHkGuNuNG3aNOXNm1fr169Xz5491a1bNz3zzDOqVq2aNm/erAYNGujFF1/UuXPnlJqaqkKFCmnWrFnauXOnhg4dqn//+9/67rvvHOb566+/at++ffr11181bdo0TZ06VVOnTpUkvfTSS9q1a5c2bNhgld+yZYu2bdumDh063Mmm4y7w/vvvKzIyUp07d7b2pYULF5Ykvfbaaxo3bpw2btyoHDlyWCe2JWnlypVq27atXnnlFe3cuVOfffaZpk6dqjfffNNh/qNGjVLbtm0VFxenkiVL6vnnn9e//vUvDR48WBs3bpQxRj169LijbYZzZGVb97///U+NGzdWpUqVtHXrVn3yySf64osv9MYbb0i6sp89fvy4fv31V2v+J06c0IIFC9SmTZt0lz99+nQNHTpUb775pnbt2qW33npLr7/+uqZNmyZJ+uCDDzR37lx99913io+P1/Tp01WkSJFs/1zgPHbvf8eNG6epU6fqyy+/1KpVq3TixAnNnj3bYZmjR4/WV199pU8//VQ7duxQnz599MILL2j58uV3uvm4C9zqPjg9GR37XWvMmDF69dVXtWjRItWtW9fuZuEell6ffPHFF60fsxpjtHLlSgUEBGjVqlWSrvxgomDBgipWrJgkzgkiCwyAdJ05c8a4u7ub7777zhp3/Phx4+XlZV555RWze/duI8msXr3amv73338bLy8vh/cAmXXs2DEjyWzfvt0YY0xERIQZNmyYNX3KlCnG39/f4T1//vmncXNzM//73/8cxtetW9cMHjzYep8kExcXl631x/2hdu3a5pVXXjHGGBMaGmomTJhgTWvevLlp166dNbxy5Urj5+dnzp8/7zCPRx55xHz22Wd3oLa4l9SuXdvUqFHDGr58+bLJlSuXefHFF61xCQkJRpKJjY1Ndx7du3c3Tz/9tDXcrl07Exoaai5fvmyNe+aZZ0yrVq2s4UaNGplu3bpZwz179jRRUVG2tAn3nqu3ccYY8+uvvxpJZsmSJda4mJgYI8n8888/xpgr+9S33nrLYT5ff/21CQkJsYYlmSFDhljDsbGxRpL54osvrHHffPON8fT0tLtJuMtkdVv373//24SFhZnU1FRr+sSJE42Pj49JSUkxxlzZ/7700kvW9M8++8wUKFDAmj5s2DATERFhTX/kkUfMjBkzHOo1atQoExkZaYy5sh2sU6eOwzJx/8qO/W9ISIgZM2aMNXzp0iVTqFAh07x5c2OMMefPnzfe3t5mzZo1DvPp2LGjad26tR3Nwj3oVvbB127fMnPsl/YdZuDAgSYkJMT89ttv2dco3NOu7ZNz5841/v7+5vLlyyYuLs4EBwebV155xQwaNMgYY0ynTp3M888/b4wxnBNElnAFDHAD+/bt08WLF1WlShVrXGBgoMLCwiRJu3btUo4cORym58mTR2FhYdq1a9cdry/uPXv27FHr1q318MMPy8/Pz/rlYVZuD7Z9+3alpKSoRIkS1v1xfXx8tHz5cofbnLi7u6ts2bJ2NwEPuK1btyo5OVl58uRx6H/79+/nNjtI19XbITc3N+XJk0dlypSxxgUFBUmSjh49KkmaOHGiKlasqHz58snHx0eTJk26bhv56KOPys3NzRoOCQmx3i9JnTt31jfffKPz58/r4sWLmjFjxk1/WYkHz9V9MyQkRNL/9cOtW7dq5MiRDtu5tF9Lnjt3Lt15pPXla/v3+fPnlZSUlK1tgfNlZVu3a9cuRUZGysXFxZpevXp1JScn66+//pIktWnTRj/88IMuXLgg6coVLs8991y6z/M7e/as9u3bp44dOzr02TfeeMPaN7dv315xcXEKCwtTr169tGjRIvs/BNxV7Nz/nj59WgkJCQ7fg3PkyKHHHnvMGt67d6/OnTun+vXrO/TDr776imNEXCejfXB6bnbsJ125Smvy5MlatWqVHn30UZtrjPtVzZo1debMGW3ZskXLly9X7dq1FRUVZV0Vs3z5ckVFRUninCCyJoezKwAAD6pmzZopNDRUkydPtu7tXbp0aV28eDHT80hOTpabm5s2bdrkcBAqyeFhhV5eXg5f7AE7JCcnKyQkxOGZQ2kCAgLueH1w98uZM6fDsIuLi8O4tO1UamqqZs6cqf79+2vcuHGKjIyUr6+v3n33Xa1bt+6m87z6WQnNmjWTh4eHZs+eLXd3d126dEktW7a0u2m4x92oH0pXtnUjRozQU089dd37PD09M5xHRvPF/Ssr27rMaNasmYwxiomJUaVKlbRy5UpNmDAh3bJp96mfPHmyw0khSdaxYoUKFbR//379/PPPWrJkiZ599lnVq1eP53Pcx7Jj/5uRtH4YExOjggULOkzz8PC41WbgPpXV7ePNjv2kKyfSY2Ji9N133+nVV1+1sba4nwUEBCgiIkLLli1TbGys6tevr1q1aqlVq1bavXu39uzZo9q1azu7mrgHEcAAN/DII48oZ86cWrdunR566CFJVx6wtXv3btWuXVvh4eG6fPmy1q1bp2rVqkmSjh8/rvj4eJUqVcqZVcc9IK2vTJ48WTVr1pQk676iN+Lu7q6UlBSHceXLl1dKSoqOHj1qzQe4UypUqKDExETlyJGDe8fDdqtXr1a1atX08ssvW+Nu5VezOXLkULt27TRlyhS5u7vrueeek5eXl51VxT0kvX3pzVSoUEHx8fHW/b4BO4WHh+uHH36QMcY68bh69Wr5+vqqUKFCkq4EfU899ZSmT5+uvXv3KiwsTBUqVEh3fkFBQSpQoID++OOPGz4jRpL8/PzUqlUrtWrVSi1btlTDhg114sQJBQYG2t9I3FNutv/19/dXSEiI1q1bp1q1akmSLl++bD0LUJJKlSolDw8PHTx4kJOVsNzKPvhWVa5cWT169FDDhg2VI0cO6/mpwNXS65O1a9fWr7/+qvXr1+vNN99UYGCgwsPD9eabbyokJEQlSpSQJM4JIksIYIAb8PHxUceOHTVgwADlyZNH+fPn12uvvWZd6l+8eHE1b95cnTt31meffSZfX1+9+uqrKliwoJo3b+7k2uNulzt3buXJk0eTJk1SSEiIDh48eNNf5hQpUkTJyclaunSpIiIi5O3trRIlSqhNmzZq27atxo0bp/Lly+vYsWNaunSpypYtqyZNmtyhFuFBVK9ePUVGRqpFixYaM2aMSpQoocOHDysmJkZPPvmkw60ogKwqXry4vvrqKy1cuFBFixbV119/rQ0bNqho0aJZnlenTp0UHh4u6cqJJTy4ihQponXr1unAgQPy8fHJ1BUIQ4cOVdOmTfXQQw+pZcuWcnV11datW/Xbb79ZD0oHbtXLL7+s9957Tz179lSPHj0UHx+vYcOGqW/fvg63GGvTpo2aNm2qHTt26IUXXshwniNGjFCvXr3k7++vhg0b6sKFC9q4caNOnjypvn37avz48QoJCVH58uXl6uqqWbNmKTg4mKtXISlz+99XXnlFb7/9tooXL66SJUtq/PjxOnXqlDXd19dX/fv3V58+fZSamqoaNWro9OnTWr16tfz8/NSuXTsntAzOdiv74NtRrVo1zZ8/X40aNVKOHDnUu3fvbF0e7j3X9snAwEBFRUXpww8/VL58+VSyZElJUlRUlD766CM988wz1ns5J4is4BkwQAbeffdd1axZU82aNVO9evVUo0YNVaxY0Zo+ZcoUVaxYUU2bNlVkZKSMMZo/f/51l8QC13J1ddXMmTO1adMmlS5dWn369NG7776b4XuqVaumrl27qlWrVsqXL5/GjBkj6Uo/bNu2rfr166ewsDC1aNFCGzZssK7cArKLi4uL5s+fr1q1aqlDhw4qUaKEnnvuOf3555/WvcSBW/Wvf/1LTz31lFq1aqUqVaro+PHjDr/GzYrixYurWrVqKlmy5HW35MGDpX///nJzc1OpUqWUL1++TD13LTo6WvPmzdOiRYtUqVIlVa1aVRMmTFBoaOgdqDHudwULFtT8+fO1fv16RUREqGvXrurYsaOGDBniUK5OnToKDAxUfHy8nn/++Qzn2alTJ33++eeaMmWKypQpo9q1a2vq1KnWCXRfX1+NGTNGjz32mCpVqqQDBw5o/vz56T5TBg+ezOx/+/XrpxdffFHt2rWzblP25JNPOpQZNWqUXn/9dY0ePVrh4eFq2LChYmJibumHFLg/3Mo++HbVqFFDMTExGjJkiD788MNsXx7uLen1yZo1ayo1NdXh6r2oqCilpKRYz39JwzlBZJaLMcY4uxIAAABAdjHGqHjx4nr55ZfVt29fZ1cHAAAAAPCA4BZkAAAAuG8dO3ZMM2fOVGJiojp06ODs6gAAAAAAHiAEMAAAALhv5c+fX3nz5tWkSZOUO3duZ1cHAAAAAPAAIYABAADAfYu77QIAAAAAnIWn7AEAAAAAAAAAANiMAAYAAAAAAAAAAMBmBDAAAAAAAAAAAAA2I4ABAAAAAAAAAACwGQEMAAAAAAAAAACAzQhgAAAAAAAAAAAAbEYAAwAAAAAAAAAAYDMCGAAAAAAAAAAAAJsRwAAAAAAAAAAAANjs/wEp3e1JQgpufAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag-of Words Model Utility\n",
        "\n",
        "---\n",
        "\n",
        "In this section, a utility function is provided for building a Bag-of-Words model. This function constructs a neural network model using TensorFlow's Keras API.\n",
        "\n",
        "The model architecture includes an input layer with a shape based on the maximum number of tokens (max_tokens), followed by a dense hidden layer with ReLU activation. A dropout layer is added to prevent overfitting, with a dropout rate of 50%. Finally, an output layer with a sigmoid activation function is included for binary classification.\n",
        "\n",
        "The model is compiled using the Adam optimizer and binary crossentropy loss function, making it suitable for binary classification tasks.\n",
        "\n",
        "This utility function offers flexibility by allowing customization of parameters such as the maximum number of tokens, the dimensionality of the hidden layer, and the dropout rate. By using this function, users can easily create and compile Bag-of-Words models tailored to their specific requirements."
      ],
      "metadata": {
        "id": "MBOmGFK8U70V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens=20000\n",
        "max_length=600\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "_lN6uwy-YU3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Function to build a neural network model\n",
        "def build_model(max_tokens=max_tokens, hidden_dims=16):\n",
        "    # Define the input layer with the shape based on max_tokens\n",
        "    inputs = Input(shape=(max_tokens,), name='Input_layer')\n",
        "\n",
        "    # Add a dense hidden layer with ReLU activation\n",
        "    x = Dense(hidden_dims, activation='relu', name='Hidden_layer')(inputs)\n",
        "\n",
        "    # Add a dropout layer to prevent overfitting\n",
        "    x = Dropout(0.50)(x)\n",
        "\n",
        "    # Add the output layer with sigmoid activation for binary classification\n",
        "    outputs = Dense(1, activation='sigmoid', name='Output_layer')(x)\n",
        "\n",
        "    # Create the model by specifying inputs and outputs\n",
        "    model = Model(inputs, outputs, name='Bag_of_Words_Model')\n",
        "\n",
        "    # Compile the model with Adam optimizer and binary crossentropy loss function\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Return the compiled model\n",
        "    return model"
      ],
      "metadata": {
        "id": "mc4s5NGJU-Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UniGram Model\n",
        "\n",
        "---\n",
        "In this section, a UniGram model is implemented for text classification using TensorFlow's Keras API.\n",
        "\n",
        "The TextVectorization layer is utilized to preprocess and vectorize the text data. The ngrams parameter is set to 1, indicating unigrams (individual words), and the output_mode is set to 'multi_hot', which outputs a binary vector indicating the presence or absence of each token in the vocabulary.\n",
        "\n",
        "The vocabulary of all unigram tokens in the dataset is built and indexed using the adapt method of the text_vectorization layer. Subsequently, the datasets are preprocessed and vectorized using this layer.\n",
        "\n",
        "Training, validation, and testing datasets are prepared by mapping the text data to their corresponding vectorized representations.\n",
        "\n",
        "A neural network model is built using the build_model function, with 20,000 max tokens and 64 hidden dimensions. The model is then compiled and trained using the binary crossentropy loss function and Adam optimizer. Model checkpoints are saved to ensure the best performing model is retained.\n",
        "\n",
        "After training, the model is evaluated on the test dataset, and the test accuracy is printed.\n",
        "\n",
        "This UniGram model serves as a baseline for text classification tasks, providing a foundation for more advanced models to be built upon."
      ],
      "metadata": {
        "id": "_IrtVQSyyA-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "ngrams=1\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    ngrams=ngrams,\n",
        "    output_mode='multi_hot'\n",
        ")\n",
        "\n",
        "# Extract only inputs and not labels from the dataset.\n",
        "text_only_ds = train_ds.map(lambda x, y: x)\n",
        "\n",
        "# Build the vocabulary of all unigram tokens in the dataset and index it.\n",
        "text_vectorization.adapt(text_only_ds)\n",
        "\n",
        "# Preprocess and vectorize the datasets.\n",
        "binary_1gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "binary_1gram_val_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "YuMNnolgox-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info_from_ds(binary_1gram_train_ds, 'Train')\n",
        "get_info_from_ds(binary_1gram_val_ds, 'Val')\n",
        "get_info_from_ds(binary_1gram_test_ds, 'Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5RQOhD0rYgE",
        "outputId": "7af317e6-39ef-4b4f-a101-75446a3a5fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(2, shape=(), dtype=int32)\n",
            "Val\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n",
            "Test\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = build_model(20000, 64)\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KZyoCKUWXAi",
        "outputId": "d49bee19-f304-48b3-8149-87eb43b1146a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Bag_of_Words_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input_layer (InputLayer)    [(None, 20000)]           0         \n",
            "                                                                 \n",
            " Hidden_layer (Dense)        (None, 64)                1280064   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        " ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                 save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "dJAb40qRbfU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(binary_1gram_train_ds.cache(),\n",
        "validation_data=binary_1gram_val_ds.cache(),\n",
        " epochs=epochs,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGQsddUUW77_",
        "outputId": "e77e54f5-74a5-4fa1-967f-b7f88d8dba5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.7804 - val_accuracy: 0.8661\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.8070 - val_accuracy: 0.8664\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.8015 - val_accuracy: 0.8658\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.8540 - val_accuracy: 0.8646\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.8639 - val_accuracy: 0.8631\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.9080 - val_accuracy: 0.8629\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.8752 - val_accuracy: 0.8617\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.9515 - val_accuracy: 0.8626\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.8999 - val_accuracy: 0.8637\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.9550 - val_accuracy: 0.8636\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.0535 - val_accuracy: 0.8653\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.0377 - val_accuracy: 0.8639\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.0661 - val_accuracy: 0.8639\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 1.0539 - val_accuracy: 0.8643\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 1.0508 - val_accuracy: 0.8620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a538151b9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test accuracy: {model1.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Kh-_SWXgbx",
        "outputId": "0b198a31-67b9-4b30-f19a-931b9c4bdc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7804 - accuracy: 0.8661\n",
            "Test accuracy: 0.866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unigram model achieves an accuracy of 86.7% on the test data. Let's try a bigram model to assess its performance."
      ],
      "metadata": {
        "id": "z4jsg_DhfAEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiGram Model\n",
        "\n",
        "---\n",
        "\n",
        "In this section, a BiGram model is implemented for text classification using TensorFlow's Keras API.\n",
        "\n",
        "The TextVectorization layer is employed to preprocess and vectorize the text data. The ngrams parameter is set to 2, indicating bigrams (pairs of consecutive words), and the output_mode is set to 'multi_hot', which outputs a binary vector indicating the presence or absence of each token in the vocabulary.\n",
        "\n",
        "The vocabulary of all bigram tokens in the dataset is built and indexed using the adapt method of the text_vectorization layer. Subsequently, the datasets are preprocessed and vectorized using this layer.\n",
        "\n",
        "Training, validation, and testing datasets are prepared by mapping the text data to their corresponding vectorized representations.\n",
        "\n",
        "A neural network model is built using the build_model function, with 20,000 max tokens and 16 hidden dimensions. The model is then compiled and trained using the binary crossentropy loss function and Adam optimizer. Model checkpoints are saved to ensure the best performing model is retained.\n",
        "\n",
        "After training, the model is evaluated on the test dataset, and the test accuracy is printed.\n",
        "\n",
        "This BiGram model extends the UniGram model by considering pairs of consecutive words, potentially capturing more complex patterns in the text data."
      ],
      "metadata": {
        "id": "07QFgBeq9pKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams=2\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    ngrams=ngrams,\n",
        "    output_mode='multi_hot'\n",
        ")\n",
        "\n",
        "# Build the vocabulary of all bigram tokens in the dataset and index it.\n",
        "text_vectorization.adapt(text_only_ds)\n",
        "\n",
        "# Preprocess and vectorize the datasets.\n",
        "binary_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "binary_2gram_val_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "binary_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "zlZnp9LD9tkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info_from_ds(binary_2gram_train_ds, 'Train')\n",
        "get_info_from_ds(binary_2gram_val_ds, 'Val')\n",
        "get_info_from_ds(binary_2gram_test_ds, 'Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfRpJkYh-N8Y",
        "outputId": "026436de-4340-468d-df17-0bbb0e40a708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n",
            "Val\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n",
            "Test\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = build_model(20000, 16)\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYyd_Mol-y7f",
        "outputId": "1bbbb49e-162b-4294-9a42-6cb1c2b6dc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Bag_of_Words_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input_layer (InputLayer)    [(None, 20000)]           0         \n",
            "                                                                 \n",
            " Hidden_layer (Dense)        (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " Output_layer (Dense)        (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320033 (1.22 MB)\n",
            "Trainable params: 320033 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        " ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                 save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "qa8_sY3C-22f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(binary_2gram_train_ds.cache(),\n",
        "validation_data=binary_2gram_val_ds.cache(),\n",
        " epochs=epochs,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU3s1IBX-6-f",
        "outputId": "7e7dcc5f-e032-4bef-953e-999dff2a0f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 11s 16ms/step - loss: 0.1334 - accuracy: 0.9551 - val_loss: 0.2814 - val_accuracy: 0.8916\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1007 - accuracy: 0.9653 - val_loss: 0.3189 - val_accuracy: 0.8917\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0807 - accuracy: 0.9732 - val_loss: 0.3405 - val_accuracy: 0.8898\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.4030 - val_accuracy: 0.8896\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 0.4128 - val_accuracy: 0.8874\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0454 - accuracy: 0.9850 - val_loss: 0.4273 - val_accuracy: 0.8890\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.4490 - val_accuracy: 0.8882\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0424 - accuracy: 0.9851 - val_loss: 0.4652 - val_accuracy: 0.8874\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.0384 - accuracy: 0.9859 - val_loss: 0.5347 - val_accuracy: 0.8876\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0394 - accuracy: 0.9850 - val_loss: 0.5219 - val_accuracy: 0.8877\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.5415 - val_accuracy: 0.8857\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 0.5952 - val_accuracy: 0.8862\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.5694 - val_accuracy: 0.8861\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0326 - accuracy: 0.9878 - val_loss: 0.6264 - val_accuracy: 0.8869\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.6377 - val_accuracy: 0.8847\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a689b360550>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test accuracy: {model2.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a4aCCVA--_3",
        "outputId": "4d76f121-9309-4c33-919f-ed15205f6352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2562 - accuracy: 0.8951\n",
            "Test accuracy: 0.895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to the unigram model's accuracy of 88.1%, the bigram model has shown an improved accuracy of 89.5% on the test data, indicating the significance of local word order."
      ],
      "metadata": {
        "id": "KZVaUZD8dFL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TriGram Model\n",
        "\n",
        "---\n",
        "\n",
        "In this section, a TriGram model is implemented for text classification using TensorFlow's Keras API.\n",
        "\n",
        "The TextVectorization layer is utilized to preprocess and vectorize the text data. The ngrams parameter is set to 3, indicating trigrams (sequences of three consecutive words), and the output_mode is set to 'multi_hot', which outputs a binary vector indicating the presence or absence of each token in the vocabulary.\n",
        "\n",
        "The vocabulary of all trigram tokens in the dataset is built and indexed using the adapt method of the text_vectorization layer. Subsequently, the datasets are preprocessed and vectorized using this layer.\n",
        "\n",
        "Training, validation, and testing datasets are prepared by mapping the text data to their corresponding vectorized representations.\n",
        "\n",
        "A neural network model is built using the build_model function, with 20,000 max tokens and 16 hidden dimensions. The model is then compiled and trained using the binary crossentropy loss function and Adam optimizer. Model checkpoints are saved to ensure the best performing model is retained.\n",
        "\n",
        "After training, the model is evaluated on the test dataset, and the test accuracy is printed.\n",
        "\n",
        "This TriGram model further extends the BiGram model by considering sequences of three consecutive words, potentially capturing even more nuanced patterns in the text data."
      ],
      "metadata": {
        "id": "4bf5l2OSdnX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams=3\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    ngrams=ngrams,\n",
        "    output_mode='multi_hot'\n",
        ")\n",
        "\n",
        "# Build the vocabulary of all trigram tokens in the dataset and index it.\n",
        "text_vectorization.adapt(text_only_ds)\n",
        "\n",
        "# Preprocess and vectorize the datasets.\n",
        "binary_3gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "binary_3gram_val_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "binary_3gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "GMFVtzD5dsVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info_from_ds(binary_3gram_train_ds, 'Train')\n",
        "get_info_from_ds(binary_3gram_val_ds, 'Val')\n",
        "get_info_from_ds(binary_3gram_test_ds, 'Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m59AqMLsdy-Q",
        "outputId": "c149aa92-4316-4466-81cb-2faa42a529b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n",
            "Val\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n",
            "Test\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor([1. 1. 0. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = build_model(20000, 16)\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jnNwPqrd20J",
        "outputId": "17e1bdcb-fafe-4c27-9245-205e191fd5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Bag_of_Words_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input_layer (InputLayer)    [(None, 20000)]           0         \n",
            "                                                                 \n",
            " Hidden_layer (Dense)        (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " Output_layer (Dense)        (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320033 (1.22 MB)\n",
            "Trainable params: 320033 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        " ModelCheckpoint(\"binary_3gram.keras\",\n",
        "                 save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "c8WyCq2Sd7Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(binary_3gram_train_ds.cache(),\n",
        "validation_data=binary_3gram_val_ds.cache(),\n",
        " epochs=epochs,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBGDkKGAeB5C",
        "outputId": "1ce475b3-219e-4b7d-bc9d-bc62fde7909d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.3658 - accuracy: 0.8493 - val_loss: 0.2582 - val_accuracy: 0.8966\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1934 - accuracy: 0.9275 - val_loss: 0.2639 - val_accuracy: 0.8933\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1328 - accuracy: 0.9521 - val_loss: 0.2822 - val_accuracy: 0.8942\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0969 - accuracy: 0.9643 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 0.3471 - val_accuracy: 0.8899\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.0640 - accuracy: 0.9755 - val_loss: 0.3788 - val_accuracy: 0.8901\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0571 - accuracy: 0.9774 - val_loss: 0.3987 - val_accuracy: 0.8899\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0446 - accuracy: 0.9821 - val_loss: 0.4353 - val_accuracy: 0.8878\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.0468 - accuracy: 0.9807 - val_loss: 0.4409 - val_accuracy: 0.8888\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0410 - accuracy: 0.9821 - val_loss: 0.4892 - val_accuracy: 0.8876\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0370 - accuracy: 0.9826 - val_loss: 0.5042 - val_accuracy: 0.8870\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.0350 - accuracy: 0.9847 - val_loss: 0.5402 - val_accuracy: 0.8875\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0335 - accuracy: 0.9843 - val_loss: 0.6200 - val_accuracy: 0.8842\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0314 - accuracy: 0.9852 - val_loss: 0.5836 - val_accuracy: 0.8866\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.0322 - accuracy: 0.9857 - val_loss: 0.6257 - val_accuracy: 0.8870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a6892504ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = load_model(\"binary_3gram.keras\")\n",
        "print(f\"Test accuracy: {model3.evaluate(binary_3gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvSX0t2GeHFD",
        "outputId": "2de9d57c-d722-45d6-d984-5e8ffa5ff76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2582 - accuracy: 0.8966\n",
            "Test accuracy: 0.897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trigram model has an accuracy of 89.7% on the test data, which is better than the bigram model's accuracy of 89.5%.\n",
        "\n",
        "We will employ the bigram model in conjunction with term frequency-inverse document frequency (TF-IDF) to evaluate performance. TF-IDF assigns weight to a term by considering its \"term frequency\" within the current document, divided by its \"inverse document frequency,\" which gauges how frequently the term occurs across the dataset."
      ],
      "metadata": {
        "id": "QfErAncufDAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiGram Model with TF-IDF\n",
        "\n",
        "---\n",
        "\n",
        "In this section, a BiGram model with TF-IDF (Term Frequency-Inverse Document Frequency) representation is implemented for text classification using TensorFlow's Keras API.\n",
        "\n",
        "The TextVectorization layer is utilized to preprocess and vectorize the text data. The ngrams parameter is set to 2, indicating bigrams (pairs of consecutive words), and the output_mode is set to 'tf_idf', which computes the TF-IDF representation of each token.\n",
        "\n",
        "The vocabulary of all bigram tokens in the dataset is built and indexed using the adapt method of the text_vectorization layer. Subsequently, the datasets are preprocessed and vectorized using this layer.\n",
        "\n",
        "Training, validation, and testing datasets are prepared by mapping the text data to their corresponding TF-IDF representations.\n",
        "\n",
        "A neural network model is built using the build_model function, with 20,000 max tokens and 16 hidden dimensions. The model is then compiled and trained using the binary crossentropy loss function and Adam optimizer. Model checkpoints are saved to ensure the best performing model is retained.\n",
        "\n",
        "After training, the model is evaluated on the test dataset, and the test accuracy is printed.\n",
        "\n",
        "This BiGram model with TF-IDF representation leverages the frequency of bigram tokens in each document and across the entire corpus to capture the importance of each token, potentially improving the model's performance compared to traditional bag-of-words approaches."
      ],
      "metadata": {
        "id": "uQO9s9Qk7hpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams=2\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    ngrams=ngrams,\n",
        "    output_mode='tf_idf'\n",
        ")\n",
        "\n",
        "# Build the vocabulary of all bigram tokens in the dataset and index it.\n",
        "text_vectorization.adapt(text_only_ds)\n",
        "\n",
        "# Preprocess and vectorize the datasets.\n",
        "tfidf_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "tfidf_2gram_val_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "tfidf_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "GxtATZ2i7qJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info_from_ds(tfidf_2gram_train_ds, 'Train')\n",
        "get_info_from_ds(tfidf_2gram_val_ds, 'Val')\n",
        "get_info_from_ds(tfidf_2gram_test_ds, 'Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pANhmdD71Ve",
        "outputId": "932a5497-9dde-4d17-e481-928fc75a0dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(\n",
            "[1156.7074       4.1851544    5.6891665 ...    0.           0.\n",
            "    0.       ], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(1, shape=(), dtype=int32)\n",
            "Val\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(\n",
            "[319.8269      2.0925772   1.4222916 ...   0.          0.\n",
            "   0.       ], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n",
            "Test\n",
            "\tinputs.shape: (32, 20000)\n",
            "\tinputs.dtype: <dtype: 'float32'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(\n",
            "[490.40128     2.0925772   0.7111458 ...   0.          0.\n",
            "   0.       ], shape=(20000,), dtype=float32)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = build_model(20000, 16)\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN183tAZ799U",
        "outputId": "e085b616-4d2e-43db-8a57-cb3d56a1c896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Bag_of_Words_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input_layer (InputLayer)    [(None, 20000)]           0         \n",
            "                                                                 \n",
            " Hidden_layer (Dense)        (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " Output_layer (Dense)        (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320033 (1.22 MB)\n",
            "Trainable params: 320033 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        " ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                 save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "7dKzMDe-8Clq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.fit(tfidf_2gram_train_ds.cache(),\n",
        "validation_data=tfidf_2gram_val_ds.cache(),\n",
        " epochs=epochs,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO6nU1eq8M2I",
        "outputId": "dfe91dc4-e00b-4d85-f51e-38e5206026b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 32s 49ms/step - loss: 0.5537 - accuracy: 0.7340 - val_loss: 0.2998 - val_accuracy: 0.8896\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3434 - accuracy: 0.8528 - val_loss: 0.2778 - val_accuracy: 0.8922\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2765 - accuracy: 0.8795 - val_loss: 0.2742 - val_accuracy: 0.8869\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2317 - accuracy: 0.8967 - val_loss: 0.2914 - val_accuracy: 0.8842\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1986 - accuracy: 0.9093 - val_loss: 0.3012 - val_accuracy: 0.8897\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1794 - accuracy: 0.9146 - val_loss: 0.3150 - val_accuracy: 0.8862\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.1624 - accuracy: 0.9212 - val_loss: 0.3641 - val_accuracy: 0.8908\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1469 - accuracy: 0.9276 - val_loss: 0.3571 - val_accuracy: 0.8879\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1446 - accuracy: 0.9246 - val_loss: 0.4192 - val_accuracy: 0.8880\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1352 - accuracy: 0.9288 - val_loss: 0.4071 - val_accuracy: 0.8886\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1261 - accuracy: 0.9323 - val_loss: 0.4337 - val_accuracy: 0.8864\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1236 - accuracy: 0.9328 - val_loss: 0.4372 - val_accuracy: 0.8886\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1151 - accuracy: 0.9395 - val_loss: 0.4632 - val_accuracy: 0.8883\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1131 - accuracy: 0.9388 - val_loss: 0.4594 - val_accuracy: 0.8882\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1114 - accuracy: 0.9405 - val_loss: 0.5025 - val_accuracy: 0.8864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5381679210>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"Test accuracy: {model4.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNZfq_f-8cOG",
        "outputId": "271cbcd2-69be-463f-ed8d-4a6766249fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 9s 11ms/step - loss: 0.2742 - accuracy: 0.8869\n",
            "Test accuracy: 0.887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model at 88.7% accuracy performed slightly worse than all previous models, with the exception of the unigram model."
      ],
      "metadata": {
        "id": "nPnt5Mw8AM2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence-to-Sequence Utility Model\n",
        "\n",
        "---\n",
        "In this section, a utility model for Sequence-to-Sequence tasks is defined using TensorFlow's Keras API. The model architecture includes an input layer that accepts sequences of variable length with integer values representing tokens. An embedding layer (one_hot) converts the integer-encoded tokens into one-hot encoded vectors with a depth of max_tokens. A Bidirectional LSTM layer with 32 units processes the embedded sequences bidirectionally to capture both past and future contexts. A dropout layer with a dropout rate of 0.5 prevents overfitting. Finally, an output layer with a single neuron and sigmoid activation function is added for binary classification. The model is compiled with the Adam optimizer and binary crossentropy loss function, suitable for binary classification tasks. Accuracy is chosen as the evaluation metric. Summarizing the model architecture provides insights into the number of parameters, layer types, and connections within the model, facilitating further analysis and adjustments if needed.\n"
      ],
      "metadata": {
        "id": "bno4Frlh6N8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import one_hot\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "\n",
        "inputs= Input(shape=(None,), dtype='int64')\n",
        "\n",
        "embedded = one_hot(inputs, depth=max_tokens)\n",
        "\n",
        "x = Bidirectional(LSTM(32))(embedded)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model1 = Model(inputs, outputs)\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q_MrY087B0X",
        "outputId": "9bc99de2-cd8b-47c6-cc87-84087df1c84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                5128448   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5128513 (19.56 MB)\n",
            "Trainable params: 5128513 (19.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with One-Hot Encoded Vectors\n",
        "\n",
        "---\n",
        "\n",
        "In this section, a model utilizing one-hot encoded vectors is implemented for sequence-to-sequence tasks using TensorFlow's Keras API.\n",
        "\n",
        "Callbacks for model checkpointing are defined to save the best performing model during training.\n",
        "\n",
        "The TextVectorization layer is used to preprocess and vectorize the text data. The output_mode is set to 'int' to output integer-encoded sequences, and the output_sequence_length is set to max_length to pad or truncate sequences to a fixed length.\n",
        "\n",
        "The vocabulary is built and indexed using the adapt method of the text_vectorization layer. Subsequently, the datasets are preprocessed and vectorized using this layer.\n",
        "\n",
        "Training, validation, and testing datasets are prepared by mapping the text data to their corresponding integer-encoded sequences.\n",
        "\n",
        "The model is then trained using the fit method. Due to the computational complexity of training with one-hot encoded sequences and Bidirectional LSTM, the model is trained for only 5 epochs.\n",
        "\n",
        "After training, the best performing model is loaded, and its performance is evaluated on the test dataset, with the test accuracy printed.\n",
        "\n",
        "It should be noted that training with one-hot encoded sequences can be computationally intensive compared to other encoding methods."
      ],
      "metadata": {
        "id": "RJqr8pE9YuEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        " ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                 save_best_only=True)\n",
        "]\n",
        "\n",
        "epochs=15"
      ],
      "metadata": {
        "id": "HruW-jkm8SP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_length\n",
        ")\n",
        "\n",
        "# Build the vocabulary and index it.\n",
        "text_vectorization.adapt(text_only_ds)\n",
        "\n",
        "# Preprocess and vectorize the datasets.\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "int_val_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ],
      "metadata": {
        "id": "bEsKksDT6UJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info_from_ds(int_train_ds, 'Train')\n",
        "get_info_from_ds(int_val_ds, 'Val')\n",
        "get_info_from_ds(int_test_ds, 'Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKCRc9P764_l",
        "outputId": "04908a43-ba93-463b-af06-60c5f7222099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "\tinputs.shape: (32, 600)\n",
            "\tinputs.dtype: <dtype: 'int64'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(\n",
            "[   10   209    11     8     4  4806   105   496   157     2  4284   632\n",
            "     3    10   222   130    10    14   544   692     3    10    26     6\n",
            "   266     2  2101     5   129   701    21     2  2190     6   178  3175\n",
            "  3840     8     2   476   216  5301    21    49    23   103    43  3840\n",
            "    55    14   343  2213  2991    41     7    38   231     8   126    40\n",
            "   419    12    55   140    28     2   396   507    16     2  4593 11080\n",
            "    16   242   512    10   103    72    66   411     6    28  2182     6\n",
            "    40   297    55     7   330  5838     2    81    83  1588    85    34\n",
            "   606   290    19   425    90   709    57     2   294    46     5    32\n",
            "     2    83  1588     8    11    18   439   130     2    29    36   114\n",
            "     2   113   290    14  8930  4869  4753     7  1162     8     2   436\n",
            "     3    61   713   770     2    53  2808    13   513   886    15    74\n",
            "     9   255   127    52    15   100   877   409    71   357   106     8\n",
            "   109     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n",
            "Val\n",
            "\tinputs.shape: (32, 600)\n",
            "\tinputs.dtype: <dtype: 'int64'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(\n",
            "[  439    39     6   374    33   654    10    59    22   138    67    11\n",
            "    18   174    45    35    66   723    46  4233    91     5  1119  2017\n",
            "     3     2  3924  2456    70  5804   120    11    18    14   382    10\n",
            "   175   194    11     9     4   357  1188   716    80    48    25    58\n",
            "  1514   393     2   112     7   408   382    11    18     7     4  5389\n",
            "   438    21     2   352     2    88  1712   499    45    23    63   177\n",
            "     6  1890   640    16  1489   230   861   139    39 17208    31   217\n",
            "     1  1472    47   124  1353   980   140     1     2  1777   809     9\n",
            "   142    22  3034    43     2  1111    10  1485     6    67     2   812\n",
            "   439    42    39     2  1489   230     5    56   120  6917    13    69\n",
            "    23   194    70    56    62   143  7650  4101  1906  2644     1     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n",
            "Test\n",
            "\tinputs.shape: (32, 600)\n",
            "\tinputs.dtype: <dtype: 'int64'>\n",
            "\ttargets.shape: (32,)\n",
            "\ttargets.dtype: <dtype: 'int32'>\n",
            "\tinputs[0]: tf.Tensor(\n",
            "[   36     2  2188    68     2  1835   315     5   967  6538  1909     8\n",
            "    11    20     9   140    26    75  4741     1   954    32     2    96\n",
            "    31     2    53   217  2970   140    26    68    40  1104  2350    13\n",
            "    13    48     7    47 19707     8     2   186    12  1393     1   589\n",
            "     7   180    74   785  6879   547    16   176    86   183    10   232\n",
            "     3    72    85    77   349    33     2   195  2193   178  1052   944\n",
            "     1     3     1  1486    13    13    10  1395   616  5120    68     6\n",
            "    28   335     4   637  2951     2  4718  1812    23    13    13   446\n",
            "    10   103     8    11    29     2   353 15208    14   178     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
            "\ttargets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(int_train_ds,\n",
        "validation_data=int_val_ds,\n",
        " epochs=5, # We will onyl train for 5 epochs as training the data using one-hot encoded sequences and Bidirectional LSTM is extremely slow\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "id": "5XLEdsZZ8OgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test accuracy: {model1.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0vdDn7A8r9C",
        "outputId": "bb6dcf35-8057-4da4-847a-7a39b79fdaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 93s 117ms/step - loss: 0.3440 - accuracy: 0.8571\n",
            "Test accuracy: 0.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model that uses one-hot encoded vectors is extremely slow and has the lowest test accuracy among all the bag-of-words models. For the next model, we will use word embeddings instead of one-hot encoded vectors."
      ],
      "metadata": {
        "id": "WGB6ETWXEB-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with Word Embeddings\n",
        "\n",
        "---\n",
        "In this section, a model is implemented using word embeddings for sequence-to-sequence tasks. The model architecture includes an input layer that accepts sequences of variable length with integer values representing tokens. An embedding layer is added, which maps each integer token to a dense vector representation of dimensionality 256. The mask_zero=True parameter instructs the layer to ignore padding tokens, ensuring that the recurrent layers skip these padding iterations during processing.\n",
        "\n",
        "Bidirectional LSTM layer with 32 units is added to process the embedded sequences bidirectionally, capturing both past and future contexts. A dropout layer with a dropout rate of 0.5 is included to prevent overfitting. Finally, an output layer with a single neuron and sigmoid activation function is added for binary classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer and binary crossentropy loss function, and accuracy is chosen as the evaluation metric.\n",
        "\n",
        "Callbacks are defined for model checkpointing to save the best performing model during training.\n",
        "\n",
        "The model is then trained using the fit method with the training and validation datasets. After training, the best performing model is loaded, and its performance is evaluated on the test dataset, with the test accuracy printed\n"
      ],
      "metadata": {
        "id": "WBjjC8gMY43N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "inputs= Input(shape=(None,), dtype='int64')\n",
        "\n",
        "embedded = Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs) # mask_zero=True instructs the layer to ignore padding tokens (encoded as zeros),\n",
        "                                                                                   # ensuring that the RNN skips these padding iterations during processing.\n",
        "\n",
        "x = Bidirectional(LSTM(32))(embedded)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model2 = Model(inputs, outputs, name='Model_using_Embeddings')\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "callbacks = [\n",
        " ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        " save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-faVWmKaYLv",
        "outputId": "0ffe8979-59f9-4f30-bc9a-31815ce93116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_using_Embeddings\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5194049 (19.81 MB)\n",
            "Trainable params: 5194049 (19.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(int_train_ds,\n",
        "validation_data=int_val_ds,\n",
        " epochs=epochs,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Eu_Mlcbn2k",
        "outputId": "35df4060-d343-4863-98ec-e7e2aba9f31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 101s 143ms/step - loss: 0.3901 - accuracy: 0.8223 - val_loss: 0.3092 - val_accuracy: 0.8709\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 57s 92ms/step - loss: 0.1724 - accuracy: 0.9368 - val_loss: 0.3177 - val_accuracy: 0.8680\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 56s 90ms/step - loss: 0.0820 - accuracy: 0.9715 - val_loss: 0.4203 - val_accuracy: 0.8656\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 0.0559 - accuracy: 0.9801 - val_loss: 0.5175 - val_accuracy: 0.8569\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.5403 - val_accuracy: 0.8516\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.6241 - val_accuracy: 0.8589\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0381 - accuracy: 0.9868 - val_loss: 0.6399 - val_accuracy: 0.8528\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 40s 65ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.6708 - val_accuracy: 0.8539\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.7428 - val_accuracy: 0.8569\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.7836 - val_accuracy: 0.8524\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 49s 78ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.7006 - val_accuracy: 0.8411\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 41s 65ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.6602 - val_accuracy: 0.8415\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.7723 - val_accuracy: 0.8435\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 45s 72ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.8229 - val_accuracy: 0.8518\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.8665 - val_accuracy: 0.8536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f6a08fa8520>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test accuracy: {model2.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "k10nkXg-bx8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1440f3e9-4ac3-4b44-e15c-add49181c6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 19s 19ms/step - loss: 0.3092 - accuracy: 0.8709\n",
            "Test accuracy: 0.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model achieved an accuracy of 87.1%, significantly outperforming the previous one. Next, we will use pre-trained word embeddings."
      ],
      "metadata": {
        "id": "ETmVu_RnNIMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model using Pretrained Word Embeddings\n",
        "\n",
        "---\n",
        "In this section, pretrained word embeddings are utilized in a model for sequence-to-sequence tasks. GloVe (Global Vectors for Word Representation) embeddings are downloaded and extracted from a provided URL. The downloaded embeddings are then loaded and processed to create a dictionary mapping words to their embedding vectors.\n",
        "\n",
        "The vocabulary is obtained using the text_vectorization.get_vocabulary() method, and a word index is created to map words to their indices in the vocabulary.\n",
        "\n",
        "Next, an embedding matrix is constructed using the pretrained word embeddings for words present in the dataset's vocabulary. Words not found in the pretrained embeddings are initialized with zeros.\n",
        "\n",
        "An embedding layer is defined using the constructed embedding matrix. This layer is configured to use the pretrained embedding vectors, set to be non-trainable (trainable=False), and to mask zero values to ignore padding tokens during processing.\n",
        "\n",
        "The model architecture includes an input layer accepting sequences of integer tokens, followed by the pretrained embedding layer. Bidirectional LSTM layer processes the embedded sequences bidirectionally, capturing context from both directions. A dropout layer with a dropout rate of 0.5 is added to prevent overfitting. Finally, a dense output layer with a sigmoid activation function is included for binary classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer and binary crossentropy loss function. Accuracy is chosen as the evaluation metric.\n",
        "\n",
        "Callbacks are defined for model checkpointing to save the best performing model during training.\n",
        "\n",
        "The model is trained using the fit method with the training and validation datasets. After training, the best performing model is loaded, and its performance is evaluated on the test dataset, with the test accuracy printed.\n"
      ],
      "metadata": {
        "id": "9L_0ZrUMOke6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8iqiLQsOyeu",
        "outputId": "f84d4e3f-9372-48a3-f58f-54d5d7329eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-29 21:22:00--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-05-29 21:22:00--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-05-29 21:22:00--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zipâ€™\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-05-29 21:24:39 (5.18 MB/s) - â€˜glove.6B.zipâ€™ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(path_to_glove_file) as f:\n",
        " for line in f:\n",
        "  word, coefs = line.split(maxsplit=1)\n",
        "  coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "  embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URAjplQxPA3X",
        "outputId": "26c45e30-59fe-4acc-b629-9b75a5749112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        " if i < max_tokens:\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        " if embedding_vector is not None:\n",
        "  embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "FgDPXdOvQRCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "embedding_layer = Embedding(input_dim=max_tokens,\n",
        "                            output_dim=embedding_dim,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            trainable=False,\n",
        "                            mask_zero=True)"
      ],
      "metadata": {
        "id": "583W7sm9R5Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "embedded = embedding_layer(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(32))(embedded)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model1 = Model(inputs, outputs, name='Model_using_Pretrained_Word_Embeddings')\n",
        "\n",
        "model1.compile(optimizer=\"adam\",\n",
        " loss=\"binary_crossentropy\",\n",
        " metrics=[\"accuracy\"])\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "callbacks = [\n",
        " ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        " save_best_only=True)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKyhEiSSSkRz",
        "outputId": "d84e045a-367e-4857-9ac3-42c17b98dce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_using_Pretrained_Word_Embeddings\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 100)         2000000   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 64)                34048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2034113 (7.76 MB)\n",
            "Trainable params: 34113 (133.25 KB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm6FxitrS2qI",
        "outputId": "184ec6ce-5921-4cfb-c8ff-9313edb6cae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 89s 129ms/step - loss: 0.5665 - accuracy: 0.6977 - val_loss: 0.4322 - val_accuracy: 0.8046\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 75s 120ms/step - loss: 0.4241 - accuracy: 0.8145 - val_loss: 0.3938 - val_accuracy: 0.8198\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 76s 122ms/step - loss: 0.3816 - accuracy: 0.8373 - val_loss: 0.3684 - val_accuracy: 0.8380\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 77s 123ms/step - loss: 0.3532 - accuracy: 0.8505 - val_loss: 0.3297 - val_accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 49s 78ms/step - loss: 0.3247 - accuracy: 0.8646 - val_loss: 0.3901 - val_accuracy: 0.8343\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.3034 - accuracy: 0.8740 - val_loss: 0.3070 - val_accuracy: 0.8685\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 79s 126ms/step - loss: 0.2872 - accuracy: 0.8828 - val_loss: 0.3041 - val_accuracy: 0.8729\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 78s 124ms/step - loss: 0.2730 - accuracy: 0.8891 - val_loss: 0.2985 - val_accuracy: 0.8776\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 49s 78ms/step - loss: 0.2558 - accuracy: 0.8955 - val_loss: 0.3055 - val_accuracy: 0.8752\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 72s 115ms/step - loss: 0.2415 - accuracy: 0.9056 - val_loss: 0.3023 - val_accuracy: 0.8769\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f6a2e59ba00>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model1.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lajAF1FDTKzT",
        "outputId": "ba5a9efe-c60a-4d38-a0ff-cad4444644c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 24s 25ms/step - loss: 0.2985 - accuracy: 0.8776\n",
            "Test acc: 0.878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performs decently but does not surpass the performance of the bigram and trigram models.\n",
        "\n",
        "Models with pretrained word embedding are only useful when the dataset is very small."
      ],
      "metadata": {
        "id": "9fiuqQxJW8Mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer with Positional Embedding\n",
        "\n",
        "---\n",
        "\n",
        "In this section, a Transformer model with positional embedding is implemented for sequence-to-sequence tasks using TensorFlow's Keras API.\n",
        "\n",
        "The transformer_encoder function defines the transformer encoder block. It includes a multi-head self-attention layer, followed by residual connections and layer normalization. The output is then passed through dense layers for projection and another set of residual connections and layer normalization.\n",
        "\n",
        "The PositionalEmbedding function calculates positional embeddings for the input tokens by adding token embeddings with positional embeddings. It utilizes two embedding layers, one for token embeddings and another for positional embeddings.\n",
        "\n",
        "The main model architecture starts with an input layer accepting sequences of integer tokens. Positional embeddings are added to the input tokens using the PositionalEmbedding function. The transformer_encoder function is applied to the positional embeddings to encode the input sequence. Global max pooling and dropout layers are added for feature extraction and regularization, respectively. Finally, a dense output layer with a sigmoid activation function is included for binary classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer and binary crossentropy loss function. Accuracy is chosen as the evaluation metric.\n",
        "\n",
        "Callbacks are defined for model checkpointing to save the best performing model during training.\n",
        "\n",
        "The model is trained using the fit method with the training and validation datasets. After training, the best performing model is loaded, and its performance is evaluated on the test dataset, with the test accuracy printed."
      ],
      "metadata": {
        "id": "-D01JHN7Xl90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, GlobalMaxPooling1D\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "def transformer_encoder(inputs, embed_dim, dense_dim, num_heads, mask=None):\n",
        "\n",
        "  '''\n",
        "    Args:\n",
        "      inputs: input tensor of shape (batch_size, sequence_length, embed_dim)\n",
        "        embed_dim: word embedding dimension\n",
        "        dense_dim: units in the dense layers\n",
        "        num_heads: number of heads in the multi-head attention\n",
        "        mask: mask tensor for attention (optional)\n",
        "  '''\n",
        "\n",
        "    # Multi-head self-attention layer\n",
        "  attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs, attention_mask=mask)\n",
        "\n",
        "  # Residual connection and layer normalization\n",
        "  proj_input = LayerNormalization()(inputs + attention_output)\n",
        "\n",
        "  # Dense projection\n",
        "  proj_output = Dense(dense_dim, activation=\"relu\")(proj_input)\n",
        "  proj_output = Dense(embed_dim)(proj_output)\n",
        "\n",
        "  # Second residual connection and layer normalization\n",
        "  output = LayerNormalization()(proj_input + proj_output)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "Ff17frnfwUvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PositionalEmbedding(sequence_length, input_dim, output_dim):\n",
        "    token_embedding_layer = Embedding(input_dim=input_dim, output_dim=output_dim)\n",
        "    position_embedding_layer = Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
        "\n",
        "    def apply_embedding(inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        positions = positions[tf.newaxis, :]\n",
        "        embedded_tokens = token_embedding_layer(inputs)\n",
        "        embedded_positions = position_embedding_layer(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    return apply_embedding"
      ],
      "metadata": {
        "id": "0jB0r_hCZIXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, GlobalMaxPooling1D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the parameters\n",
        "vocab_size = 20000\n",
        "sequence_len = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "mask = None\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(shape=(sequence_len,), dtype=\"int64\")\n",
        "\n",
        "# Get the positional embedding\n",
        "x = PositionalEmbedding(sequence_len, vocab_size, embed_dim)(inputs)\n",
        "\n",
        "# Apply the transformer_encoder function\n",
        "encoder_output = transformer_encoder(x, embed_dim, dense_dim, num_heads, mask=None)\n",
        "\n",
        "# Apply global max pooling and dropout\n",
        "x = GlobalMaxPooling1D()(encoder_output)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Add the output layer\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Create the model\n",
        "model1 = Model(inputs=inputs, outputs=outputs, name='Transformer_architecture_with_Positional_Embedding')\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer=\"adam\",\n",
        "               loss=\"binary_crossentropy\",\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "# Display model summary\n",
        "model1.summary()\n",
        "\n",
        "callbacks = [\n",
        " ModelCheckpoint(\"transformer_encoder.keras\",\n",
        " save_best_only=True)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz1M8dB-_PkA",
        "outputId": "5de84492-49bc-4b3c-aca3-556d7be18304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Transformer_architecture_with_Positional_Embedding\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 600)]                0         []                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_1 (TFOp  (2,)                         0         ['input_4[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_1[0][0]']\n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.range_1 (TFOpLambda)     (600,)                       0         ['tf.__operators__.getitem_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3  (1, 600)                     0         ['tf.range_1[0][0]']          \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 600, 256)             5120000   ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (1, 600, 256)                153600    ['tf.__operators__.getitem_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None, 600, 256)             0         ['embedding_2[0][0]',         \n",
            " OpLambda)                                                           'embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 600, 256)             526080    ['tf.__operators__.add_3[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TF  (None, 600, 256)             0         ['tf.__operators__.add_3[0][0]\n",
            " OpLambda)                                                          ',                            \n",
            "                                                                     'multi_head_attention_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 600, 256)             512       ['tf.__operators__.add_4[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 600, 32)              8224      ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 600, 256)             8448      ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TF  (None, 600, 256)             0         ['layer_normalization_2[0][0]'\n",
            " OpLambda)                                                          , 'dense_5[0][0]']            \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 600, 256)             512       ['tf.__operators__.add_5[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 256)                  0         ['layer_normalization_3[0][0]'\n",
            " obalMaxPooling1D)                                                  ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 256)                  0         ['global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    257       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5817633 (22.19 MB)\n",
            "Trainable params: 5817633 (22.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(int_train_ds, validation_data=int_val_ds, epochs=15,\n",
        " callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4QA63OI4oB3",
        "outputId": "a8182ed6-6b79-4f75-bcf4-50664c9b82e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 88s 131ms/step - loss: 0.5789 - accuracy: 0.7031 - val_loss: 0.3398 - val_accuracy: 0.8519\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.2619 - accuracy: 0.8911 - val_loss: 0.3244 - val_accuracy: 0.8708\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 63s 100ms/step - loss: 0.1186 - accuracy: 0.9563 - val_loss: 0.5441 - val_accuracy: 0.8537\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 61s 98ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.6043 - val_accuracy: 0.8509\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.6376 - val_accuracy: 0.8410\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.7956 - val_accuracy: 0.8299\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.8902 - val_accuracy: 0.8377\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 60s 97ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.8815 - val_accuracy: 0.8436\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 59s 95ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.8251 - val_accuracy: 0.8414\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.9605 - val_accuracy: 0.8420\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.7938 - val_accuracy: 0.8402\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 58s 94ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.8058 - val_accuracy: 0.8366\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 1.0200 - val_accuracy: 0.8286\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 1.0915 - val_accuracy: 0.8350\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.1106 - val_accuracy: 0.8220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a68a03498a0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = load_model(\"transformer_encoder.keras\")\n",
        "print(f\"Test acc: {model1.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px5p1Ey0jepH",
        "outputId": "c82ecccc-a44d-4e24-e94f-48869db1df93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 20s 25ms/step - loss: 0.3244 - accuracy: 0.8708\n",
            "Test acc: 0.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis evaluated various text representation models to determine their effectiveness in sentiment analysis, focusing on their classification accuracy. Among the Bag-of-Words (BoW) models, the TriGram model achieved the highest accuracy at 89.7%, followed by the BiGram model at 89.5%, and the UniGram model at 86.6%. When incorporating TF-IDF with the BiGram model, the accuracy slightly decreased to 88.7%.\n",
        "\n",
        "In the sequence-to-sequence models, one-hot encoded vectors resulted in an accuracy of 85.7%. Using word embeddings showed improvement: standard word embeddings reached 87.1%, while pre-trained word embeddings (GloVe) achieved 87.8%. The Transformer model with positional encoding matched the standard word embedding performance with an accuracy of 87.1%.\n",
        "\n",
        "Overall, the TriGram model exhibited the highest accuracy, highlighting the importance of capturing word sequences in sentiment analysis. Based on these results, the TriGram model was selected as the best-performing model. It will be used to predict sentiment on two random movie reviews."
      ],
      "metadata": {
        "id": "imTWj23wkIUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Prediction with the Best Model: Unseen Reviews\n",
        "\n",
        "---\n",
        "In this section, sentiment prediction is performed using the best-trained model on unseen reviews.\n",
        "\n",
        "Three example sentences are provided for sentiment prediction: \"It was a terrible movie.\", \"The movie was great. The music was outstanding!\", and \"Excellent! Loved every bit of it!\".\n",
        "\n",
        "The sentences are tokenized using the same tokenizer used during training to convert them into integer sequences.\n",
        "\n",
        "The best-trained model (3-gram approach) is loaded for prediction. Predictions are made on the tokenized sequences using the loaded model, resulting in probability scores for each class (positive or negative sentiment).\n",
        "\n",
        "A threshold of 0.5 is applied to convert the probability scores into binary classes, where values above the threshold are classified as positive sentiment (1) and values below or equal to the threshold are classified as negative sentiment (0).\n",
        "\n",
        "The predicted classes are then printed to display the sentiment prediction for each input sentence.\n"
      ],
      "metadata": {
        "id": "4TqvYO3uhEwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define the sentences to predict.\n",
        "sentences_to_predict = [\"It was a terrible movie.\", \"The movie was great. The music was outstanding!\", \"Excellent! Loved every bit of it!\"]\n",
        "\n",
        "# Convert the sentences into integer sequences.\n",
        "tokenized_sentences = text_vectorization(sentences_to_predict)\n",
        "\n",
        "# Load the best model for prediction.\n",
        "model_final = load_model(\"binary_3gram.keras\")\n",
        "\n",
        "# Make predictions on the padded sequences.\n",
        "predictions = model_final.predict(tokenized_sentences)\n",
        "\n",
        "# Assuming binary classification, you can use a threshold (e.g., 0.5) to convert probabilities to classes.\n",
        "threshold = 0.5\n",
        "predicted_classes = (predictions > threshold).astype(\"int32\")\n",
        "\n",
        "# Display the predicted classes.\n",
        "print(predicted_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO1y3p0dkmlC",
        "outputId": "d427b7be-41a8-4107-f673-0f0300dce782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "[[0]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    }
  ]
}